<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <title id="head-title">report.html</title>
      <link href="assets\style.css" rel="stylesheet" type="text/css"/>
  </head>
  <body>
    <h1 id="title">report.html</h1>
    <p>Report generated on 03-Nov-2023 at 14:09:19 by <a href="https://pypi.python.org/pypi/pytest-html">pytest-html</a>
        v4.0.2</p>
    <div id="environment-header">
      <h2>Environment</h2>
    </div>
    <table id="environment"></table>
    <!-- TEMPLATES -->
      <template id="template_environment_row">
      <tr>
        <td></td>
        <td></td>
      </tr>
    </template>
    <template id="template_results-table__body--empty">
      <tbody class="results-table-row">
        <tr id="not-found-message">
          <td colspan="4">No results found. Check the filters.</th>
        </tr>
    </template>
    <template id="template_results-table__tbody">
      <tbody class="results-table-row">
        <tr class="collapsible">
        </tr>
        <tr class="extras-row">
          <td class="extra" colspan="4">
            <div class="extraHTML"></div>
            <div class="media">
              <div class="media-container">
                  <div class="media-container__nav--left"><</div>
                  <div class="media-container__viewport">
                    <img src="" />
                    <video controls>
                      <source src="" type="video/mp4">
                    </video>
                  </div>
                  <div class="media-container__nav--right">></div>
                </div>
                <div class="media__name"></div>
                <div class="media__counter"></div>
            </div>
            <div class="logwrapper">
              <div class="logexpander"></div>
              <div class="log"></div>
            </div>
          </td>
        </tr>
      </tbody>
    </template>
    <!-- END TEMPLATES -->
    <div class="summary">
      <div class="summary__data">
        <h2>Summary</h2>
        <div class="additional-summary prefix">
        </div>
        <p class="run-count">0 test took 880 ms.</p>
        <p class="filter">(Un)check the boxes to filter the results.</p>
        <div class="summary__reload">
          <div class="summary__reload__button hidden" onclick="location.reload()">
            <div>There are still tests running. <br />Reload this page to ge the latest results!</div>
          </div>
        </div>
        <div class="summary__spacer"></div>
        <div class="controls">
          <div class="filters">
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="failed" disabled/>
            <span class="failed">0 Failed,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="passed" disabled/>
            <span class="passed">0 Passed,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="skipped" disabled/>
            <span class="skipped">0 Skipped,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="xfailed" disabled/>
            <span class="xfailed">0 Expected failures,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="xpassed" disabled/>
            <span class="xpassed">0 Unexpected passes,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="error" />
            <span class="error">11 Errors,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="rerun" disabled/>
            <span class="rerun">0 Reruns</span>
          </div>
          <div class="collapse">
            <button id="show_all_details">Show all details</button>&nbsp;/&nbsp;<button id="hide_all_details">Hide all details</button>
          </div>
        </div>
      </div>
      <div class="additional-summary summary">
      </div>
      <div class="additional-summary postfix">
      </div>
    </div>
    <table id="results-table">
      <thead id="results-table-head">
        <tr>
          <th class="sortable" data-column-type="result">Result</th>
          <th class="sortable" data-column-type="testId">Test</th>
          <th class="sortable" data-column-type="duration">Duration</th>
          <th>Links</th>
        </tr>
      </thead>
    </table>
  </body>
  <footer>
    <div id="data-container" data-jsonblob="{&#34;environment&#34;: {&#34;Python&#34;: &#34;3.11.5&#34;, &#34;Platform&#34;: &#34;Windows-10-10.0.22621-SP0&#34;, &#34;Packages&#34;: {&#34;pytest&#34;: &#34;7.4.2&#34;, &#34;pluggy&#34;: &#34;1.3.0&#34;}, &#34;Plugins&#34;: {&#34;anyio&#34;: &#34;3.7.1&#34;, &#34;Faker&#34;: &#34;19.3.1&#34;, &#34;bdd&#34;: &#34;7.0.0&#34;, &#34;html&#34;: &#34;4.0.2&#34;, &#34;metadata&#34;: &#34;3.0.0&#34;}, &#34;JAVA_HOME&#34;: &#34;C:\\Program Files (x86)\\Java\\jre1.8.0_361&#34;}, &#34;tests&#34;: {&#34;Single_bucket_sim.py::test_user_creation_and_login&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Error&#34;, &#34;testId&#34;: &#34;Single_bucket_sim.py::test_user_creation_and_login::setup&#34;, &#34;duration&#34;: &#34;874 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Error&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;Single_bucket_sim.py::test_user_creation_and_login::setup&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;874 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;\n\n    def _new_conn(self):\n        \&#34;\&#34;\&#34;Establish a socket connection and set nodelay settings on it.\n    \n        :return: New socket connection.\n        \&#34;\&#34;\&#34;\n        extra_kw = {}\n        if self.source_address:\n            extra_kw[\&#34;source_address\&#34;] = self.source_address\n    \n        if self.socket_options:\n            extra_kw[\&#34;socket_options\&#34;] = self.socket_options\n    \n        try:\n&amp;gt;           conn = connection.create_connection(\n                (self._dns_host, self.port), self.timeout, **extra_kw\n            )\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connection.py:174: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\util\\connection.py:72: in create_connection\n    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nhost = &#39;googlechromelabs.github.io&#39;, port = 443, family = &amp;lt;AddressFamily.AF_UNSPEC: 0&amp;gt;, type = &amp;lt;SocketKind.SOCK_STREAM: 1&amp;gt;, proto = 0, flags = 0\n\n    def getaddrinfo(host, port, family=0, type=0, proto=0, flags=0):\n        \&#34;\&#34;\&#34;Resolve host and port into list of address info entries.\n    \n        Translate the host/port argument into a sequence of 5-tuples that contain\n        all the necessary arguments for creating a socket connected to that service.\n        host is a domain name, a string representation of an IPv4/v6 address or\n        None. port is a string service name such as &#39;http&#39;, a numeric port number or\n        None. By passing None as the value of host and port, you can pass NULL to\n        the underlying C API.\n    \n        The family, type and proto arguments can be optionally specified in order to\n        narrow the list of addresses returned. Passing zero as a value for each of\n        these arguments selects the full range of results.\n        \&#34;\&#34;\&#34;\n        # We override this function since we want to translate the numeric family\n        # and socket type values to enum constants.\n        addrlist = []\n&amp;gt;       for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\nE       socket.gaierror: [Errno 11001] getaddrinfo failed\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\socket.py:962: gaierror\n\nDuring handling of the above exception, another exception occurred:\n\nself = &amp;lt;urllib3.connectionpool.HTTPSConnectionPool object at 0x000002487F354910&amp;gt;, method = &#39;GET&#39;, url = &#39;/chrome-for-testing/known-good-versions-with-downloads.json&#39;\nbody = None, headers = {&#39;User-Agent&#39;: &#39;python-requests/2.27.1&#39;, &#39;Accept-Encoding&#39;: &#39;gzip, deflate&#39;, &#39;Accept&#39;: &#39;*/*&#39;, &#39;Connection&#39;: &#39;keep-alive&#39;}\nretries = Retry(total=0, connect=None, read=False, redirect=None, status=None), redirect = False, assert_same_host = False\ntimeout = Timeout(connect=None, read=None, total=None), pool_timeout = None, release_conn = False, chunked = False, body_pos = None\nresponse_kw = {&#39;decode_content&#39;: False, &#39;preload_content&#39;: False}\nparsed_url = Url(scheme=None, auth=None, host=None, port=None, path=&#39;/chrome-for-testing/known-good-versions-with-downloads.json&#39;, query=None, fragment=None)\ndestination_scheme = None, conn = None, release_this_conn = True, http_tunnel_required = False, err = None, clean_exit = False\n\n    def urlopen(\n        self,\n        method,\n        url,\n        body=None,\n        headers=None,\n        retries=None,\n        redirect=True,\n        assert_same_host=True,\n        timeout=_Default,\n        pool_timeout=None,\n        release_conn=None,\n        chunked=False,\n        body_pos=None,\n        **response_kw\n    ):\n        \&#34;\&#34;\&#34;\n        Get a connection from the pool and perform an HTTP request. This is the\n        lowest level call for making a request, so you&#39;ll need to specify all\n        the raw details.\n    \n        .. note::\n    \n           More commonly, it&#39;s appropriate to use a convenience method provided\n           by :class:`.RequestMethods`, such as :meth:`request`.\n    \n        .. note::\n    \n           `release_conn` will only behave as expected if\n           `preload_content=False` because we want to make\n           `preload_content=False` the default behaviour someday soon without\n           breaking backwards compatibility.\n    \n        :param method:\n            HTTP request method (such as GET, POST, PUT, etc.)\n    \n        :param url:\n            The URL to perform the request on.\n    \n        :param body:\n            Data to send in the request body, either :class:`str`, :class:`bytes`,\n            an iterable of :class:`str`/:class:`bytes`, or a file-like object.\n    \n        :param headers:\n            Dictionary of custom headers to send, such as User-Agent,\n            If-None-Match, etc. If None, pool headers are used. If provided,\n            these headers completely replace any pool-specific headers.\n    \n        :param retries:\n            Configure the number of retries to allow before raising a\n            :class:`~urllib3.exceptions.MaxRetryError` exception.\n    \n            Pass ``None`` to retry until you receive a response. Pass a\n            :class:`~urllib3.util.retry.Retry` object for fine-grained control\n            over different types of retries.\n            Pass an integer number to retry connection errors that many times,\n            but no other types of errors. Pass zero to never retry.\n    \n            If ``False``, then retries are disabled and any exception is raised\n            immediately. Also, instead of raising a MaxRetryError on redirects,\n            the redirect response will be returned.\n    \n        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.\n    \n        :param redirect:\n            If True, automatically handle redirects (status codes 301, 302,\n            303, 307, 308). Each redirect counts as a retry. Disabling retries\n            will disable redirect, too.\n    \n        :param assert_same_host:\n            If ``True``, will make sure that the host of the pool requests is\n            consistent else will raise HostChangedError. When ``False``, you can\n            use the pool on an HTTP proxy and request foreign hosts.\n    \n        :param timeout:\n            If specified, overrides the default timeout for this one\n            request. It may be a float (in seconds) or an instance of\n            :class:`urllib3.util.Timeout`.\n    \n        :param pool_timeout:\n            If set and the pool is set to block=True, then this method will\n            block for ``pool_timeout`` seconds and raise EmptyPoolError if no\n            connection is available within the time period.\n    \n        :param release_conn:\n            If False, then the urlopen call will not release the connection\n            back into the pool once a response is received (but will release if\n            you read the entire contents of the response such as when\n            `preload_content=True`). This is useful if you&#39;re not preloading\n            the response&#39;s content immediately. You will need to call\n            ``r.release_conn()`` on the response ``r`` to return the connection\n            back into the pool. If None, it takes the value of\n            ``response_kw.get(&#39;preload_content&#39;, True)``.\n    \n        :param chunked:\n            If True, urllib3 will send the body using chunked transfer\n            encoding. Otherwise, urllib3 will send the body using the standard\n            content-length form. Defaults to False.\n    \n        :param int body_pos:\n            Position to seek to in file-like body in the event of a retry or\n            redirect. Typically this won&#39;t need to be set because urllib3 will\n            auto-populate the value when needed.\n    \n        :param \\\\**response_kw:\n            Additional parameters are passed to\n            :meth:`urllib3.response.HTTPResponse.from_httplib`\n        \&#34;\&#34;\&#34;\n    \n        parsed_url = parse_url(url)\n        destination_scheme = parsed_url.scheme\n    \n        if headers is None:\n            headers = self.headers\n    \n        if not isinstance(retries, Retry):\n            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)\n    \n        if release_conn is None:\n            release_conn = response_kw.get(\&#34;preload_content\&#34;, True)\n    \n        # Check host\n        if assert_same_host and not self.is_same_host(url):\n            raise HostChangedError(self, url, retries)\n    \n        # Ensure that the URL we&#39;re connecting to is properly encoded\n        if url.startswith(\&#34;/\&#34;):\n            url = six.ensure_str(_encode_target(url))\n        else:\n            url = six.ensure_str(parsed_url.url)\n    \n        conn = None\n    \n        # Track whether `conn` needs to be released before\n        # returning/raising/recursing. Update this variable if necessary, and\n        # leave `release_conn` constant throughout the function. That way, if\n        # the function recurses, the original value of `release_conn` will be\n        # passed down into the recursive call, and its value will be respected.\n        #\n        # See issue #651 [1] for details.\n        #\n        # [1] &amp;lt;https://github.com/urllib3/urllib3/issues/651&amp;gt;\n        release_this_conn = release_conn\n    \n        http_tunnel_required = connection_requires_http_tunnel(\n            self.proxy, self.proxy_config, destination_scheme\n        )\n    \n        # Merge the proxy headers. Only done when not using HTTP CONNECT. We\n        # have to copy the headers dict so we can safely change it without those\n        # changes being reflected in anyone else&#39;s copy.\n        if not http_tunnel_required:\n            headers = headers.copy()\n            headers.update(self.proxy_headers)\n    \n        # Must keep the exception bound to a separate variable or else Python 3\n        # complains about UnboundLocalError.\n        err = None\n    \n        # Keep track of whether we cleanly exited the except block. This\n        # ensures we do proper cleanup in finally.\n        clean_exit = False\n    \n        # Rewind body position, if needed. Record current position\n        # for future rewinds in the event of a redirect/retry.\n        body_pos = set_file_position(body, body_pos)\n    \n        try:\n            # Request a connection from the queue.\n            timeout_obj = self._get_timeout(timeout)\n            conn = self._get_conn(timeout=pool_timeout)\n    \n            conn.timeout = timeout_obj.connect_timeout\n    \n            is_new_proxy_conn = self.proxy is not None and not getattr(\n                conn, \&#34;sock\&#34;, None\n            )\n            if is_new_proxy_conn and http_tunnel_required:\n                self._prepare_proxy(conn)\n    \n            # Make the request on the httplib connection object.\n&amp;gt;           httplib_response = self._make_request(\n                conn,\n                method,\n                url,\n                timeout=timeout_obj,\n                body=body,\n                headers=headers,\n                chunked=chunked,\n            )\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:715: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:404: in _make_request\n    self._validate_conn(conn)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1058: in _validate_conn\n    conn.connect()\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connection.py:363: in connect\n    self.sock = conn = self._new_conn()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;\n\n    def _new_conn(self):\n        \&#34;\&#34;\&#34;Establish a socket connection and set nodelay settings on it.\n    \n        :return: New socket connection.\n        \&#34;\&#34;\&#34;\n        extra_kw = {}\n        if self.source_address:\n            extra_kw[\&#34;source_address\&#34;] = self.source_address\n    \n        if self.socket_options:\n            extra_kw[\&#34;socket_options\&#34;] = self.socket_options\n    \n        try:\n            conn = connection.create_connection(\n                (self._dns_host, self.port), self.timeout, **extra_kw\n            )\n    \n        except SocketTimeout:\n            raise ConnectTimeoutError(\n                self,\n                \&#34;Connection to %s timed out. (connect timeout=%s)\&#34;\n                % (self.host, self.timeout),\n            )\n    \n        except SocketError as e:\n&amp;gt;           raise NewConnectionError(\n                self, \&#34;Failed to establish a new connection: %s\&#34; % e\n            )\nE           urllib3.exceptions.NewConnectionError: &amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;: Failed to establish a new connection: [Errno 11001] getaddrinfo failed\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connection.py:186: NewConnectionError\n\nDuring handling of the above exception, another exception occurred:\n\nself = &amp;lt;requests.adapters.HTTPAdapter object at 0x000002487F34AA10&amp;gt;, request = &amp;lt;PreparedRequest [GET]&amp;gt;, stream = True, timeout = Timeout(connect=None, read=None, total=None)\nverify = True, cert = None, proxies = OrderedDict()\n\n    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):\n        \&#34;\&#34;\&#34;Sends PreparedRequest object. Returns Response object.\n    \n        :param request: The :class:`PreparedRequest &amp;lt;PreparedRequest&amp;gt;` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) &amp;lt;timeouts&amp;gt;` tuple.\n        :type timeout: float or tuple or urllib3 Timeout object\n        :param verify: (optional) Either a boolean, in which case it controls whether\n            we verify the server&#39;s TLS certificate, or a string, in which case it\n            must be a path to a CA bundle to use\n        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        :rtype: requests.Response\n        \&#34;\&#34;\&#34;\n    \n        try:\n            conn = self.get_connection(request.url, proxies)\n        except LocationValueError as e:\n            raise InvalidURL(e, request=request)\n    \n        self.cert_verify(conn, request.url, verify, cert)\n        url = self.request_url(request, proxies)\n        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)\n    \n        chunked = not (request.body is None or &#39;Content-Length&#39; in request.headers)\n    \n        if isinstance(timeout, tuple):\n            try:\n                connect, read = timeout\n                timeout = TimeoutSauce(connect=connect, read=read)\n            except ValueError as e:\n                # this may raise a string formatting error.\n                err = (\&#34;Invalid timeout {}. Pass a (connect, read) \&#34;\n                       \&#34;timeout tuple, or a single float to set \&#34;\n                       \&#34;both timeouts to the same value\&#34;.format(timeout))\n                raise ValueError(err)\n        elif isinstance(timeout, TimeoutSauce):\n            pass\n        else:\n            timeout = TimeoutSauce(connect=timeout, read=timeout)\n    \n        try:\n            if not chunked:\n&amp;gt;               resp = conn.urlopen(\n                    method=request.method,\n                    url=url,\n                    body=request.body,\n                    headers=request.headers,\n                    redirect=False,\n                    assert_same_host=False,\n                    preload_content=False,\n                    decode_content=False,\n                    retries=self.max_retries,\n                    timeout=timeout\n                )\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\adapters.py:440: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:799: in urlopen\n    retries = retries.increment(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = Retry(total=0, connect=None, read=False, redirect=None, status=None), method = &#39;GET&#39;, url = &#39;/chrome-for-testing/known-good-versions-with-downloads.json&#39;\nresponse = None\nerror = NewConnectionError(&#39;&amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;: Failed to establish a new connection: [Errno 11001] getaddrinfo failed&#39;)\n_pool = &amp;lt;urllib3.connectionpool.HTTPSConnectionPool object at 0x000002487F354910&amp;gt;, _stacktrace = &amp;lt;traceback object at 0x000002487F354FC0&amp;gt;\n\n    def increment(\n        self,\n        method=None,\n        url=None,\n        response=None,\n        error=None,\n        _pool=None,\n        _stacktrace=None,\n    ):\n        \&#34;\&#34;\&#34;Return a new Retry object with incremented retry counters.\n    \n        :param response: A response object, or None, if the server did not\n            return a response.\n        :type response: :class:`~urllib3.response.HTTPResponse`\n        :param Exception error: An error encountered during the request, or\n            None if the response was received successfully.\n    \n        :return: A new ``Retry`` object.\n        \&#34;\&#34;\&#34;\n        if self.total is False and error:\n            # Disabled, indicate to re-raise the error.\n            raise six.reraise(type(error), error, _stacktrace)\n    \n        total = self.total\n        if total is not None:\n            total -= 1\n    \n        connect = self.connect\n        read = self.read\n        redirect = self.redirect\n        status_count = self.status\n        other = self.other\n        cause = \&#34;unknown\&#34;\n        status = None\n        redirect_location = None\n    \n        if error and self._is_connection_error(error):\n            # Connect retry?\n            if connect is False:\n                raise six.reraise(type(error), error, _stacktrace)\n            elif connect is not None:\n                connect -= 1\n    \n        elif error and self._is_read_error(error):\n            # Read retry?\n            if read is False or not self._is_method_retryable(method):\n                raise six.reraise(type(error), error, _stacktrace)\n            elif read is not None:\n                read -= 1\n    \n        elif error:\n            # Other retry?\n            if other is not None:\n                other -= 1\n    \n        elif response and response.get_redirect_location():\n            # Redirect retry?\n            if redirect is not None:\n                redirect -= 1\n            cause = \&#34;too many redirects\&#34;\n            redirect_location = response.get_redirect_location()\n            status = response.status\n    \n        else:\n            # Incrementing because of a server error like a 500 in\n            # status_forcelist and the given method is in the allowed_methods\n            cause = ResponseError.GENERIC_ERROR\n            if response and response.status:\n                if status_count is not None:\n                    status_count -= 1\n                cause = ResponseError.SPECIFIC_ERROR.format(status_code=response.status)\n                status = response.status\n    \n        history = self.history + (\n            RequestHistory(method, url, error, status, redirect_location),\n        )\n    \n        new_retry = self.new(\n            total=total,\n            connect=connect,\n            read=read,\n            redirect=redirect,\n            status=status_count,\n            other=other,\n            history=history,\n        )\n    \n        if new_retry.is_exhausted():\n&amp;gt;           raise MaxRetryError(_pool, url, error or ResponseError(cause))\nE           urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host=&#39;googlechromelabs.github.io&#39;, port=443): Max retries exceeded with url: /chrome-for-testing/known-good-versions-with-downloads.json (Caused by NewConnectionError(&#39;&amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;: Failed to establish a new connection: [Errno 11001] getaddrinfo failed&#39;))\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\util\\retry.py:592: MaxRetryError\n\nDuring handling of the above exception, another exception occurred:\n\nself = &amp;lt;webdriver_manager.core.http.WDMHttpClient object at 0x000002487F2E6990&amp;gt;\nurl = &#39;https://googlechromelabs.github.io/chrome-for-testing/known-good-versions-with-downloads.json&#39;, kwargs = {}\n\n    def get(self, url, **kwargs) -&amp;gt; Response:\n        try:\n&amp;gt;           resp = requests.get(\n                url=url, verify=self._ssl_verify, stream=True, **kwargs)\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\core\\http.py:32: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\api.py:75: in get\n    return request(&#39;get&#39;, url, params=params, **kwargs)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\api.py:61: in request\n    return session.request(method=method, url=url, **kwargs)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\sessions.py:529: in request\n    resp = self.send(prep, **send_kwargs)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\sessions.py:645: in send\n    r = adapter.send(request, **kwargs)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;requests.adapters.HTTPAdapter object at 0x000002487F34AA10&amp;gt;, request = &amp;lt;PreparedRequest [GET]&amp;gt;, stream = True, timeout = Timeout(connect=None, read=None, total=None)\nverify = True, cert = None, proxies = OrderedDict()\n\n    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):\n        \&#34;\&#34;\&#34;Sends PreparedRequest object. Returns Response object.\n    \n        :param request: The :class:`PreparedRequest &amp;lt;PreparedRequest&amp;gt;` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) &amp;lt;timeouts&amp;gt;` tuple.\n        :type timeout: float or tuple or urllib3 Timeout object\n        :param verify: (optional) Either a boolean, in which case it controls whether\n            we verify the server&#39;s TLS certificate, or a string, in which case it\n            must be a path to a CA bundle to use\n        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        :rtype: requests.Response\n        \&#34;\&#34;\&#34;\n    \n        try:\n            conn = self.get_connection(request.url, proxies)\n        except LocationValueError as e:\n            raise InvalidURL(e, request=request)\n    \n        self.cert_verify(conn, request.url, verify, cert)\n        url = self.request_url(request, proxies)\n        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)\n    \n        chunked = not (request.body is None or &#39;Content-Length&#39; in request.headers)\n    \n        if isinstance(timeout, tuple):\n            try:\n                connect, read = timeout\n                timeout = TimeoutSauce(connect=connect, read=read)\n            except ValueError as e:\n                # this may raise a string formatting error.\n                err = (\&#34;Invalid timeout {}. Pass a (connect, read) \&#34;\n                       \&#34;timeout tuple, or a single float to set \&#34;\n                       \&#34;both timeouts to the same value\&#34;.format(timeout))\n                raise ValueError(err)\n        elif isinstance(timeout, TimeoutSauce):\n            pass\n        else:\n            timeout = TimeoutSauce(connect=timeout, read=timeout)\n    \n        try:\n            if not chunked:\n                resp = conn.urlopen(\n                    method=request.method,\n                    url=url,\n                    body=request.body,\n                    headers=request.headers,\n                    redirect=False,\n                    assert_same_host=False,\n                    preload_content=False,\n                    decode_content=False,\n                    retries=self.max_retries,\n                    timeout=timeout\n                )\n    \n            # Send the request.\n            else:\n                if hasattr(conn, &#39;proxy_pool&#39;):\n                    conn = conn.proxy_pool\n    \n                low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)\n    \n                try:\n                    skip_host = &#39;Host&#39; in request.headers\n                    low_conn.putrequest(request.method,\n                                        url,\n                                        skip_accept_encoding=True,\n                                        skip_host=skip_host)\n    \n                    for header, value in request.headers.items():\n                        low_conn.putheader(header, value)\n    \n                    low_conn.endheaders()\n    \n                    for i in request.body:\n                        low_conn.send(hex(len(i))[2:].encode(&#39;utf-8&#39;))\n                        low_conn.send(b&#39;\\r\\n&#39;)\n                        low_conn.send(i)\n                        low_conn.send(b&#39;\\r\\n&#39;)\n                    low_conn.send(b&#39;0\\r\\n\\r\\n&#39;)\n    \n                    # Receive the response from the server\n                    try:\n                        # For Python 2.7, use buffering of HTTP responses\n                        r = low_conn.getresponse(buffering=True)\n                    except TypeError:\n                        # For compatibility with Python 3.3+\n                        r = low_conn.getresponse()\n    \n                    resp = HTTPResponse.from_httplib(\n                        r,\n                        pool=conn,\n                        connection=low_conn,\n                        preload_content=False,\n                        decode_content=False\n                    )\n                except:\n                    # If we hit any problems here, clean up the connection.\n                    # Then, reraise so that we can handle the actual exception.\n                    low_conn.close()\n                    raise\n    \n        except (ProtocolError, socket.error) as err:\n            raise ConnectionError(err, request=request)\n    \n        except MaxRetryError as e:\n            if isinstance(e.reason, ConnectTimeoutError):\n                # TODO: Remove this in 3.0.0: see #2811\n                if not isinstance(e.reason, NewConnectionError):\n                    raise ConnectTimeout(e, request=request)\n    \n            if isinstance(e.reason, ResponseError):\n                raise RetryError(e, request=request)\n    \n            if isinstance(e.reason, _ProxyError):\n                raise ProxyError(e, request=request)\n    \n            if isinstance(e.reason, _SSLError):\n                # This branch is for urllib3 v1.22 and later.\n                raise SSLError(e, request=request)\n    \n&amp;gt;           raise ConnectionError(e, request=request)\nE           requests.exceptions.ConnectionError: HTTPSConnectionPool(host=&#39;googlechromelabs.github.io&#39;, port=443): Max retries exceeded with url: /chrome-for-testing/known-good-versions-with-downloads.json (Caused by NewConnectionError(&#39;&amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;: Failed to establish a new connection: [Errno 11001] getaddrinfo failed&#39;))\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\adapters.py:519: ConnectionError\n\nDuring handling of the above exception, another exception occurred:\n\n    @pytest.fixture(scope=\&#34;module\&#34;)\n    def driver():\n        options = Options()\n        options.add_experimental_option(\&#34;detach\&#34;, True)\n        #driver = webdriver.Chrome(options=options)\n&amp;gt;       driver = webdriver.Chrome(options=options, service=Service(ChromeDriverManager().install()))\n\nSingle_bucket_sim.py:27: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\chrome.py:40: in install\n    driver_path = self._get_driver_binary_path(self.driver)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\core\\manager.py:40: in _get_driver_binary_path\n    file = self._download_manager.download_file(driver.get_driver_download_url(os_type))\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\drivers\\chrome.py:44: in get_driver_download_url\n    modern_version_url = self.get_url_for_version_and_platform(driver_version_to_download, os_type)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\drivers\\chrome.py:69: in get_url_for_version_and_platform\n    response = self._http_client.get(url)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;webdriver_manager.core.http.WDMHttpClient object at 0x000002487F2E6990&amp;gt;\nurl = &#39;https://googlechromelabs.github.io/chrome-for-testing/known-good-versions-with-downloads.json&#39;, kwargs = {}\n\n    def get(self, url, **kwargs) -&amp;gt; Response:\n        try:\n            resp = requests.get(\n                url=url, verify=self._ssl_verify, stream=True, **kwargs)\n        except exceptions.ConnectionError:\n&amp;gt;           raise exceptions.ConnectionError(f\&#34;Could not reach host. Are you offline?\&#34;)\nE           requests.exceptions.ConnectionError: Could not reach host. Are you offline?\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\core\\http.py:35: ConnectionError\n&#34;}], &#34;Single_bucket_sim.py::test_login&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Error&#34;, &#34;testId&#34;: &#34;Single_bucket_sim.py::test_login::setup&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Error&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;Single_bucket_sim.py::test_login::setup&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;\n\n    def _new_conn(self):\n        \&#34;\&#34;\&#34;Establish a socket connection and set nodelay settings on it.\n    \n        :return: New socket connection.\n        \&#34;\&#34;\&#34;\n        extra_kw = {}\n        if self.source_address:\n            extra_kw[\&#34;source_address\&#34;] = self.source_address\n    \n        if self.socket_options:\n            extra_kw[\&#34;socket_options\&#34;] = self.socket_options\n    \n        try:\n&amp;gt;           conn = connection.create_connection(\n                (self._dns_host, self.port), self.timeout, **extra_kw\n            )\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connection.py:174: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\util\\connection.py:72: in create_connection\n    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nhost = &#39;googlechromelabs.github.io&#39;, port = 443, family = &amp;lt;AddressFamily.AF_UNSPEC: 0&amp;gt;, type = &amp;lt;SocketKind.SOCK_STREAM: 1&amp;gt;, proto = 0, flags = 0\n\n    def getaddrinfo(host, port, family=0, type=0, proto=0, flags=0):\n        \&#34;\&#34;\&#34;Resolve host and port into list of address info entries.\n    \n        Translate the host/port argument into a sequence of 5-tuples that contain\n        all the necessary arguments for creating a socket connected to that service.\n        host is a domain name, a string representation of an IPv4/v6 address or\n        None. port is a string service name such as &#39;http&#39;, a numeric port number or\n        None. By passing None as the value of host and port, you can pass NULL to\n        the underlying C API.\n    \n        The family, type and proto arguments can be optionally specified in order to\n        narrow the list of addresses returned. Passing zero as a value for each of\n        these arguments selects the full range of results.\n        \&#34;\&#34;\&#34;\n        # We override this function since we want to translate the numeric family\n        # and socket type values to enum constants.\n        addrlist = []\n&amp;gt;       for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\nE       socket.gaierror: [Errno 11001] getaddrinfo failed\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\socket.py:962: gaierror\n\nDuring handling of the above exception, another exception occurred:\n\nself = &amp;lt;urllib3.connectionpool.HTTPSConnectionPool object at 0x000002487F354910&amp;gt;, method = &#39;GET&#39;, url = &#39;/chrome-for-testing/known-good-versions-with-downloads.json&#39;\nbody = None, headers = {&#39;User-Agent&#39;: &#39;python-requests/2.27.1&#39;, &#39;Accept-Encoding&#39;: &#39;gzip, deflate&#39;, &#39;Accept&#39;: &#39;*/*&#39;, &#39;Connection&#39;: &#39;keep-alive&#39;}\nretries = Retry(total=0, connect=None, read=False, redirect=None, status=None), redirect = False, assert_same_host = False\ntimeout = Timeout(connect=None, read=None, total=None), pool_timeout = None, release_conn = False, chunked = False, body_pos = None\nresponse_kw = {&#39;decode_content&#39;: False, &#39;preload_content&#39;: False}\nparsed_url = Url(scheme=None, auth=None, host=None, port=None, path=&#39;/chrome-for-testing/known-good-versions-with-downloads.json&#39;, query=None, fragment=None)\ndestination_scheme = None, conn = None, release_this_conn = True, http_tunnel_required = False, err = None, clean_exit = False\n\n    def urlopen(\n        self,\n        method,\n        url,\n        body=None,\n        headers=None,\n        retries=None,\n        redirect=True,\n        assert_same_host=True,\n        timeout=_Default,\n        pool_timeout=None,\n        release_conn=None,\n        chunked=False,\n        body_pos=None,\n        **response_kw\n    ):\n        \&#34;\&#34;\&#34;\n        Get a connection from the pool and perform an HTTP request. This is the\n        lowest level call for making a request, so you&#39;ll need to specify all\n        the raw details.\n    \n        .. note::\n    \n           More commonly, it&#39;s appropriate to use a convenience method provided\n           by :class:`.RequestMethods`, such as :meth:`request`.\n    \n        .. note::\n    \n           `release_conn` will only behave as expected if\n           `preload_content=False` because we want to make\n           `preload_content=False` the default behaviour someday soon without\n           breaking backwards compatibility.\n    \n        :param method:\n            HTTP request method (such as GET, POST, PUT, etc.)\n    \n        :param url:\n            The URL to perform the request on.\n    \n        :param body:\n            Data to send in the request body, either :class:`str`, :class:`bytes`,\n            an iterable of :class:`str`/:class:`bytes`, or a file-like object.\n    \n        :param headers:\n            Dictionary of custom headers to send, such as User-Agent,\n            If-None-Match, etc. If None, pool headers are used. If provided,\n            these headers completely replace any pool-specific headers.\n    \n        :param retries:\n            Configure the number of retries to allow before raising a\n            :class:`~urllib3.exceptions.MaxRetryError` exception.\n    \n            Pass ``None`` to retry until you receive a response. Pass a\n            :class:`~urllib3.util.retry.Retry` object for fine-grained control\n            over different types of retries.\n            Pass an integer number to retry connection errors that many times,\n            but no other types of errors. Pass zero to never retry.\n    \n            If ``False``, then retries are disabled and any exception is raised\n            immediately. Also, instead of raising a MaxRetryError on redirects,\n            the redirect response will be returned.\n    \n        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.\n    \n        :param redirect:\n            If True, automatically handle redirects (status codes 301, 302,\n            303, 307, 308). Each redirect counts as a retry. Disabling retries\n            will disable redirect, too.\n    \n        :param assert_same_host:\n            If ``True``, will make sure that the host of the pool requests is\n            consistent else will raise HostChangedError. When ``False``, you can\n            use the pool on an HTTP proxy and request foreign hosts.\n    \n        :param timeout:\n            If specified, overrides the default timeout for this one\n            request. It may be a float (in seconds) or an instance of\n            :class:`urllib3.util.Timeout`.\n    \n        :param pool_timeout:\n            If set and the pool is set to block=True, then this method will\n            block for ``pool_timeout`` seconds and raise EmptyPoolError if no\n            connection is available within the time period.\n    \n        :param release_conn:\n            If False, then the urlopen call will not release the connection\n            back into the pool once a response is received (but will release if\n            you read the entire contents of the response such as when\n            `preload_content=True`). This is useful if you&#39;re not preloading\n            the response&#39;s content immediately. You will need to call\n            ``r.release_conn()`` on the response ``r`` to return the connection\n            back into the pool. If None, it takes the value of\n            ``response_kw.get(&#39;preload_content&#39;, True)``.\n    \n        :param chunked:\n            If True, urllib3 will send the body using chunked transfer\n            encoding. Otherwise, urllib3 will send the body using the standard\n            content-length form. Defaults to False.\n    \n        :param int body_pos:\n            Position to seek to in file-like body in the event of a retry or\n            redirect. Typically this won&#39;t need to be set because urllib3 will\n            auto-populate the value when needed.\n    \n        :param \\\\**response_kw:\n            Additional parameters are passed to\n            :meth:`urllib3.response.HTTPResponse.from_httplib`\n        \&#34;\&#34;\&#34;\n    \n        parsed_url = parse_url(url)\n        destination_scheme = parsed_url.scheme\n    \n        if headers is None:\n            headers = self.headers\n    \n        if not isinstance(retries, Retry):\n            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)\n    \n        if release_conn is None:\n            release_conn = response_kw.get(\&#34;preload_content\&#34;, True)\n    \n        # Check host\n        if assert_same_host and not self.is_same_host(url):\n            raise HostChangedError(self, url, retries)\n    \n        # Ensure that the URL we&#39;re connecting to is properly encoded\n        if url.startswith(\&#34;/\&#34;):\n            url = six.ensure_str(_encode_target(url))\n        else:\n            url = six.ensure_str(parsed_url.url)\n    \n        conn = None\n    \n        # Track whether `conn` needs to be released before\n        # returning/raising/recursing. Update this variable if necessary, and\n        # leave `release_conn` constant throughout the function. That way, if\n        # the function recurses, the original value of `release_conn` will be\n        # passed down into the recursive call, and its value will be respected.\n        #\n        # See issue #651 [1] for details.\n        #\n        # [1] &amp;lt;https://github.com/urllib3/urllib3/issues/651&amp;gt;\n        release_this_conn = release_conn\n    \n        http_tunnel_required = connection_requires_http_tunnel(\n            self.proxy, self.proxy_config, destination_scheme\n        )\n    \n        # Merge the proxy headers. Only done when not using HTTP CONNECT. We\n        # have to copy the headers dict so we can safely change it without those\n        # changes being reflected in anyone else&#39;s copy.\n        if not http_tunnel_required:\n            headers = headers.copy()\n            headers.update(self.proxy_headers)\n    \n        # Must keep the exception bound to a separate variable or else Python 3\n        # complains about UnboundLocalError.\n        err = None\n    \n        # Keep track of whether we cleanly exited the except block. This\n        # ensures we do proper cleanup in finally.\n        clean_exit = False\n    \n        # Rewind body position, if needed. Record current position\n        # for future rewinds in the event of a redirect/retry.\n        body_pos = set_file_position(body, body_pos)\n    \n        try:\n            # Request a connection from the queue.\n            timeout_obj = self._get_timeout(timeout)\n            conn = self._get_conn(timeout=pool_timeout)\n    \n            conn.timeout = timeout_obj.connect_timeout\n    \n            is_new_proxy_conn = self.proxy is not None and not getattr(\n                conn, \&#34;sock\&#34;, None\n            )\n            if is_new_proxy_conn and http_tunnel_required:\n                self._prepare_proxy(conn)\n    \n            # Make the request on the httplib connection object.\n&amp;gt;           httplib_response = self._make_request(\n                conn,\n                method,\n                url,\n                timeout=timeout_obj,\n                body=body,\n                headers=headers,\n                chunked=chunked,\n            )\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:715: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:404: in _make_request\n    self._validate_conn(conn)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1058: in _validate_conn\n    conn.connect()\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connection.py:363: in connect\n    self.sock = conn = self._new_conn()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;\n\n    def _new_conn(self):\n        \&#34;\&#34;\&#34;Establish a socket connection and set nodelay settings on it.\n    \n        :return: New socket connection.\n        \&#34;\&#34;\&#34;\n        extra_kw = {}\n        if self.source_address:\n            extra_kw[\&#34;source_address\&#34;] = self.source_address\n    \n        if self.socket_options:\n            extra_kw[\&#34;socket_options\&#34;] = self.socket_options\n    \n        try:\n            conn = connection.create_connection(\n                (self._dns_host, self.port), self.timeout, **extra_kw\n            )\n    \n        except SocketTimeout:\n            raise ConnectTimeoutError(\n                self,\n                \&#34;Connection to %s timed out. (connect timeout=%s)\&#34;\n                % (self.host, self.timeout),\n            )\n    \n        except SocketError as e:\n&amp;gt;           raise NewConnectionError(\n                self, \&#34;Failed to establish a new connection: %s\&#34; % e\n            )\nE           urllib3.exceptions.NewConnectionError: &amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;: Failed to establish a new connection: [Errno 11001] getaddrinfo failed\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connection.py:186: NewConnectionError\n\nDuring handling of the above exception, another exception occurred:\n\nself = &amp;lt;requests.adapters.HTTPAdapter object at 0x000002487F34AA10&amp;gt;, request = &amp;lt;PreparedRequest [GET]&amp;gt;, stream = True, timeout = Timeout(connect=None, read=None, total=None)\nverify = True, cert = None, proxies = OrderedDict()\n\n    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):\n        \&#34;\&#34;\&#34;Sends PreparedRequest object. Returns Response object.\n    \n        :param request: The :class:`PreparedRequest &amp;lt;PreparedRequest&amp;gt;` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) &amp;lt;timeouts&amp;gt;` tuple.\n        :type timeout: float or tuple or urllib3 Timeout object\n        :param verify: (optional) Either a boolean, in which case it controls whether\n            we verify the server&#39;s TLS certificate, or a string, in which case it\n            must be a path to a CA bundle to use\n        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        :rtype: requests.Response\n        \&#34;\&#34;\&#34;\n    \n        try:\n            conn = self.get_connection(request.url, proxies)\n        except LocationValueError as e:\n            raise InvalidURL(e, request=request)\n    \n        self.cert_verify(conn, request.url, verify, cert)\n        url = self.request_url(request, proxies)\n        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)\n    \n        chunked = not (request.body is None or &#39;Content-Length&#39; in request.headers)\n    \n        if isinstance(timeout, tuple):\n            try:\n                connect, read = timeout\n                timeout = TimeoutSauce(connect=connect, read=read)\n            except ValueError as e:\n                # this may raise a string formatting error.\n                err = (\&#34;Invalid timeout {}. Pass a (connect, read) \&#34;\n                       \&#34;timeout tuple, or a single float to set \&#34;\n                       \&#34;both timeouts to the same value\&#34;.format(timeout))\n                raise ValueError(err)\n        elif isinstance(timeout, TimeoutSauce):\n            pass\n        else:\n            timeout = TimeoutSauce(connect=timeout, read=timeout)\n    \n        try:\n            if not chunked:\n&amp;gt;               resp = conn.urlopen(\n                    method=request.method,\n                    url=url,\n                    body=request.body,\n                    headers=request.headers,\n                    redirect=False,\n                    assert_same_host=False,\n                    preload_content=False,\n                    decode_content=False,\n                    retries=self.max_retries,\n                    timeout=timeout\n                )\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\adapters.py:440: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:799: in urlopen\n    retries = retries.increment(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = Retry(total=0, connect=None, read=False, redirect=None, status=None), method = &#39;GET&#39;, url = &#39;/chrome-for-testing/known-good-versions-with-downloads.json&#39;\nresponse = None\nerror = NewConnectionError(&#39;&amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;: Failed to establish a new connection: [Errno 11001] getaddrinfo failed&#39;)\n_pool = &amp;lt;urllib3.connectionpool.HTTPSConnectionPool object at 0x000002487F354910&amp;gt;, _stacktrace = &amp;lt;traceback object at 0x000002487F354FC0&amp;gt;\n\n    def increment(\n        self,\n        method=None,\n        url=None,\n        response=None,\n        error=None,\n        _pool=None,\n        _stacktrace=None,\n    ):\n        \&#34;\&#34;\&#34;Return a new Retry object with incremented retry counters.\n    \n        :param response: A response object, or None, if the server did not\n            return a response.\n        :type response: :class:`~urllib3.response.HTTPResponse`\n        :param Exception error: An error encountered during the request, or\n            None if the response was received successfully.\n    \n        :return: A new ``Retry`` object.\n        \&#34;\&#34;\&#34;\n        if self.total is False and error:\n            # Disabled, indicate to re-raise the error.\n            raise six.reraise(type(error), error, _stacktrace)\n    \n        total = self.total\n        if total is not None:\n            total -= 1\n    \n        connect = self.connect\n        read = self.read\n        redirect = self.redirect\n        status_count = self.status\n        other = self.other\n        cause = \&#34;unknown\&#34;\n        status = None\n        redirect_location = None\n    \n        if error and self._is_connection_error(error):\n            # Connect retry?\n            if connect is False:\n                raise six.reraise(type(error), error, _stacktrace)\n            elif connect is not None:\n                connect -= 1\n    \n        elif error and self._is_read_error(error):\n            # Read retry?\n            if read is False or not self._is_method_retryable(method):\n                raise six.reraise(type(error), error, _stacktrace)\n            elif read is not None:\n                read -= 1\n    \n        elif error:\n            # Other retry?\n            if other is not None:\n                other -= 1\n    \n        elif response and response.get_redirect_location():\n            # Redirect retry?\n            if redirect is not None:\n                redirect -= 1\n            cause = \&#34;too many redirects\&#34;\n            redirect_location = response.get_redirect_location()\n            status = response.status\n    \n        else:\n            # Incrementing because of a server error like a 500 in\n            # status_forcelist and the given method is in the allowed_methods\n            cause = ResponseError.GENERIC_ERROR\n            if response and response.status:\n                if status_count is not None:\n                    status_count -= 1\n                cause = ResponseError.SPECIFIC_ERROR.format(status_code=response.status)\n                status = response.status\n    \n        history = self.history + (\n            RequestHistory(method, url, error, status, redirect_location),\n        )\n    \n        new_retry = self.new(\n            total=total,\n            connect=connect,\n            read=read,\n            redirect=redirect,\n            status=status_count,\n            other=other,\n            history=history,\n        )\n    \n        if new_retry.is_exhausted():\n&amp;gt;           raise MaxRetryError(_pool, url, error or ResponseError(cause))\nE           urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host=&#39;googlechromelabs.github.io&#39;, port=443): Max retries exceeded with url: /chrome-for-testing/known-good-versions-with-downloads.json (Caused by NewConnectionError(&#39;&amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;: Failed to establish a new connection: [Errno 11001] getaddrinfo failed&#39;))\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\util\\retry.py:592: MaxRetryError\n\nDuring handling of the above exception, another exception occurred:\n\nself = &amp;lt;webdriver_manager.core.http.WDMHttpClient object at 0x000002487F2E6990&amp;gt;\nurl = &#39;https://googlechromelabs.github.io/chrome-for-testing/known-good-versions-with-downloads.json&#39;, kwargs = {}\n\n    def get(self, url, **kwargs) -&amp;gt; Response:\n        try:\n&amp;gt;           resp = requests.get(\n                url=url, verify=self._ssl_verify, stream=True, **kwargs)\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\core\\http.py:32: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\api.py:75: in get\n    return request(&#39;get&#39;, url, params=params, **kwargs)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\api.py:61: in request\n    return session.request(method=method, url=url, **kwargs)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\sessions.py:529: in request\n    resp = self.send(prep, **send_kwargs)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\sessions.py:645: in send\n    r = adapter.send(request, **kwargs)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;requests.adapters.HTTPAdapter object at 0x000002487F34AA10&amp;gt;, request = &amp;lt;PreparedRequest [GET]&amp;gt;, stream = True, timeout = Timeout(connect=None, read=None, total=None)\nverify = True, cert = None, proxies = OrderedDict()\n\n    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):\n        \&#34;\&#34;\&#34;Sends PreparedRequest object. Returns Response object.\n    \n        :param request: The :class:`PreparedRequest &amp;lt;PreparedRequest&amp;gt;` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) &amp;lt;timeouts&amp;gt;` tuple.\n        :type timeout: float or tuple or urllib3 Timeout object\n        :param verify: (optional) Either a boolean, in which case it controls whether\n            we verify the server&#39;s TLS certificate, or a string, in which case it\n            must be a path to a CA bundle to use\n        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        :rtype: requests.Response\n        \&#34;\&#34;\&#34;\n    \n        try:\n            conn = self.get_connection(request.url, proxies)\n        except LocationValueError as e:\n            raise InvalidURL(e, request=request)\n    \n        self.cert_verify(conn, request.url, verify, cert)\n        url = self.request_url(request, proxies)\n        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)\n    \n        chunked = not (request.body is None or &#39;Content-Length&#39; in request.headers)\n    \n        if isinstance(timeout, tuple):\n            try:\n                connect, read = timeout\n                timeout = TimeoutSauce(connect=connect, read=read)\n            except ValueError as e:\n                # this may raise a string formatting error.\n                err = (\&#34;Invalid timeout {}. Pass a (connect, read) \&#34;\n                       \&#34;timeout tuple, or a single float to set \&#34;\n                       \&#34;both timeouts to the same value\&#34;.format(timeout))\n                raise ValueError(err)\n        elif isinstance(timeout, TimeoutSauce):\n            pass\n        else:\n            timeout = TimeoutSauce(connect=timeout, read=timeout)\n    \n        try:\n            if not chunked:\n                resp = conn.urlopen(\n                    method=request.method,\n                    url=url,\n                    body=request.body,\n                    headers=request.headers,\n                    redirect=False,\n                    assert_same_host=False,\n                    preload_content=False,\n                    decode_content=False,\n                    retries=self.max_retries,\n                    timeout=timeout\n                )\n    \n            # Send the request.\n            else:\n                if hasattr(conn, &#39;proxy_pool&#39;):\n                    conn = conn.proxy_pool\n    \n                low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)\n    \n                try:\n                    skip_host = &#39;Host&#39; in request.headers\n                    low_conn.putrequest(request.method,\n                                        url,\n                                        skip_accept_encoding=True,\n                                        skip_host=skip_host)\n    \n                    for header, value in request.headers.items():\n                        low_conn.putheader(header, value)\n    \n                    low_conn.endheaders()\n    \n                    for i in request.body:\n                        low_conn.send(hex(len(i))[2:].encode(&#39;utf-8&#39;))\n                        low_conn.send(b&#39;\\r\\n&#39;)\n                        low_conn.send(i)\n                        low_conn.send(b&#39;\\r\\n&#39;)\n                    low_conn.send(b&#39;0\\r\\n\\r\\n&#39;)\n    \n                    # Receive the response from the server\n                    try:\n                        # For Python 2.7, use buffering of HTTP responses\n                        r = low_conn.getresponse(buffering=True)\n                    except TypeError:\n                        # For compatibility with Python 3.3+\n                        r = low_conn.getresponse()\n    \n                    resp = HTTPResponse.from_httplib(\n                        r,\n                        pool=conn,\n                        connection=low_conn,\n                        preload_content=False,\n                        decode_content=False\n                    )\n                except:\n                    # If we hit any problems here, clean up the connection.\n                    # Then, reraise so that we can handle the actual exception.\n                    low_conn.close()\n                    raise\n    \n        except (ProtocolError, socket.error) as err:\n            raise ConnectionError(err, request=request)\n    \n        except MaxRetryError as e:\n            if isinstance(e.reason, ConnectTimeoutError):\n                # TODO: Remove this in 3.0.0: see #2811\n                if not isinstance(e.reason, NewConnectionError):\n                    raise ConnectTimeout(e, request=request)\n    \n            if isinstance(e.reason, ResponseError):\n                raise RetryError(e, request=request)\n    \n            if isinstance(e.reason, _ProxyError):\n                raise ProxyError(e, request=request)\n    \n            if isinstance(e.reason, _SSLError):\n                # This branch is for urllib3 v1.22 and later.\n                raise SSLError(e, request=request)\n    \n&amp;gt;           raise ConnectionError(e, request=request)\nE           requests.exceptions.ConnectionError: HTTPSConnectionPool(host=&#39;googlechromelabs.github.io&#39;, port=443): Max retries exceeded with url: /chrome-for-testing/known-good-versions-with-downloads.json (Caused by NewConnectionError(&#39;&amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;: Failed to establish a new connection: [Errno 11001] getaddrinfo failed&#39;))\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\adapters.py:519: ConnectionError\n\nDuring handling of the above exception, another exception occurred:\n\n    @pytest.fixture(scope=\&#34;module\&#34;)\n    def driver():\n        options = Options()\n        options.add_experimental_option(\&#34;detach\&#34;, True)\n        #driver = webdriver.Chrome(options=options)\n&amp;gt;       driver = webdriver.Chrome(options=options, service=Service(ChromeDriverManager().install()))\n\nSingle_bucket_sim.py:27: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\chrome.py:40: in install\n    driver_path = self._get_driver_binary_path(self.driver)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\core\\manager.py:40: in _get_driver_binary_path\n    file = self._download_manager.download_file(driver.get_driver_download_url(os_type))\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\drivers\\chrome.py:44: in get_driver_download_url\n    modern_version_url = self.get_url_for_version_and_platform(driver_version_to_download, os_type)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\drivers\\chrome.py:69: in get_url_for_version_and_platform\n    response = self._http_client.get(url)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;webdriver_manager.core.http.WDMHttpClient object at 0x000002487F2E6990&amp;gt;\nurl = &#39;https://googlechromelabs.github.io/chrome-for-testing/known-good-versions-with-downloads.json&#39;, kwargs = {}\n\n    def get(self, url, **kwargs) -&amp;gt; Response:\n        try:\n            resp = requests.get(\n                url=url, verify=self._ssl_verify, stream=True, **kwargs)\n        except exceptions.ConnectionError:\n&amp;gt;           raise exceptions.ConnectionError(f\&#34;Could not reach host. Are you offline?\&#34;)\nE           requests.exceptions.ConnectionError: Could not reach host. Are you offline?\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\core\\http.py:35: ConnectionError\n&#34;}], &#34;Single_bucket_sim.py::test_simulation_name&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Error&#34;, &#34;testId&#34;: &#34;Single_bucket_sim.py::test_simulation_name::setup&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Error&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;Single_bucket_sim.py::test_simulation_name::setup&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;\n\n    def _new_conn(self):\n        \&#34;\&#34;\&#34;Establish a socket connection and set nodelay settings on it.\n    \n        :return: New socket connection.\n        \&#34;\&#34;\&#34;\n        extra_kw = {}\n        if self.source_address:\n            extra_kw[\&#34;source_address\&#34;] = self.source_address\n    \n        if self.socket_options:\n            extra_kw[\&#34;socket_options\&#34;] = self.socket_options\n    \n        try:\n&amp;gt;           conn = connection.create_connection(\n                (self._dns_host, self.port), self.timeout, **extra_kw\n            )\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connection.py:174: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\util\\connection.py:72: in create_connection\n    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nhost = &#39;googlechromelabs.github.io&#39;, port = 443, family = &amp;lt;AddressFamily.AF_UNSPEC: 0&amp;gt;, type = &amp;lt;SocketKind.SOCK_STREAM: 1&amp;gt;, proto = 0, flags = 0\n\n    def getaddrinfo(host, port, family=0, type=0, proto=0, flags=0):\n        \&#34;\&#34;\&#34;Resolve host and port into list of address info entries.\n    \n        Translate the host/port argument into a sequence of 5-tuples that contain\n        all the necessary arguments for creating a socket connected to that service.\n        host is a domain name, a string representation of an IPv4/v6 address or\n        None. port is a string service name such as &#39;http&#39;, a numeric port number or\n        None. By passing None as the value of host and port, you can pass NULL to\n        the underlying C API.\n    \n        The family, type and proto arguments can be optionally specified in order to\n        narrow the list of addresses returned. Passing zero as a value for each of\n        these arguments selects the full range of results.\n        \&#34;\&#34;\&#34;\n        # We override this function since we want to translate the numeric family\n        # and socket type values to enum constants.\n        addrlist = []\n&amp;gt;       for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\nE       socket.gaierror: [Errno 11001] getaddrinfo failed\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\socket.py:962: gaierror\n\nDuring handling of the above exception, another exception occurred:\n\nself = &amp;lt;urllib3.connectionpool.HTTPSConnectionPool object at 0x000002487F354910&amp;gt;, method = &#39;GET&#39;, url = &#39;/chrome-for-testing/known-good-versions-with-downloads.json&#39;\nbody = None, headers = {&#39;User-Agent&#39;: &#39;python-requests/2.27.1&#39;, &#39;Accept-Encoding&#39;: &#39;gzip, deflate&#39;, &#39;Accept&#39;: &#39;*/*&#39;, &#39;Connection&#39;: &#39;keep-alive&#39;}\nretries = Retry(total=0, connect=None, read=False, redirect=None, status=None), redirect = False, assert_same_host = False\ntimeout = Timeout(connect=None, read=None, total=None), pool_timeout = None, release_conn = False, chunked = False, body_pos = None\nresponse_kw = {&#39;decode_content&#39;: False, &#39;preload_content&#39;: False}\nparsed_url = Url(scheme=None, auth=None, host=None, port=None, path=&#39;/chrome-for-testing/known-good-versions-with-downloads.json&#39;, query=None, fragment=None)\ndestination_scheme = None, conn = None, release_this_conn = True, http_tunnel_required = False, err = None, clean_exit = False\n\n    def urlopen(\n        self,\n        method,\n        url,\n        body=None,\n        headers=None,\n        retries=None,\n        redirect=True,\n        assert_same_host=True,\n        timeout=_Default,\n        pool_timeout=None,\n        release_conn=None,\n        chunked=False,\n        body_pos=None,\n        **response_kw\n    ):\n        \&#34;\&#34;\&#34;\n        Get a connection from the pool and perform an HTTP request. This is the\n        lowest level call for making a request, so you&#39;ll need to specify all\n        the raw details.\n    \n        .. note::\n    \n           More commonly, it&#39;s appropriate to use a convenience method provided\n           by :class:`.RequestMethods`, such as :meth:`request`.\n    \n        .. note::\n    \n           `release_conn` will only behave as expected if\n           `preload_content=False` because we want to make\n           `preload_content=False` the default behaviour someday soon without\n           breaking backwards compatibility.\n    \n        :param method:\n            HTTP request method (such as GET, POST, PUT, etc.)\n    \n        :param url:\n            The URL to perform the request on.\n    \n        :param body:\n            Data to send in the request body, either :class:`str`, :class:`bytes`,\n            an iterable of :class:`str`/:class:`bytes`, or a file-like object.\n    \n        :param headers:\n            Dictionary of custom headers to send, such as User-Agent,\n            If-None-Match, etc. If None, pool headers are used. If provided,\n            these headers completely replace any pool-specific headers.\n    \n        :param retries:\n            Configure the number of retries to allow before raising a\n            :class:`~urllib3.exceptions.MaxRetryError` exception.\n    \n            Pass ``None`` to retry until you receive a response. Pass a\n            :class:`~urllib3.util.retry.Retry` object for fine-grained control\n            over different types of retries.\n            Pass an integer number to retry connection errors that many times,\n            but no other types of errors. Pass zero to never retry.\n    \n            If ``False``, then retries are disabled and any exception is raised\n            immediately. Also, instead of raising a MaxRetryError on redirects,\n            the redirect response will be returned.\n    \n        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.\n    \n        :param redirect:\n            If True, automatically handle redirects (status codes 301, 302,\n            303, 307, 308). Each redirect counts as a retry. Disabling retries\n            will disable redirect, too.\n    \n        :param assert_same_host:\n            If ``True``, will make sure that the host of the pool requests is\n            consistent else will raise HostChangedError. When ``False``, you can\n            use the pool on an HTTP proxy and request foreign hosts.\n    \n        :param timeout:\n            If specified, overrides the default timeout for this one\n            request. It may be a float (in seconds) or an instance of\n            :class:`urllib3.util.Timeout`.\n    \n        :param pool_timeout:\n            If set and the pool is set to block=True, then this method will\n            block for ``pool_timeout`` seconds and raise EmptyPoolError if no\n            connection is available within the time period.\n    \n        :param release_conn:\n            If False, then the urlopen call will not release the connection\n            back into the pool once a response is received (but will release if\n            you read the entire contents of the response such as when\n            `preload_content=True`). This is useful if you&#39;re not preloading\n            the response&#39;s content immediately. You will need to call\n            ``r.release_conn()`` on the response ``r`` to return the connection\n            back into the pool. If None, it takes the value of\n            ``response_kw.get(&#39;preload_content&#39;, True)``.\n    \n        :param chunked:\n            If True, urllib3 will send the body using chunked transfer\n            encoding. Otherwise, urllib3 will send the body using the standard\n            content-length form. Defaults to False.\n    \n        :param int body_pos:\n            Position to seek to in file-like body in the event of a retry or\n            redirect. Typically this won&#39;t need to be set because urllib3 will\n            auto-populate the value when needed.\n    \n        :param \\\\**response_kw:\n            Additional parameters are passed to\n            :meth:`urllib3.response.HTTPResponse.from_httplib`\n        \&#34;\&#34;\&#34;\n    \n        parsed_url = parse_url(url)\n        destination_scheme = parsed_url.scheme\n    \n        if headers is None:\n            headers = self.headers\n    \n        if not isinstance(retries, Retry):\n            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)\n    \n        if release_conn is None:\n            release_conn = response_kw.get(\&#34;preload_content\&#34;, True)\n    \n        # Check host\n        if assert_same_host and not self.is_same_host(url):\n            raise HostChangedError(self, url, retries)\n    \n        # Ensure that the URL we&#39;re connecting to is properly encoded\n        if url.startswith(\&#34;/\&#34;):\n            url = six.ensure_str(_encode_target(url))\n        else:\n            url = six.ensure_str(parsed_url.url)\n    \n        conn = None\n    \n        # Track whether `conn` needs to be released before\n        # returning/raising/recursing. Update this variable if necessary, and\n        # leave `release_conn` constant throughout the function. That way, if\n        # the function recurses, the original value of `release_conn` will be\n        # passed down into the recursive call, and its value will be respected.\n        #\n        # See issue #651 [1] for details.\n        #\n        # [1] &amp;lt;https://github.com/urllib3/urllib3/issues/651&amp;gt;\n        release_this_conn = release_conn\n    \n        http_tunnel_required = connection_requires_http_tunnel(\n            self.proxy, self.proxy_config, destination_scheme\n        )\n    \n        # Merge the proxy headers. Only done when not using HTTP CONNECT. We\n        # have to copy the headers dict so we can safely change it without those\n        # changes being reflected in anyone else&#39;s copy.\n        if not http_tunnel_required:\n            headers = headers.copy()\n            headers.update(self.proxy_headers)\n    \n        # Must keep the exception bound to a separate variable or else Python 3\n        # complains about UnboundLocalError.\n        err = None\n    \n        # Keep track of whether we cleanly exited the except block. This\n        # ensures we do proper cleanup in finally.\n        clean_exit = False\n    \n        # Rewind body position, if needed. Record current position\n        # for future rewinds in the event of a redirect/retry.\n        body_pos = set_file_position(body, body_pos)\n    \n        try:\n            # Request a connection from the queue.\n            timeout_obj = self._get_timeout(timeout)\n            conn = self._get_conn(timeout=pool_timeout)\n    \n            conn.timeout = timeout_obj.connect_timeout\n    \n            is_new_proxy_conn = self.proxy is not None and not getattr(\n                conn, \&#34;sock\&#34;, None\n            )\n            if is_new_proxy_conn and http_tunnel_required:\n                self._prepare_proxy(conn)\n    \n            # Make the request on the httplib connection object.\n&amp;gt;           httplib_response = self._make_request(\n                conn,\n                method,\n                url,\n                timeout=timeout_obj,\n                body=body,\n                headers=headers,\n                chunked=chunked,\n            )\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:715: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:404: in _make_request\n    self._validate_conn(conn)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1058: in _validate_conn\n    conn.connect()\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connection.py:363: in connect\n    self.sock = conn = self._new_conn()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;\n\n    def _new_conn(self):\n        \&#34;\&#34;\&#34;Establish a socket connection and set nodelay settings on it.\n    \n        :return: New socket connection.\n        \&#34;\&#34;\&#34;\n        extra_kw = {}\n        if self.source_address:\n            extra_kw[\&#34;source_address\&#34;] = self.source_address\n    \n        if self.socket_options:\n            extra_kw[\&#34;socket_options\&#34;] = self.socket_options\n    \n        try:\n            conn = connection.create_connection(\n                (self._dns_host, self.port), self.timeout, **extra_kw\n            )\n    \n        except SocketTimeout:\n            raise ConnectTimeoutError(\n                self,\n                \&#34;Connection to %s timed out. (connect timeout=%s)\&#34;\n                % (self.host, self.timeout),\n            )\n    \n        except SocketError as e:\n&amp;gt;           raise NewConnectionError(\n                self, \&#34;Failed to establish a new connection: %s\&#34; % e\n            )\nE           urllib3.exceptions.NewConnectionError: &amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;: Failed to establish a new connection: [Errno 11001] getaddrinfo failed\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connection.py:186: NewConnectionError\n\nDuring handling of the above exception, another exception occurred:\n\nself = &amp;lt;requests.adapters.HTTPAdapter object at 0x000002487F34AA10&amp;gt;, request = &amp;lt;PreparedRequest [GET]&amp;gt;, stream = True, timeout = Timeout(connect=None, read=None, total=None)\nverify = True, cert = None, proxies = OrderedDict()\n\n    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):\n        \&#34;\&#34;\&#34;Sends PreparedRequest object. Returns Response object.\n    \n        :param request: The :class:`PreparedRequest &amp;lt;PreparedRequest&amp;gt;` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) &amp;lt;timeouts&amp;gt;` tuple.\n        :type timeout: float or tuple or urllib3 Timeout object\n        :param verify: (optional) Either a boolean, in which case it controls whether\n            we verify the server&#39;s TLS certificate, or a string, in which case it\n            must be a path to a CA bundle to use\n        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        :rtype: requests.Response\n        \&#34;\&#34;\&#34;\n    \n        try:\n            conn = self.get_connection(request.url, proxies)\n        except LocationValueError as e:\n            raise InvalidURL(e, request=request)\n    \n        self.cert_verify(conn, request.url, verify, cert)\n        url = self.request_url(request, proxies)\n        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)\n    \n        chunked = not (request.body is None or &#39;Content-Length&#39; in request.headers)\n    \n        if isinstance(timeout, tuple):\n            try:\n                connect, read = timeout\n                timeout = TimeoutSauce(connect=connect, read=read)\n            except ValueError as e:\n                # this may raise a string formatting error.\n                err = (\&#34;Invalid timeout {}. Pass a (connect, read) \&#34;\n                       \&#34;timeout tuple, or a single float to set \&#34;\n                       \&#34;both timeouts to the same value\&#34;.format(timeout))\n                raise ValueError(err)\n        elif isinstance(timeout, TimeoutSauce):\n            pass\n        else:\n            timeout = TimeoutSauce(connect=timeout, read=timeout)\n    \n        try:\n            if not chunked:\n&amp;gt;               resp = conn.urlopen(\n                    method=request.method,\n                    url=url,\n                    body=request.body,\n                    headers=request.headers,\n                    redirect=False,\n                    assert_same_host=False,\n                    preload_content=False,\n                    decode_content=False,\n                    retries=self.max_retries,\n                    timeout=timeout\n                )\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\adapters.py:440: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:799: in urlopen\n    retries = retries.increment(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = Retry(total=0, connect=None, read=False, redirect=None, status=None), method = &#39;GET&#39;, url = &#39;/chrome-for-testing/known-good-versions-with-downloads.json&#39;\nresponse = None\nerror = NewConnectionError(&#39;&amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;: Failed to establish a new connection: [Errno 11001] getaddrinfo failed&#39;)\n_pool = &amp;lt;urllib3.connectionpool.HTTPSConnectionPool object at 0x000002487F354910&amp;gt;, _stacktrace = &amp;lt;traceback object at 0x000002487F354FC0&amp;gt;\n\n    def increment(\n        self,\n        method=None,\n        url=None,\n        response=None,\n        error=None,\n        _pool=None,\n        _stacktrace=None,\n    ):\n        \&#34;\&#34;\&#34;Return a new Retry object with incremented retry counters.\n    \n        :param response: A response object, or None, if the server did not\n            return a response.\n        :type response: :class:`~urllib3.response.HTTPResponse`\n        :param Exception error: An error encountered during the request, or\n            None if the response was received successfully.\n    \n        :return: A new ``Retry`` object.\n        \&#34;\&#34;\&#34;\n        if self.total is False and error:\n            # Disabled, indicate to re-raise the error.\n            raise six.reraise(type(error), error, _stacktrace)\n    \n        total = self.total\n        if total is not None:\n            total -= 1\n    \n        connect = self.connect\n        read = self.read\n        redirect = self.redirect\n        status_count = self.status\n        other = self.other\n        cause = \&#34;unknown\&#34;\n        status = None\n        redirect_location = None\n    \n        if error and self._is_connection_error(error):\n            # Connect retry?\n            if connect is False:\n                raise six.reraise(type(error), error, _stacktrace)\n            elif connect is not None:\n                connect -= 1\n    \n        elif error and self._is_read_error(error):\n            # Read retry?\n            if read is False or not self._is_method_retryable(method):\n                raise six.reraise(type(error), error, _stacktrace)\n            elif read is not None:\n                read -= 1\n    \n        elif error:\n            # Other retry?\n            if other is not None:\n                other -= 1\n    \n        elif response and response.get_redirect_location():\n            # Redirect retry?\n            if redirect is not None:\n                redirect -= 1\n            cause = \&#34;too many redirects\&#34;\n            redirect_location = response.get_redirect_location()\n            status = response.status\n    \n        else:\n            # Incrementing because of a server error like a 500 in\n            # status_forcelist and the given method is in the allowed_methods\n            cause = ResponseError.GENERIC_ERROR\n            if response and response.status:\n                if status_count is not None:\n                    status_count -= 1\n                cause = ResponseError.SPECIFIC_ERROR.format(status_code=response.status)\n                status = response.status\n    \n        history = self.history + (\n            RequestHistory(method, url, error, status, redirect_location),\n        )\n    \n        new_retry = self.new(\n            total=total,\n            connect=connect,\n            read=read,\n            redirect=redirect,\n            status=status_count,\n            other=other,\n            history=history,\n        )\n    \n        if new_retry.is_exhausted():\n&amp;gt;           raise MaxRetryError(_pool, url, error or ResponseError(cause))\nE           urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host=&#39;googlechromelabs.github.io&#39;, port=443): Max retries exceeded with url: /chrome-for-testing/known-good-versions-with-downloads.json (Caused by NewConnectionError(&#39;&amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;: Failed to establish a new connection: [Errno 11001] getaddrinfo failed&#39;))\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\util\\retry.py:592: MaxRetryError\n\nDuring handling of the above exception, another exception occurred:\n\nself = &amp;lt;webdriver_manager.core.http.WDMHttpClient object at 0x000002487F2E6990&amp;gt;\nurl = &#39;https://googlechromelabs.github.io/chrome-for-testing/known-good-versions-with-downloads.json&#39;, kwargs = {}\n\n    def get(self, url, **kwargs) -&amp;gt; Response:\n        try:\n&amp;gt;           resp = requests.get(\n                url=url, verify=self._ssl_verify, stream=True, **kwargs)\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\core\\http.py:32: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\api.py:75: in get\n    return request(&#39;get&#39;, url, params=params, **kwargs)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\api.py:61: in request\n    return session.request(method=method, url=url, **kwargs)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\sessions.py:529: in request\n    resp = self.send(prep, **send_kwargs)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\sessions.py:645: in send\n    r = adapter.send(request, **kwargs)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;requests.adapters.HTTPAdapter object at 0x000002487F34AA10&amp;gt;, request = &amp;lt;PreparedRequest [GET]&amp;gt;, stream = True, timeout = Timeout(connect=None, read=None, total=None)\nverify = True, cert = None, proxies = OrderedDict()\n\n    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):\n        \&#34;\&#34;\&#34;Sends PreparedRequest object. Returns Response object.\n    \n        :param request: The :class:`PreparedRequest &amp;lt;PreparedRequest&amp;gt;` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) &amp;lt;timeouts&amp;gt;` tuple.\n        :type timeout: float or tuple or urllib3 Timeout object\n        :param verify: (optional) Either a boolean, in which case it controls whether\n            we verify the server&#39;s TLS certificate, or a string, in which case it\n            must be a path to a CA bundle to use\n        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        :rtype: requests.Response\n        \&#34;\&#34;\&#34;\n    \n        try:\n            conn = self.get_connection(request.url, proxies)\n        except LocationValueError as e:\n            raise InvalidURL(e, request=request)\n    \n        self.cert_verify(conn, request.url, verify, cert)\n        url = self.request_url(request, proxies)\n        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)\n    \n        chunked = not (request.body is None or &#39;Content-Length&#39; in request.headers)\n    \n        if isinstance(timeout, tuple):\n            try:\n                connect, read = timeout\n                timeout = TimeoutSauce(connect=connect, read=read)\n            except ValueError as e:\n                # this may raise a string formatting error.\n                err = (\&#34;Invalid timeout {}. Pass a (connect, read) \&#34;\n                       \&#34;timeout tuple, or a single float to set \&#34;\n                       \&#34;both timeouts to the same value\&#34;.format(timeout))\n                raise ValueError(err)\n        elif isinstance(timeout, TimeoutSauce):\n            pass\n        else:\n            timeout = TimeoutSauce(connect=timeout, read=timeout)\n    \n        try:\n            if not chunked:\n                resp = conn.urlopen(\n                    method=request.method,\n                    url=url,\n                    body=request.body,\n                    headers=request.headers,\n                    redirect=False,\n                    assert_same_host=False,\n                    preload_content=False,\n                    decode_content=False,\n                    retries=self.max_retries,\n                    timeout=timeout\n                )\n    \n            # Send the request.\n            else:\n                if hasattr(conn, &#39;proxy_pool&#39;):\n                    conn = conn.proxy_pool\n    \n                low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)\n    \n                try:\n                    skip_host = &#39;Host&#39; in request.headers\n                    low_conn.putrequest(request.method,\n                                        url,\n                                        skip_accept_encoding=True,\n                                        skip_host=skip_host)\n    \n                    for header, value in request.headers.items():\n                        low_conn.putheader(header, value)\n    \n                    low_conn.endheaders()\n    \n                    for i in request.body:\n                        low_conn.send(hex(len(i))[2:].encode(&#39;utf-8&#39;))\n                        low_conn.send(b&#39;\\r\\n&#39;)\n                        low_conn.send(i)\n                        low_conn.send(b&#39;\\r\\n&#39;)\n                    low_conn.send(b&#39;0\\r\\n\\r\\n&#39;)\n    \n                    # Receive the response from the server\n                    try:\n                        # For Python 2.7, use buffering of HTTP responses\n                        r = low_conn.getresponse(buffering=True)\n                    except TypeError:\n                        # For compatibility with Python 3.3+\n                        r = low_conn.getresponse()\n    \n                    resp = HTTPResponse.from_httplib(\n                        r,\n                        pool=conn,\n                        connection=low_conn,\n                        preload_content=False,\n                        decode_content=False\n                    )\n                except:\n                    # If we hit any problems here, clean up the connection.\n                    # Then, reraise so that we can handle the actual exception.\n                    low_conn.close()\n                    raise\n    \n        except (ProtocolError, socket.error) as err:\n            raise ConnectionError(err, request=request)\n    \n        except MaxRetryError as e:\n            if isinstance(e.reason, ConnectTimeoutError):\n                # TODO: Remove this in 3.0.0: see #2811\n                if not isinstance(e.reason, NewConnectionError):\n                    raise ConnectTimeout(e, request=request)\n    \n            if isinstance(e.reason, ResponseError):\n                raise RetryError(e, request=request)\n    \n            if isinstance(e.reason, _ProxyError):\n                raise ProxyError(e, request=request)\n    \n            if isinstance(e.reason, _SSLError):\n                # This branch is for urllib3 v1.22 and later.\n                raise SSLError(e, request=request)\n    \n&amp;gt;           raise ConnectionError(e, request=request)\nE           requests.exceptions.ConnectionError: HTTPSConnectionPool(host=&#39;googlechromelabs.github.io&#39;, port=443): Max retries exceeded with url: /chrome-for-testing/known-good-versions-with-downloads.json (Caused by NewConnectionError(&#39;&amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;: Failed to establish a new connection: [Errno 11001] getaddrinfo failed&#39;))\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\adapters.py:519: ConnectionError\n\nDuring handling of the above exception, another exception occurred:\n\n    @pytest.fixture(scope=\&#34;module\&#34;)\n    def driver():\n        options = Options()\n        options.add_experimental_option(\&#34;detach\&#34;, True)\n        #driver = webdriver.Chrome(options=options)\n&amp;gt;       driver = webdriver.Chrome(options=options, service=Service(ChromeDriverManager().install()))\n\nSingle_bucket_sim.py:27: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\chrome.py:40: in install\n    driver_path = self._get_driver_binary_path(self.driver)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\core\\manager.py:40: in _get_driver_binary_path\n    file = self._download_manager.download_file(driver.get_driver_download_url(os_type))\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\drivers\\chrome.py:44: in get_driver_download_url\n    modern_version_url = self.get_url_for_version_and_platform(driver_version_to_download, os_type)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\drivers\\chrome.py:69: in get_url_for_version_and_platform\n    response = self._http_client.get(url)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;webdriver_manager.core.http.WDMHttpClient object at 0x000002487F2E6990&amp;gt;\nurl = &#39;https://googlechromelabs.github.io/chrome-for-testing/known-good-versions-with-downloads.json&#39;, kwargs = {}\n\n    def get(self, url, **kwargs) -&amp;gt; Response:\n        try:\n            resp = requests.get(\n                url=url, verify=self._ssl_verify, stream=True, **kwargs)\n        except exceptions.ConnectionError:\n&amp;gt;           raise exceptions.ConnectionError(f\&#34;Could not reach host. Are you offline?\&#34;)\nE           requests.exceptions.ConnectionError: Could not reach host. Are you offline?\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\core\\http.py:35: ConnectionError\n&#34;}], &#34;Single_bucket_sim.py::test_first_page_heading&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Error&#34;, &#34;testId&#34;: &#34;Single_bucket_sim.py::test_first_page_heading::setup&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Error&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;Single_bucket_sim.py::test_first_page_heading::setup&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;\n\n    def _new_conn(self):\n        \&#34;\&#34;\&#34;Establish a socket connection and set nodelay settings on it.\n    \n        :return: New socket connection.\n        \&#34;\&#34;\&#34;\n        extra_kw = {}\n        if self.source_address:\n            extra_kw[\&#34;source_address\&#34;] = self.source_address\n    \n        if self.socket_options:\n            extra_kw[\&#34;socket_options\&#34;] = self.socket_options\n    \n        try:\n&amp;gt;           conn = connection.create_connection(\n                (self._dns_host, self.port), self.timeout, **extra_kw\n            )\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connection.py:174: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\util\\connection.py:72: in create_connection\n    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nhost = &#39;googlechromelabs.github.io&#39;, port = 443, family = &amp;lt;AddressFamily.AF_UNSPEC: 0&amp;gt;, type = &amp;lt;SocketKind.SOCK_STREAM: 1&amp;gt;, proto = 0, flags = 0\n\n    def getaddrinfo(host, port, family=0, type=0, proto=0, flags=0):\n        \&#34;\&#34;\&#34;Resolve host and port into list of address info entries.\n    \n        Translate the host/port argument into a sequence of 5-tuples that contain\n        all the necessary arguments for creating a socket connected to that service.\n        host is a domain name, a string representation of an IPv4/v6 address or\n        None. port is a string service name such as &#39;http&#39;, a numeric port number or\n        None. By passing None as the value of host and port, you can pass NULL to\n        the underlying C API.\n    \n        The family, type and proto arguments can be optionally specified in order to\n        narrow the list of addresses returned. Passing zero as a value for each of\n        these arguments selects the full range of results.\n        \&#34;\&#34;\&#34;\n        # We override this function since we want to translate the numeric family\n        # and socket type values to enum constants.\n        addrlist = []\n&amp;gt;       for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\nE       socket.gaierror: [Errno 11001] getaddrinfo failed\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\socket.py:962: gaierror\n\nDuring handling of the above exception, another exception occurred:\n\nself = &amp;lt;urllib3.connectionpool.HTTPSConnectionPool object at 0x000002487F354910&amp;gt;, method = &#39;GET&#39;, url = &#39;/chrome-for-testing/known-good-versions-with-downloads.json&#39;\nbody = None, headers = {&#39;User-Agent&#39;: &#39;python-requests/2.27.1&#39;, &#39;Accept-Encoding&#39;: &#39;gzip, deflate&#39;, &#39;Accept&#39;: &#39;*/*&#39;, &#39;Connection&#39;: &#39;keep-alive&#39;}\nretries = Retry(total=0, connect=None, read=False, redirect=None, status=None), redirect = False, assert_same_host = False\ntimeout = Timeout(connect=None, read=None, total=None), pool_timeout = None, release_conn = False, chunked = False, body_pos = None\nresponse_kw = {&#39;decode_content&#39;: False, &#39;preload_content&#39;: False}\nparsed_url = Url(scheme=None, auth=None, host=None, port=None, path=&#39;/chrome-for-testing/known-good-versions-with-downloads.json&#39;, query=None, fragment=None)\ndestination_scheme = None, conn = None, release_this_conn = True, http_tunnel_required = False, err = None, clean_exit = False\n\n    def urlopen(\n        self,\n        method,\n        url,\n        body=None,\n        headers=None,\n        retries=None,\n        redirect=True,\n        assert_same_host=True,\n        timeout=_Default,\n        pool_timeout=None,\n        release_conn=None,\n        chunked=False,\n        body_pos=None,\n        **response_kw\n    ):\n        \&#34;\&#34;\&#34;\n        Get a connection from the pool and perform an HTTP request. This is the\n        lowest level call for making a request, so you&#39;ll need to specify all\n        the raw details.\n    \n        .. note::\n    \n           More commonly, it&#39;s appropriate to use a convenience method provided\n           by :class:`.RequestMethods`, such as :meth:`request`.\n    \n        .. note::\n    \n           `release_conn` will only behave as expected if\n           `preload_content=False` because we want to make\n           `preload_content=False` the default behaviour someday soon without\n           breaking backwards compatibility.\n    \n        :param method:\n            HTTP request method (such as GET, POST, PUT, etc.)\n    \n        :param url:\n            The URL to perform the request on.\n    \n        :param body:\n            Data to send in the request body, either :class:`str`, :class:`bytes`,\n            an iterable of :class:`str`/:class:`bytes`, or a file-like object.\n    \n        :param headers:\n            Dictionary of custom headers to send, such as User-Agent,\n            If-None-Match, etc. If None, pool headers are used. If provided,\n            these headers completely replace any pool-specific headers.\n    \n        :param retries:\n            Configure the number of retries to allow before raising a\n            :class:`~urllib3.exceptions.MaxRetryError` exception.\n    \n            Pass ``None`` to retry until you receive a response. Pass a\n            :class:`~urllib3.util.retry.Retry` object for fine-grained control\n            over different types of retries.\n            Pass an integer number to retry connection errors that many times,\n            but no other types of errors. Pass zero to never retry.\n    \n            If ``False``, then retries are disabled and any exception is raised\n            immediately. Also, instead of raising a MaxRetryError on redirects,\n            the redirect response will be returned.\n    \n        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.\n    \n        :param redirect:\n            If True, automatically handle redirects (status codes 301, 302,\n            303, 307, 308). Each redirect counts as a retry. Disabling retries\n            will disable redirect, too.\n    \n        :param assert_same_host:\n            If ``True``, will make sure that the host of the pool requests is\n            consistent else will raise HostChangedError. When ``False``, you can\n            use the pool on an HTTP proxy and request foreign hosts.\n    \n        :param timeout:\n            If specified, overrides the default timeout for this one\n            request. It may be a float (in seconds) or an instance of\n            :class:`urllib3.util.Timeout`.\n    \n        :param pool_timeout:\n            If set and the pool is set to block=True, then this method will\n            block for ``pool_timeout`` seconds and raise EmptyPoolError if no\n            connection is available within the time period.\n    \n        :param release_conn:\n            If False, then the urlopen call will not release the connection\n            back into the pool once a response is received (but will release if\n            you read the entire contents of the response such as when\n            `preload_content=True`). This is useful if you&#39;re not preloading\n            the response&#39;s content immediately. You will need to call\n            ``r.release_conn()`` on the response ``r`` to return the connection\n            back into the pool. If None, it takes the value of\n            ``response_kw.get(&#39;preload_content&#39;, True)``.\n    \n        :param chunked:\n            If True, urllib3 will send the body using chunked transfer\n            encoding. Otherwise, urllib3 will send the body using the standard\n            content-length form. Defaults to False.\n    \n        :param int body_pos:\n            Position to seek to in file-like body in the event of a retry or\n            redirect. Typically this won&#39;t need to be set because urllib3 will\n            auto-populate the value when needed.\n    \n        :param \\\\**response_kw:\n            Additional parameters are passed to\n            :meth:`urllib3.response.HTTPResponse.from_httplib`\n        \&#34;\&#34;\&#34;\n    \n        parsed_url = parse_url(url)\n        destination_scheme = parsed_url.scheme\n    \n        if headers is None:\n            headers = self.headers\n    \n        if not isinstance(retries, Retry):\n            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)\n    \n        if release_conn is None:\n            release_conn = response_kw.get(\&#34;preload_content\&#34;, True)\n    \n        # Check host\n        if assert_same_host and not self.is_same_host(url):\n            raise HostChangedError(self, url, retries)\n    \n        # Ensure that the URL we&#39;re connecting to is properly encoded\n        if url.startswith(\&#34;/\&#34;):\n            url = six.ensure_str(_encode_target(url))\n        else:\n            url = six.ensure_str(parsed_url.url)\n    \n        conn = None\n    \n        # Track whether `conn` needs to be released before\n        # returning/raising/recursing. Update this variable if necessary, and\n        # leave `release_conn` constant throughout the function. That way, if\n        # the function recurses, the original value of `release_conn` will be\n        # passed down into the recursive call, and its value will be respected.\n        #\n        # See issue #651 [1] for details.\n        #\n        # [1] &amp;lt;https://github.com/urllib3/urllib3/issues/651&amp;gt;\n        release_this_conn = release_conn\n    \n        http_tunnel_required = connection_requires_http_tunnel(\n            self.proxy, self.proxy_config, destination_scheme\n        )\n    \n        # Merge the proxy headers. Only done when not using HTTP CONNECT. We\n        # have to copy the headers dict so we can safely change it without those\n        # changes being reflected in anyone else&#39;s copy.\n        if not http_tunnel_required:\n            headers = headers.copy()\n            headers.update(self.proxy_headers)\n    \n        # Must keep the exception bound to a separate variable or else Python 3\n        # complains about UnboundLocalError.\n        err = None\n    \n        # Keep track of whether we cleanly exited the except block. This\n        # ensures we do proper cleanup in finally.\n        clean_exit = False\n    \n        # Rewind body position, if needed. Record current position\n        # for future rewinds in the event of a redirect/retry.\n        body_pos = set_file_position(body, body_pos)\n    \n        try:\n            # Request a connection from the queue.\n            timeout_obj = self._get_timeout(timeout)\n            conn = self._get_conn(timeout=pool_timeout)\n    \n            conn.timeout = timeout_obj.connect_timeout\n    \n            is_new_proxy_conn = self.proxy is not None and not getattr(\n                conn, \&#34;sock\&#34;, None\n            )\n            if is_new_proxy_conn and http_tunnel_required:\n                self._prepare_proxy(conn)\n    \n            # Make the request on the httplib connection object.\n&amp;gt;           httplib_response = self._make_request(\n                conn,\n                method,\n                url,\n                timeout=timeout_obj,\n                body=body,\n                headers=headers,\n                chunked=chunked,\n            )\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:715: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:404: in _make_request\n    self._validate_conn(conn)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1058: in _validate_conn\n    conn.connect()\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connection.py:363: in connect\n    self.sock = conn = self._new_conn()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;\n\n    def _new_conn(self):\n        \&#34;\&#34;\&#34;Establish a socket connection and set nodelay settings on it.\n    \n        :return: New socket connection.\n        \&#34;\&#34;\&#34;\n        extra_kw = {}\n        if self.source_address:\n            extra_kw[\&#34;source_address\&#34;] = self.source_address\n    \n        if self.socket_options:\n            extra_kw[\&#34;socket_options\&#34;] = self.socket_options\n    \n        try:\n            conn = connection.create_connection(\n                (self._dns_host, self.port), self.timeout, **extra_kw\n            )\n    \n        except SocketTimeout:\n            raise ConnectTimeoutError(\n                self,\n                \&#34;Connection to %s timed out. (connect timeout=%s)\&#34;\n                % (self.host, self.timeout),\n            )\n    \n        except SocketError as e:\n&amp;gt;           raise NewConnectionError(\n                self, \&#34;Failed to establish a new connection: %s\&#34; % e\n            )\nE           urllib3.exceptions.NewConnectionError: &amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;: Failed to establish a new connection: [Errno 11001] getaddrinfo failed\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connection.py:186: NewConnectionError\n\nDuring handling of the above exception, another exception occurred:\n\nself = &amp;lt;requests.adapters.HTTPAdapter object at 0x000002487F34AA10&amp;gt;, request = &amp;lt;PreparedRequest [GET]&amp;gt;, stream = True, timeout = Timeout(connect=None, read=None, total=None)\nverify = True, cert = None, proxies = OrderedDict()\n\n    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):\n        \&#34;\&#34;\&#34;Sends PreparedRequest object. Returns Response object.\n    \n        :param request: The :class:`PreparedRequest &amp;lt;PreparedRequest&amp;gt;` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) &amp;lt;timeouts&amp;gt;` tuple.\n        :type timeout: float or tuple or urllib3 Timeout object\n        :param verify: (optional) Either a boolean, in which case it controls whether\n            we verify the server&#39;s TLS certificate, or a string, in which case it\n            must be a path to a CA bundle to use\n        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        :rtype: requests.Response\n        \&#34;\&#34;\&#34;\n    \n        try:\n            conn = self.get_connection(request.url, proxies)\n        except LocationValueError as e:\n            raise InvalidURL(e, request=request)\n    \n        self.cert_verify(conn, request.url, verify, cert)\n        url = self.request_url(request, proxies)\n        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)\n    \n        chunked = not (request.body is None or &#39;Content-Length&#39; in request.headers)\n    \n        if isinstance(timeout, tuple):\n            try:\n                connect, read = timeout\n                timeout = TimeoutSauce(connect=connect, read=read)\n            except ValueError as e:\n                # this may raise a string formatting error.\n                err = (\&#34;Invalid timeout {}. Pass a (connect, read) \&#34;\n                       \&#34;timeout tuple, or a single float to set \&#34;\n                       \&#34;both timeouts to the same value\&#34;.format(timeout))\n                raise ValueError(err)\n        elif isinstance(timeout, TimeoutSauce):\n            pass\n        else:\n            timeout = TimeoutSauce(connect=timeout, read=timeout)\n    \n        try:\n            if not chunked:\n&amp;gt;               resp = conn.urlopen(\n                    method=request.method,\n                    url=url,\n                    body=request.body,\n                    headers=request.headers,\n                    redirect=False,\n                    assert_same_host=False,\n                    preload_content=False,\n                    decode_content=False,\n                    retries=self.max_retries,\n                    timeout=timeout\n                )\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\adapters.py:440: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:799: in urlopen\n    retries = retries.increment(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = Retry(total=0, connect=None, read=False, redirect=None, status=None), method = &#39;GET&#39;, url = &#39;/chrome-for-testing/known-good-versions-with-downloads.json&#39;\nresponse = None\nerror = NewConnectionError(&#39;&amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;: Failed to establish a new connection: [Errno 11001] getaddrinfo failed&#39;)\n_pool = &amp;lt;urllib3.connectionpool.HTTPSConnectionPool object at 0x000002487F354910&amp;gt;, _stacktrace = &amp;lt;traceback object at 0x000002487F354FC0&amp;gt;\n\n    def increment(\n        self,\n        method=None,\n        url=None,\n        response=None,\n        error=None,\n        _pool=None,\n        _stacktrace=None,\n    ):\n        \&#34;\&#34;\&#34;Return a new Retry object with incremented retry counters.\n    \n        :param response: A response object, or None, if the server did not\n            return a response.\n        :type response: :class:`~urllib3.response.HTTPResponse`\n        :param Exception error: An error encountered during the request, or\n            None if the response was received successfully.\n    \n        :return: A new ``Retry`` object.\n        \&#34;\&#34;\&#34;\n        if self.total is False and error:\n            # Disabled, indicate to re-raise the error.\n            raise six.reraise(type(error), error, _stacktrace)\n    \n        total = self.total\n        if total is not None:\n            total -= 1\n    \n        connect = self.connect\n        read = self.read\n        redirect = self.redirect\n        status_count = self.status\n        other = self.other\n        cause = \&#34;unknown\&#34;\n        status = None\n        redirect_location = None\n    \n        if error and self._is_connection_error(error):\n            # Connect retry?\n            if connect is False:\n                raise six.reraise(type(error), error, _stacktrace)\n            elif connect is not None:\n                connect -= 1\n    \n        elif error and self._is_read_error(error):\n            # Read retry?\n            if read is False or not self._is_method_retryable(method):\n                raise six.reraise(type(error), error, _stacktrace)\n            elif read is not None:\n                read -= 1\n    \n        elif error:\n            # Other retry?\n            if other is not None:\n                other -= 1\n    \n        elif response and response.get_redirect_location():\n            # Redirect retry?\n            if redirect is not None:\n                redirect -= 1\n            cause = \&#34;too many redirects\&#34;\n            redirect_location = response.get_redirect_location()\n            status = response.status\n    \n        else:\n            # Incrementing because of a server error like a 500 in\n            # status_forcelist and the given method is in the allowed_methods\n            cause = ResponseError.GENERIC_ERROR\n            if response and response.status:\n                if status_count is not None:\n                    status_count -= 1\n                cause = ResponseError.SPECIFIC_ERROR.format(status_code=response.status)\n                status = response.status\n    \n        history = self.history + (\n            RequestHistory(method, url, error, status, redirect_location),\n        )\n    \n        new_retry = self.new(\n            total=total,\n            connect=connect,\n            read=read,\n            redirect=redirect,\n            status=status_count,\n            other=other,\n            history=history,\n        )\n    \n        if new_retry.is_exhausted():\n&amp;gt;           raise MaxRetryError(_pool, url, error or ResponseError(cause))\nE           urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host=&#39;googlechromelabs.github.io&#39;, port=443): Max retries exceeded with url: /chrome-for-testing/known-good-versions-with-downloads.json (Caused by NewConnectionError(&#39;&amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;: Failed to establish a new connection: [Errno 11001] getaddrinfo failed&#39;))\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\util\\retry.py:592: MaxRetryError\n\nDuring handling of the above exception, another exception occurred:\n\nself = &amp;lt;webdriver_manager.core.http.WDMHttpClient object at 0x000002487F2E6990&amp;gt;\nurl = &#39;https://googlechromelabs.github.io/chrome-for-testing/known-good-versions-with-downloads.json&#39;, kwargs = {}\n\n    def get(self, url, **kwargs) -&amp;gt; Response:\n        try:\n&amp;gt;           resp = requests.get(\n                url=url, verify=self._ssl_verify, stream=True, **kwargs)\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\core\\http.py:32: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\api.py:75: in get\n    return request(&#39;get&#39;, url, params=params, **kwargs)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\api.py:61: in request\n    return session.request(method=method, url=url, **kwargs)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\sessions.py:529: in request\n    resp = self.send(prep, **send_kwargs)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\sessions.py:645: in send\n    r = adapter.send(request, **kwargs)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;requests.adapters.HTTPAdapter object at 0x000002487F34AA10&amp;gt;, request = &amp;lt;PreparedRequest [GET]&amp;gt;, stream = True, timeout = Timeout(connect=None, read=None, total=None)\nverify = True, cert = None, proxies = OrderedDict()\n\n    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):\n        \&#34;\&#34;\&#34;Sends PreparedRequest object. Returns Response object.\n    \n        :param request: The :class:`PreparedRequest &amp;lt;PreparedRequest&amp;gt;` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) &amp;lt;timeouts&amp;gt;` tuple.\n        :type timeout: float or tuple or urllib3 Timeout object\n        :param verify: (optional) Either a boolean, in which case it controls whether\n            we verify the server&#39;s TLS certificate, or a string, in which case it\n            must be a path to a CA bundle to use\n        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        :rtype: requests.Response\n        \&#34;\&#34;\&#34;\n    \n        try:\n            conn = self.get_connection(request.url, proxies)\n        except LocationValueError as e:\n            raise InvalidURL(e, request=request)\n    \n        self.cert_verify(conn, request.url, verify, cert)\n        url = self.request_url(request, proxies)\n        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)\n    \n        chunked = not (request.body is None or &#39;Content-Length&#39; in request.headers)\n    \n        if isinstance(timeout, tuple):\n            try:\n                connect, read = timeout\n                timeout = TimeoutSauce(connect=connect, read=read)\n            except ValueError as e:\n                # this may raise a string formatting error.\n                err = (\&#34;Invalid timeout {}. Pass a (connect, read) \&#34;\n                       \&#34;timeout tuple, or a single float to set \&#34;\n                       \&#34;both timeouts to the same value\&#34;.format(timeout))\n                raise ValueError(err)\n        elif isinstance(timeout, TimeoutSauce):\n            pass\n        else:\n            timeout = TimeoutSauce(connect=timeout, read=timeout)\n    \n        try:\n            if not chunked:\n                resp = conn.urlopen(\n                    method=request.method,\n                    url=url,\n                    body=request.body,\n                    headers=request.headers,\n                    redirect=False,\n                    assert_same_host=False,\n                    preload_content=False,\n                    decode_content=False,\n                    retries=self.max_retries,\n                    timeout=timeout\n                )\n    \n            # Send the request.\n            else:\n                if hasattr(conn, &#39;proxy_pool&#39;):\n                    conn = conn.proxy_pool\n    \n                low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)\n    \n                try:\n                    skip_host = &#39;Host&#39; in request.headers\n                    low_conn.putrequest(request.method,\n                                        url,\n                                        skip_accept_encoding=True,\n                                        skip_host=skip_host)\n    \n                    for header, value in request.headers.items():\n                        low_conn.putheader(header, value)\n    \n                    low_conn.endheaders()\n    \n                    for i in request.body:\n                        low_conn.send(hex(len(i))[2:].encode(&#39;utf-8&#39;))\n                        low_conn.send(b&#39;\\r\\n&#39;)\n                        low_conn.send(i)\n                        low_conn.send(b&#39;\\r\\n&#39;)\n                    low_conn.send(b&#39;0\\r\\n\\r\\n&#39;)\n    \n                    # Receive the response from the server\n                    try:\n                        # For Python 2.7, use buffering of HTTP responses\n                        r = low_conn.getresponse(buffering=True)\n                    except TypeError:\n                        # For compatibility with Python 3.3+\n                        r = low_conn.getresponse()\n    \n                    resp = HTTPResponse.from_httplib(\n                        r,\n                        pool=conn,\n                        connection=low_conn,\n                        preload_content=False,\n                        decode_content=False\n                    )\n                except:\n                    # If we hit any problems here, clean up the connection.\n                    # Then, reraise so that we can handle the actual exception.\n                    low_conn.close()\n                    raise\n    \n        except (ProtocolError, socket.error) as err:\n            raise ConnectionError(err, request=request)\n    \n        except MaxRetryError as e:\n            if isinstance(e.reason, ConnectTimeoutError):\n                # TODO: Remove this in 3.0.0: see #2811\n                if not isinstance(e.reason, NewConnectionError):\n                    raise ConnectTimeout(e, request=request)\n    \n            if isinstance(e.reason, ResponseError):\n                raise RetryError(e, request=request)\n    \n            if isinstance(e.reason, _ProxyError):\n                raise ProxyError(e, request=request)\n    \n            if isinstance(e.reason, _SSLError):\n                # This branch is for urllib3 v1.22 and later.\n                raise SSLError(e, request=request)\n    \n&amp;gt;           raise ConnectionError(e, request=request)\nE           requests.exceptions.ConnectionError: HTTPSConnectionPool(host=&#39;googlechromelabs.github.io&#39;, port=443): Max retries exceeded with url: /chrome-for-testing/known-good-versions-with-downloads.json (Caused by NewConnectionError(&#39;&amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;: Failed to establish a new connection: [Errno 11001] getaddrinfo failed&#39;))\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\adapters.py:519: ConnectionError\n\nDuring handling of the above exception, another exception occurred:\n\n    @pytest.fixture(scope=\&#34;module\&#34;)\n    def driver():\n        options = Options()\n        options.add_experimental_option(\&#34;detach\&#34;, True)\n        #driver = webdriver.Chrome(options=options)\n&amp;gt;       driver = webdriver.Chrome(options=options, service=Service(ChromeDriverManager().install()))\n\nSingle_bucket_sim.py:27: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\chrome.py:40: in install\n    driver_path = self._get_driver_binary_path(self.driver)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\core\\manager.py:40: in _get_driver_binary_path\n    file = self._download_manager.download_file(driver.get_driver_download_url(os_type))\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\drivers\\chrome.py:44: in get_driver_download_url\n    modern_version_url = self.get_url_for_version_and_platform(driver_version_to_download, os_type)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\drivers\\chrome.py:69: in get_url_for_version_and_platform\n    response = self._http_client.get(url)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;webdriver_manager.core.http.WDMHttpClient object at 0x000002487F2E6990&amp;gt;\nurl = &#39;https://googlechromelabs.github.io/chrome-for-testing/known-good-versions-with-downloads.json&#39;, kwargs = {}\n\n    def get(self, url, **kwargs) -&amp;gt; Response:\n        try:\n            resp = requests.get(\n                url=url, verify=self._ssl_verify, stream=True, **kwargs)\n        except exceptions.ConnectionError:\n&amp;gt;           raise exceptions.ConnectionError(f\&#34;Could not reach host. Are you offline?\&#34;)\nE           requests.exceptions.ConnectionError: Could not reach host. Are you offline?\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\core\\http.py:35: ConnectionError\n&#34;}], &#34;Single_bucket_sim.py::test_first_page_content&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Error&#34;, &#34;testId&#34;: &#34;Single_bucket_sim.py::test_first_page_content::setup&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Error&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;Single_bucket_sim.py::test_first_page_content::setup&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;\n\n    def _new_conn(self):\n        \&#34;\&#34;\&#34;Establish a socket connection and set nodelay settings on it.\n    \n        :return: New socket connection.\n        \&#34;\&#34;\&#34;\n        extra_kw = {}\n        if self.source_address:\n            extra_kw[\&#34;source_address\&#34;] = self.source_address\n    \n        if self.socket_options:\n            extra_kw[\&#34;socket_options\&#34;] = self.socket_options\n    \n        try:\n&amp;gt;           conn = connection.create_connection(\n                (self._dns_host, self.port), self.timeout, **extra_kw\n            )\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connection.py:174: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\util\\connection.py:72: in create_connection\n    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nhost = &#39;googlechromelabs.github.io&#39;, port = 443, family = &amp;lt;AddressFamily.AF_UNSPEC: 0&amp;gt;, type = &amp;lt;SocketKind.SOCK_STREAM: 1&amp;gt;, proto = 0, flags = 0\n\n    def getaddrinfo(host, port, family=0, type=0, proto=0, flags=0):\n        \&#34;\&#34;\&#34;Resolve host and port into list of address info entries.\n    \n        Translate the host/port argument into a sequence of 5-tuples that contain\n        all the necessary arguments for creating a socket connected to that service.\n        host is a domain name, a string representation of an IPv4/v6 address or\n        None. port is a string service name such as &#39;http&#39;, a numeric port number or\n        None. By passing None as the value of host and port, you can pass NULL to\n        the underlying C API.\n    \n        The family, type and proto arguments can be optionally specified in order to\n        narrow the list of addresses returned. Passing zero as a value for each of\n        these arguments selects the full range of results.\n        \&#34;\&#34;\&#34;\n        # We override this function since we want to translate the numeric family\n        # and socket type values to enum constants.\n        addrlist = []\n&amp;gt;       for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\nE       socket.gaierror: [Errno 11001] getaddrinfo failed\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\socket.py:962: gaierror\n\nDuring handling of the above exception, another exception occurred:\n\nself = &amp;lt;urllib3.connectionpool.HTTPSConnectionPool object at 0x000002487F354910&amp;gt;, method = &#39;GET&#39;, url = &#39;/chrome-for-testing/known-good-versions-with-downloads.json&#39;\nbody = None, headers = {&#39;User-Agent&#39;: &#39;python-requests/2.27.1&#39;, &#39;Accept-Encoding&#39;: &#39;gzip, deflate&#39;, &#39;Accept&#39;: &#39;*/*&#39;, &#39;Connection&#39;: &#39;keep-alive&#39;}\nretries = Retry(total=0, connect=None, read=False, redirect=None, status=None), redirect = False, assert_same_host = False\ntimeout = Timeout(connect=None, read=None, total=None), pool_timeout = None, release_conn = False, chunked = False, body_pos = None\nresponse_kw = {&#39;decode_content&#39;: False, &#39;preload_content&#39;: False}\nparsed_url = Url(scheme=None, auth=None, host=None, port=None, path=&#39;/chrome-for-testing/known-good-versions-with-downloads.json&#39;, query=None, fragment=None)\ndestination_scheme = None, conn = None, release_this_conn = True, http_tunnel_required = False, err = None, clean_exit = False\n\n    def urlopen(\n        self,\n        method,\n        url,\n        body=None,\n        headers=None,\n        retries=None,\n        redirect=True,\n        assert_same_host=True,\n        timeout=_Default,\n        pool_timeout=None,\n        release_conn=None,\n        chunked=False,\n        body_pos=None,\n        **response_kw\n    ):\n        \&#34;\&#34;\&#34;\n        Get a connection from the pool and perform an HTTP request. This is the\n        lowest level call for making a request, so you&#39;ll need to specify all\n        the raw details.\n    \n        .. note::\n    \n           More commonly, it&#39;s appropriate to use a convenience method provided\n           by :class:`.RequestMethods`, such as :meth:`request`.\n    \n        .. note::\n    \n           `release_conn` will only behave as expected if\n           `preload_content=False` because we want to make\n           `preload_content=False` the default behaviour someday soon without\n           breaking backwards compatibility.\n    \n        :param method:\n            HTTP request method (such as GET, POST, PUT, etc.)\n    \n        :param url:\n            The URL to perform the request on.\n    \n        :param body:\n            Data to send in the request body, either :class:`str`, :class:`bytes`,\n            an iterable of :class:`str`/:class:`bytes`, or a file-like object.\n    \n        :param headers:\n            Dictionary of custom headers to send, such as User-Agent,\n            If-None-Match, etc. If None, pool headers are used. If provided,\n            these headers completely replace any pool-specific headers.\n    \n        :param retries:\n            Configure the number of retries to allow before raising a\n            :class:`~urllib3.exceptions.MaxRetryError` exception.\n    \n            Pass ``None`` to retry until you receive a response. Pass a\n            :class:`~urllib3.util.retry.Retry` object for fine-grained control\n            over different types of retries.\n            Pass an integer number to retry connection errors that many times,\n            but no other types of errors. Pass zero to never retry.\n    \n            If ``False``, then retries are disabled and any exception is raised\n            immediately. Also, instead of raising a MaxRetryError on redirects,\n            the redirect response will be returned.\n    \n        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.\n    \n        :param redirect:\n            If True, automatically handle redirects (status codes 301, 302,\n            303, 307, 308). Each redirect counts as a retry. Disabling retries\n            will disable redirect, too.\n    \n        :param assert_same_host:\n            If ``True``, will make sure that the host of the pool requests is\n            consistent else will raise HostChangedError. When ``False``, you can\n            use the pool on an HTTP proxy and request foreign hosts.\n    \n        :param timeout:\n            If specified, overrides the default timeout for this one\n            request. It may be a float (in seconds) or an instance of\n            :class:`urllib3.util.Timeout`.\n    \n        :param pool_timeout:\n            If set and the pool is set to block=True, then this method will\n            block for ``pool_timeout`` seconds and raise EmptyPoolError if no\n            connection is available within the time period.\n    \n        :param release_conn:\n            If False, then the urlopen call will not release the connection\n            back into the pool once a response is received (but will release if\n            you read the entire contents of the response such as when\n            `preload_content=True`). This is useful if you&#39;re not preloading\n            the response&#39;s content immediately. You will need to call\n            ``r.release_conn()`` on the response ``r`` to return the connection\n            back into the pool. If None, it takes the value of\n            ``response_kw.get(&#39;preload_content&#39;, True)``.\n    \n        :param chunked:\n            If True, urllib3 will send the body using chunked transfer\n            encoding. Otherwise, urllib3 will send the body using the standard\n            content-length form. Defaults to False.\n    \n        :param int body_pos:\n            Position to seek to in file-like body in the event of a retry or\n            redirect. Typically this won&#39;t need to be set because urllib3 will\n            auto-populate the value when needed.\n    \n        :param \\\\**response_kw:\n            Additional parameters are passed to\n            :meth:`urllib3.response.HTTPResponse.from_httplib`\n        \&#34;\&#34;\&#34;\n    \n        parsed_url = parse_url(url)\n        destination_scheme = parsed_url.scheme\n    \n        if headers is None:\n            headers = self.headers\n    \n        if not isinstance(retries, Retry):\n            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)\n    \n        if release_conn is None:\n            release_conn = response_kw.get(\&#34;preload_content\&#34;, True)\n    \n        # Check host\n        if assert_same_host and not self.is_same_host(url):\n            raise HostChangedError(self, url, retries)\n    \n        # Ensure that the URL we&#39;re connecting to is properly encoded\n        if url.startswith(\&#34;/\&#34;):\n            url = six.ensure_str(_encode_target(url))\n        else:\n            url = six.ensure_str(parsed_url.url)\n    \n        conn = None\n    \n        # Track whether `conn` needs to be released before\n        # returning/raising/recursing. Update this variable if necessary, and\n        # leave `release_conn` constant throughout the function. That way, if\n        # the function recurses, the original value of `release_conn` will be\n        # passed down into the recursive call, and its value will be respected.\n        #\n        # See issue #651 [1] for details.\n        #\n        # [1] &amp;lt;https://github.com/urllib3/urllib3/issues/651&amp;gt;\n        release_this_conn = release_conn\n    \n        http_tunnel_required = connection_requires_http_tunnel(\n            self.proxy, self.proxy_config, destination_scheme\n        )\n    \n        # Merge the proxy headers. Only done when not using HTTP CONNECT. We\n        # have to copy the headers dict so we can safely change it without those\n        # changes being reflected in anyone else&#39;s copy.\n        if not http_tunnel_required:\n            headers = headers.copy()\n            headers.update(self.proxy_headers)\n    \n        # Must keep the exception bound to a separate variable or else Python 3\n        # complains about UnboundLocalError.\n        err = None\n    \n        # Keep track of whether we cleanly exited the except block. This\n        # ensures we do proper cleanup in finally.\n        clean_exit = False\n    \n        # Rewind body position, if needed. Record current position\n        # for future rewinds in the event of a redirect/retry.\n        body_pos = set_file_position(body, body_pos)\n    \n        try:\n            # Request a connection from the queue.\n            timeout_obj = self._get_timeout(timeout)\n            conn = self._get_conn(timeout=pool_timeout)\n    \n            conn.timeout = timeout_obj.connect_timeout\n    \n            is_new_proxy_conn = self.proxy is not None and not getattr(\n                conn, \&#34;sock\&#34;, None\n            )\n            if is_new_proxy_conn and http_tunnel_required:\n                self._prepare_proxy(conn)\n    \n            # Make the request on the httplib connection object.\n&amp;gt;           httplib_response = self._make_request(\n                conn,\n                method,\n                url,\n                timeout=timeout_obj,\n                body=body,\n                headers=headers,\n                chunked=chunked,\n            )\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:715: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:404: in _make_request\n    self._validate_conn(conn)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1058: in _validate_conn\n    conn.connect()\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connection.py:363: in connect\n    self.sock = conn = self._new_conn()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;\n\n    def _new_conn(self):\n        \&#34;\&#34;\&#34;Establish a socket connection and set nodelay settings on it.\n    \n        :return: New socket connection.\n        \&#34;\&#34;\&#34;\n        extra_kw = {}\n        if self.source_address:\n            extra_kw[\&#34;source_address\&#34;] = self.source_address\n    \n        if self.socket_options:\n            extra_kw[\&#34;socket_options\&#34;] = self.socket_options\n    \n        try:\n            conn = connection.create_connection(\n                (self._dns_host, self.port), self.timeout, **extra_kw\n            )\n    \n        except SocketTimeout:\n            raise ConnectTimeoutError(\n                self,\n                \&#34;Connection to %s timed out. (connect timeout=%s)\&#34;\n                % (self.host, self.timeout),\n            )\n    \n        except SocketError as e:\n&amp;gt;           raise NewConnectionError(\n                self, \&#34;Failed to establish a new connection: %s\&#34; % e\n            )\nE           urllib3.exceptions.NewConnectionError: &amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;: Failed to establish a new connection: [Errno 11001] getaddrinfo failed\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connection.py:186: NewConnectionError\n\nDuring handling of the above exception, another exception occurred:\n\nself = &amp;lt;requests.adapters.HTTPAdapter object at 0x000002487F34AA10&amp;gt;, request = &amp;lt;PreparedRequest [GET]&amp;gt;, stream = True, timeout = Timeout(connect=None, read=None, total=None)\nverify = True, cert = None, proxies = OrderedDict()\n\n    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):\n        \&#34;\&#34;\&#34;Sends PreparedRequest object. Returns Response object.\n    \n        :param request: The :class:`PreparedRequest &amp;lt;PreparedRequest&amp;gt;` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) &amp;lt;timeouts&amp;gt;` tuple.\n        :type timeout: float or tuple or urllib3 Timeout object\n        :param verify: (optional) Either a boolean, in which case it controls whether\n            we verify the server&#39;s TLS certificate, or a string, in which case it\n            must be a path to a CA bundle to use\n        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        :rtype: requests.Response\n        \&#34;\&#34;\&#34;\n    \n        try:\n            conn = self.get_connection(request.url, proxies)\n        except LocationValueError as e:\n            raise InvalidURL(e, request=request)\n    \n        self.cert_verify(conn, request.url, verify, cert)\n        url = self.request_url(request, proxies)\n        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)\n    \n        chunked = not (request.body is None or &#39;Content-Length&#39; in request.headers)\n    \n        if isinstance(timeout, tuple):\n            try:\n                connect, read = timeout\n                timeout = TimeoutSauce(connect=connect, read=read)\n            except ValueError as e:\n                # this may raise a string formatting error.\n                err = (\&#34;Invalid timeout {}. Pass a (connect, read) \&#34;\n                       \&#34;timeout tuple, or a single float to set \&#34;\n                       \&#34;both timeouts to the same value\&#34;.format(timeout))\n                raise ValueError(err)\n        elif isinstance(timeout, TimeoutSauce):\n            pass\n        else:\n            timeout = TimeoutSauce(connect=timeout, read=timeout)\n    \n        try:\n            if not chunked:\n&amp;gt;               resp = conn.urlopen(\n                    method=request.method,\n                    url=url,\n                    body=request.body,\n                    headers=request.headers,\n                    redirect=False,\n                    assert_same_host=False,\n                    preload_content=False,\n                    decode_content=False,\n                    retries=self.max_retries,\n                    timeout=timeout\n                )\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\adapters.py:440: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:799: in urlopen\n    retries = retries.increment(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = Retry(total=0, connect=None, read=False, redirect=None, status=None), method = &#39;GET&#39;, url = &#39;/chrome-for-testing/known-good-versions-with-downloads.json&#39;\nresponse = None\nerror = NewConnectionError(&#39;&amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;: Failed to establish a new connection: [Errno 11001] getaddrinfo failed&#39;)\n_pool = &amp;lt;urllib3.connectionpool.HTTPSConnectionPool object at 0x000002487F354910&amp;gt;, _stacktrace = &amp;lt;traceback object at 0x000002487F354FC0&amp;gt;\n\n    def increment(\n        self,\n        method=None,\n        url=None,\n        response=None,\n        error=None,\n        _pool=None,\n        _stacktrace=None,\n    ):\n        \&#34;\&#34;\&#34;Return a new Retry object with incremented retry counters.\n    \n        :param response: A response object, or None, if the server did not\n            return a response.\n        :type response: :class:`~urllib3.response.HTTPResponse`\n        :param Exception error: An error encountered during the request, or\n            None if the response was received successfully.\n    \n        :return: A new ``Retry`` object.\n        \&#34;\&#34;\&#34;\n        if self.total is False and error:\n            # Disabled, indicate to re-raise the error.\n            raise six.reraise(type(error), error, _stacktrace)\n    \n        total = self.total\n        if total is not None:\n            total -= 1\n    \n        connect = self.connect\n        read = self.read\n        redirect = self.redirect\n        status_count = self.status\n        other = self.other\n        cause = \&#34;unknown\&#34;\n        status = None\n        redirect_location = None\n    \n        if error and self._is_connection_error(error):\n            # Connect retry?\n            if connect is False:\n                raise six.reraise(type(error), error, _stacktrace)\n            elif connect is not None:\n                connect -= 1\n    \n        elif error and self._is_read_error(error):\n            # Read retry?\n            if read is False or not self._is_method_retryable(method):\n                raise six.reraise(type(error), error, _stacktrace)\n            elif read is not None:\n                read -= 1\n    \n        elif error:\n            # Other retry?\n            if other is not None:\n                other -= 1\n    \n        elif response and response.get_redirect_location():\n            # Redirect retry?\n            if redirect is not None:\n                redirect -= 1\n            cause = \&#34;too many redirects\&#34;\n            redirect_location = response.get_redirect_location()\n            status = response.status\n    \n        else:\n            # Incrementing because of a server error like a 500 in\n            # status_forcelist and the given method is in the allowed_methods\n            cause = ResponseError.GENERIC_ERROR\n            if response and response.status:\n                if status_count is not None:\n                    status_count -= 1\n                cause = ResponseError.SPECIFIC_ERROR.format(status_code=response.status)\n                status = response.status\n    \n        history = self.history + (\n            RequestHistory(method, url, error, status, redirect_location),\n        )\n    \n        new_retry = self.new(\n            total=total,\n            connect=connect,\n            read=read,\n            redirect=redirect,\n            status=status_count,\n            other=other,\n            history=history,\n        )\n    \n        if new_retry.is_exhausted():\n&amp;gt;           raise MaxRetryError(_pool, url, error or ResponseError(cause))\nE           urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host=&#39;googlechromelabs.github.io&#39;, port=443): Max retries exceeded with url: /chrome-for-testing/known-good-versions-with-downloads.json (Caused by NewConnectionError(&#39;&amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;: Failed to establish a new connection: [Errno 11001] getaddrinfo failed&#39;))\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\util\\retry.py:592: MaxRetryError\n\nDuring handling of the above exception, another exception occurred:\n\nself = &amp;lt;webdriver_manager.core.http.WDMHttpClient object at 0x000002487F2E6990&amp;gt;\nurl = &#39;https://googlechromelabs.github.io/chrome-for-testing/known-good-versions-with-downloads.json&#39;, kwargs = {}\n\n    def get(self, url, **kwargs) -&amp;gt; Response:\n        try:\n&amp;gt;           resp = requests.get(\n                url=url, verify=self._ssl_verify, stream=True, **kwargs)\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\core\\http.py:32: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\api.py:75: in get\n    return request(&#39;get&#39;, url, params=params, **kwargs)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\api.py:61: in request\n    return session.request(method=method, url=url, **kwargs)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\sessions.py:529: in request\n    resp = self.send(prep, **send_kwargs)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\sessions.py:645: in send\n    r = adapter.send(request, **kwargs)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;requests.adapters.HTTPAdapter object at 0x000002487F34AA10&amp;gt;, request = &amp;lt;PreparedRequest [GET]&amp;gt;, stream = True, timeout = Timeout(connect=None, read=None, total=None)\nverify = True, cert = None, proxies = OrderedDict()\n\n    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):\n        \&#34;\&#34;\&#34;Sends PreparedRequest object. Returns Response object.\n    \n        :param request: The :class:`PreparedRequest &amp;lt;PreparedRequest&amp;gt;` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) &amp;lt;timeouts&amp;gt;` tuple.\n        :type timeout: float or tuple or urllib3 Timeout object\n        :param verify: (optional) Either a boolean, in which case it controls whether\n            we verify the server&#39;s TLS certificate, or a string, in which case it\n            must be a path to a CA bundle to use\n        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        :rtype: requests.Response\n        \&#34;\&#34;\&#34;\n    \n        try:\n            conn = self.get_connection(request.url, proxies)\n        except LocationValueError as e:\n            raise InvalidURL(e, request=request)\n    \n        self.cert_verify(conn, request.url, verify, cert)\n        url = self.request_url(request, proxies)\n        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)\n    \n        chunked = not (request.body is None or &#39;Content-Length&#39; in request.headers)\n    \n        if isinstance(timeout, tuple):\n            try:\n                connect, read = timeout\n                timeout = TimeoutSauce(connect=connect, read=read)\n            except ValueError as e:\n                # this may raise a string formatting error.\n                err = (\&#34;Invalid timeout {}. Pass a (connect, read) \&#34;\n                       \&#34;timeout tuple, or a single float to set \&#34;\n                       \&#34;both timeouts to the same value\&#34;.format(timeout))\n                raise ValueError(err)\n        elif isinstance(timeout, TimeoutSauce):\n            pass\n        else:\n            timeout = TimeoutSauce(connect=timeout, read=timeout)\n    \n        try:\n            if not chunked:\n                resp = conn.urlopen(\n                    method=request.method,\n                    url=url,\n                    body=request.body,\n                    headers=request.headers,\n                    redirect=False,\n                    assert_same_host=False,\n                    preload_content=False,\n                    decode_content=False,\n                    retries=self.max_retries,\n                    timeout=timeout\n                )\n    \n            # Send the request.\n            else:\n                if hasattr(conn, &#39;proxy_pool&#39;):\n                    conn = conn.proxy_pool\n    \n                low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)\n    \n                try:\n                    skip_host = &#39;Host&#39; in request.headers\n                    low_conn.putrequest(request.method,\n                                        url,\n                                        skip_accept_encoding=True,\n                                        skip_host=skip_host)\n    \n                    for header, value in request.headers.items():\n                        low_conn.putheader(header, value)\n    \n                    low_conn.endheaders()\n    \n                    for i in request.body:\n                        low_conn.send(hex(len(i))[2:].encode(&#39;utf-8&#39;))\n                        low_conn.send(b&#39;\\r\\n&#39;)\n                        low_conn.send(i)\n                        low_conn.send(b&#39;\\r\\n&#39;)\n                    low_conn.send(b&#39;0\\r\\n\\r\\n&#39;)\n    \n                    # Receive the response from the server\n                    try:\n                        # For Python 2.7, use buffering of HTTP responses\n                        r = low_conn.getresponse(buffering=True)\n                    except TypeError:\n                        # For compatibility with Python 3.3+\n                        r = low_conn.getresponse()\n    \n                    resp = HTTPResponse.from_httplib(\n                        r,\n                        pool=conn,\n                        connection=low_conn,\n                        preload_content=False,\n                        decode_content=False\n                    )\n                except:\n                    # If we hit any problems here, clean up the connection.\n                    # Then, reraise so that we can handle the actual exception.\n                    low_conn.close()\n                    raise\n    \n        except (ProtocolError, socket.error) as err:\n            raise ConnectionError(err, request=request)\n    \n        except MaxRetryError as e:\n            if isinstance(e.reason, ConnectTimeoutError):\n                # TODO: Remove this in 3.0.0: see #2811\n                if not isinstance(e.reason, NewConnectionError):\n                    raise ConnectTimeout(e, request=request)\n    \n            if isinstance(e.reason, ResponseError):\n                raise RetryError(e, request=request)\n    \n            if isinstance(e.reason, _ProxyError):\n                raise ProxyError(e, request=request)\n    \n            if isinstance(e.reason, _SSLError):\n                # This branch is for urllib3 v1.22 and later.\n                raise SSLError(e, request=request)\n    \n&amp;gt;           raise ConnectionError(e, request=request)\nE           requests.exceptions.ConnectionError: HTTPSConnectionPool(host=&#39;googlechromelabs.github.io&#39;, port=443): Max retries exceeded with url: /chrome-for-testing/known-good-versions-with-downloads.json (Caused by NewConnectionError(&#39;&amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;: Failed to establish a new connection: [Errno 11001] getaddrinfo failed&#39;))\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\adapters.py:519: ConnectionError\n\nDuring handling of the above exception, another exception occurred:\n\n    @pytest.fixture(scope=\&#34;module\&#34;)\n    def driver():\n        options = Options()\n        options.add_experimental_option(\&#34;detach\&#34;, True)\n        #driver = webdriver.Chrome(options=options)\n&amp;gt;       driver = webdriver.Chrome(options=options, service=Service(ChromeDriverManager().install()))\n\nSingle_bucket_sim.py:27: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\chrome.py:40: in install\n    driver_path = self._get_driver_binary_path(self.driver)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\core\\manager.py:40: in _get_driver_binary_path\n    file = self._download_manager.download_file(driver.get_driver_download_url(os_type))\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\drivers\\chrome.py:44: in get_driver_download_url\n    modern_version_url = self.get_url_for_version_and_platform(driver_version_to_download, os_type)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\drivers\\chrome.py:69: in get_url_for_version_and_platform\n    response = self._http_client.get(url)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;webdriver_manager.core.http.WDMHttpClient object at 0x000002487F2E6990&amp;gt;\nurl = &#39;https://googlechromelabs.github.io/chrome-for-testing/known-good-versions-with-downloads.json&#39;, kwargs = {}\n\n    def get(self, url, **kwargs) -&amp;gt; Response:\n        try:\n            resp = requests.get(\n                url=url, verify=self._ssl_verify, stream=True, **kwargs)\n        except exceptions.ConnectionError:\n&amp;gt;           raise exceptions.ConnectionError(f\&#34;Could not reach host. Are you offline?\&#34;)\nE           requests.exceptions.ConnectionError: Could not reach host. Are you offline?\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\core\\http.py:35: ConnectionError\n&#34;}], &#34;Single_bucket_sim.py::test_first_page_content_intrigued&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Error&#34;, &#34;testId&#34;: &#34;Single_bucket_sim.py::test_first_page_content_intrigued::setup&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Error&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;Single_bucket_sim.py::test_first_page_content_intrigued::setup&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;\n\n    def _new_conn(self):\n        \&#34;\&#34;\&#34;Establish a socket connection and set nodelay settings on it.\n    \n        :return: New socket connection.\n        \&#34;\&#34;\&#34;\n        extra_kw = {}\n        if self.source_address:\n            extra_kw[\&#34;source_address\&#34;] = self.source_address\n    \n        if self.socket_options:\n            extra_kw[\&#34;socket_options\&#34;] = self.socket_options\n    \n        try:\n&amp;gt;           conn = connection.create_connection(\n                (self._dns_host, self.port), self.timeout, **extra_kw\n            )\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connection.py:174: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\util\\connection.py:72: in create_connection\n    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nhost = &#39;googlechromelabs.github.io&#39;, port = 443, family = &amp;lt;AddressFamily.AF_UNSPEC: 0&amp;gt;, type = &amp;lt;SocketKind.SOCK_STREAM: 1&amp;gt;, proto = 0, flags = 0\n\n    def getaddrinfo(host, port, family=0, type=0, proto=0, flags=0):\n        \&#34;\&#34;\&#34;Resolve host and port into list of address info entries.\n    \n        Translate the host/port argument into a sequence of 5-tuples that contain\n        all the necessary arguments for creating a socket connected to that service.\n        host is a domain name, a string representation of an IPv4/v6 address or\n        None. port is a string service name such as &#39;http&#39;, a numeric port number or\n        None. By passing None as the value of host and port, you can pass NULL to\n        the underlying C API.\n    \n        The family, type and proto arguments can be optionally specified in order to\n        narrow the list of addresses returned. Passing zero as a value for each of\n        these arguments selects the full range of results.\n        \&#34;\&#34;\&#34;\n        # We override this function since we want to translate the numeric family\n        # and socket type values to enum constants.\n        addrlist = []\n&amp;gt;       for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\nE       socket.gaierror: [Errno 11001] getaddrinfo failed\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\socket.py:962: gaierror\n\nDuring handling of the above exception, another exception occurred:\n\nself = &amp;lt;urllib3.connectionpool.HTTPSConnectionPool object at 0x000002487F354910&amp;gt;, method = &#39;GET&#39;, url = &#39;/chrome-for-testing/known-good-versions-with-downloads.json&#39;\nbody = None, headers = {&#39;User-Agent&#39;: &#39;python-requests/2.27.1&#39;, &#39;Accept-Encoding&#39;: &#39;gzip, deflate&#39;, &#39;Accept&#39;: &#39;*/*&#39;, &#39;Connection&#39;: &#39;keep-alive&#39;}\nretries = Retry(total=0, connect=None, read=False, redirect=None, status=None), redirect = False, assert_same_host = False\ntimeout = Timeout(connect=None, read=None, total=None), pool_timeout = None, release_conn = False, chunked = False, body_pos = None\nresponse_kw = {&#39;decode_content&#39;: False, &#39;preload_content&#39;: False}\nparsed_url = Url(scheme=None, auth=None, host=None, port=None, path=&#39;/chrome-for-testing/known-good-versions-with-downloads.json&#39;, query=None, fragment=None)\ndestination_scheme = None, conn = None, release_this_conn = True, http_tunnel_required = False, err = None, clean_exit = False\n\n    def urlopen(\n        self,\n        method,\n        url,\n        body=None,\n        headers=None,\n        retries=None,\n        redirect=True,\n        assert_same_host=True,\n        timeout=_Default,\n        pool_timeout=None,\n        release_conn=None,\n        chunked=False,\n        body_pos=None,\n        **response_kw\n    ):\n        \&#34;\&#34;\&#34;\n        Get a connection from the pool and perform an HTTP request. This is the\n        lowest level call for making a request, so you&#39;ll need to specify all\n        the raw details.\n    \n        .. note::\n    \n           More commonly, it&#39;s appropriate to use a convenience method provided\n           by :class:`.RequestMethods`, such as :meth:`request`.\n    \n        .. note::\n    \n           `release_conn` will only behave as expected if\n           `preload_content=False` because we want to make\n           `preload_content=False` the default behaviour someday soon without\n           breaking backwards compatibility.\n    \n        :param method:\n            HTTP request method (such as GET, POST, PUT, etc.)\n    \n        :param url:\n            The URL to perform the request on.\n    \n        :param body:\n            Data to send in the request body, either :class:`str`, :class:`bytes`,\n            an iterable of :class:`str`/:class:`bytes`, or a file-like object.\n    \n        :param headers:\n            Dictionary of custom headers to send, such as User-Agent,\n            If-None-Match, etc. If None, pool headers are used. If provided,\n            these headers completely replace any pool-specific headers.\n    \n        :param retries:\n            Configure the number of retries to allow before raising a\n            :class:`~urllib3.exceptions.MaxRetryError` exception.\n    \n            Pass ``None`` to retry until you receive a response. Pass a\n            :class:`~urllib3.util.retry.Retry` object for fine-grained control\n            over different types of retries.\n            Pass an integer number to retry connection errors that many times,\n            but no other types of errors. Pass zero to never retry.\n    \n            If ``False``, then retries are disabled and any exception is raised\n            immediately. Also, instead of raising a MaxRetryError on redirects,\n            the redirect response will be returned.\n    \n        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.\n    \n        :param redirect:\n            If True, automatically handle redirects (status codes 301, 302,\n            303, 307, 308). Each redirect counts as a retry. Disabling retries\n            will disable redirect, too.\n    \n        :param assert_same_host:\n            If ``True``, will make sure that the host of the pool requests is\n            consistent else will raise HostChangedError. When ``False``, you can\n            use the pool on an HTTP proxy and request foreign hosts.\n    \n        :param timeout:\n            If specified, overrides the default timeout for this one\n            request. It may be a float (in seconds) or an instance of\n            :class:`urllib3.util.Timeout`.\n    \n        :param pool_timeout:\n            If set and the pool is set to block=True, then this method will\n            block for ``pool_timeout`` seconds and raise EmptyPoolError if no\n            connection is available within the time period.\n    \n        :param release_conn:\n            If False, then the urlopen call will not release the connection\n            back into the pool once a response is received (but will release if\n            you read the entire contents of the response such as when\n            `preload_content=True`). This is useful if you&#39;re not preloading\n            the response&#39;s content immediately. You will need to call\n            ``r.release_conn()`` on the response ``r`` to return the connection\n            back into the pool. If None, it takes the value of\n            ``response_kw.get(&#39;preload_content&#39;, True)``.\n    \n        :param chunked:\n            If True, urllib3 will send the body using chunked transfer\n            encoding. Otherwise, urllib3 will send the body using the standard\n            content-length form. Defaults to False.\n    \n        :param int body_pos:\n            Position to seek to in file-like body in the event of a retry or\n            redirect. Typically this won&#39;t need to be set because urllib3 will\n            auto-populate the value when needed.\n    \n        :param \\\\**response_kw:\n            Additional parameters are passed to\n            :meth:`urllib3.response.HTTPResponse.from_httplib`\n        \&#34;\&#34;\&#34;\n    \n        parsed_url = parse_url(url)\n        destination_scheme = parsed_url.scheme\n    \n        if headers is None:\n            headers = self.headers\n    \n        if not isinstance(retries, Retry):\n            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)\n    \n        if release_conn is None:\n            release_conn = response_kw.get(\&#34;preload_content\&#34;, True)\n    \n        # Check host\n        if assert_same_host and not self.is_same_host(url):\n            raise HostChangedError(self, url, retries)\n    \n        # Ensure that the URL we&#39;re connecting to is properly encoded\n        if url.startswith(\&#34;/\&#34;):\n            url = six.ensure_str(_encode_target(url))\n        else:\n            url = six.ensure_str(parsed_url.url)\n    \n        conn = None\n    \n        # Track whether `conn` needs to be released before\n        # returning/raising/recursing. Update this variable if necessary, and\n        # leave `release_conn` constant throughout the function. That way, if\n        # the function recurses, the original value of `release_conn` will be\n        # passed down into the recursive call, and its value will be respected.\n        #\n        # See issue #651 [1] for details.\n        #\n        # [1] &amp;lt;https://github.com/urllib3/urllib3/issues/651&amp;gt;\n        release_this_conn = release_conn\n    \n        http_tunnel_required = connection_requires_http_tunnel(\n            self.proxy, self.proxy_config, destination_scheme\n        )\n    \n        # Merge the proxy headers. Only done when not using HTTP CONNECT. We\n        # have to copy the headers dict so we can safely change it without those\n        # changes being reflected in anyone else&#39;s copy.\n        if not http_tunnel_required:\n            headers = headers.copy()\n            headers.update(self.proxy_headers)\n    \n        # Must keep the exception bound to a separate variable or else Python 3\n        # complains about UnboundLocalError.\n        err = None\n    \n        # Keep track of whether we cleanly exited the except block. This\n        # ensures we do proper cleanup in finally.\n        clean_exit = False\n    \n        # Rewind body position, if needed. Record current position\n        # for future rewinds in the event of a redirect/retry.\n        body_pos = set_file_position(body, body_pos)\n    \n        try:\n            # Request a connection from the queue.\n            timeout_obj = self._get_timeout(timeout)\n            conn = self._get_conn(timeout=pool_timeout)\n    \n            conn.timeout = timeout_obj.connect_timeout\n    \n            is_new_proxy_conn = self.proxy is not None and not getattr(\n                conn, \&#34;sock\&#34;, None\n            )\n            if is_new_proxy_conn and http_tunnel_required:\n                self._prepare_proxy(conn)\n    \n            # Make the request on the httplib connection object.\n&amp;gt;           httplib_response = self._make_request(\n                conn,\n                method,\n                url,\n                timeout=timeout_obj,\n                body=body,\n                headers=headers,\n                chunked=chunked,\n            )\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:715: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:404: in _make_request\n    self._validate_conn(conn)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1058: in _validate_conn\n    conn.connect()\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connection.py:363: in connect\n    self.sock = conn = self._new_conn()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;\n\n    def _new_conn(self):\n        \&#34;\&#34;\&#34;Establish a socket connection and set nodelay settings on it.\n    \n        :return: New socket connection.\n        \&#34;\&#34;\&#34;\n        extra_kw = {}\n        if self.source_address:\n            extra_kw[\&#34;source_address\&#34;] = self.source_address\n    \n        if self.socket_options:\n            extra_kw[\&#34;socket_options\&#34;] = self.socket_options\n    \n        try:\n            conn = connection.create_connection(\n                (self._dns_host, self.port), self.timeout, **extra_kw\n            )\n    \n        except SocketTimeout:\n            raise ConnectTimeoutError(\n                self,\n                \&#34;Connection to %s timed out. (connect timeout=%s)\&#34;\n                % (self.host, self.timeout),\n            )\n    \n        except SocketError as e:\n&amp;gt;           raise NewConnectionError(\n                self, \&#34;Failed to establish a new connection: %s\&#34; % e\n            )\nE           urllib3.exceptions.NewConnectionError: &amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;: Failed to establish a new connection: [Errno 11001] getaddrinfo failed\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connection.py:186: NewConnectionError\n\nDuring handling of the above exception, another exception occurred:\n\nself = &amp;lt;requests.adapters.HTTPAdapter object at 0x000002487F34AA10&amp;gt;, request = &amp;lt;PreparedRequest [GET]&amp;gt;, stream = True, timeout = Timeout(connect=None, read=None, total=None)\nverify = True, cert = None, proxies = OrderedDict()\n\n    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):\n        \&#34;\&#34;\&#34;Sends PreparedRequest object. Returns Response object.\n    \n        :param request: The :class:`PreparedRequest &amp;lt;PreparedRequest&amp;gt;` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) &amp;lt;timeouts&amp;gt;` tuple.\n        :type timeout: float or tuple or urllib3 Timeout object\n        :param verify: (optional) Either a boolean, in which case it controls whether\n            we verify the server&#39;s TLS certificate, or a string, in which case it\n            must be a path to a CA bundle to use\n        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        :rtype: requests.Response\n        \&#34;\&#34;\&#34;\n    \n        try:\n            conn = self.get_connection(request.url, proxies)\n        except LocationValueError as e:\n            raise InvalidURL(e, request=request)\n    \n        self.cert_verify(conn, request.url, verify, cert)\n        url = self.request_url(request, proxies)\n        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)\n    \n        chunked = not (request.body is None or &#39;Content-Length&#39; in request.headers)\n    \n        if isinstance(timeout, tuple):\n            try:\n                connect, read = timeout\n                timeout = TimeoutSauce(connect=connect, read=read)\n            except ValueError as e:\n                # this may raise a string formatting error.\n                err = (\&#34;Invalid timeout {}. Pass a (connect, read) \&#34;\n                       \&#34;timeout tuple, or a single float to set \&#34;\n                       \&#34;both timeouts to the same value\&#34;.format(timeout))\n                raise ValueError(err)\n        elif isinstance(timeout, TimeoutSauce):\n            pass\n        else:\n            timeout = TimeoutSauce(connect=timeout, read=timeout)\n    \n        try:\n            if not chunked:\n&amp;gt;               resp = conn.urlopen(\n                    method=request.method,\n                    url=url,\n                    body=request.body,\n                    headers=request.headers,\n                    redirect=False,\n                    assert_same_host=False,\n                    preload_content=False,\n                    decode_content=False,\n                    retries=self.max_retries,\n                    timeout=timeout\n                )\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\adapters.py:440: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:799: in urlopen\n    retries = retries.increment(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = Retry(total=0, connect=None, read=False, redirect=None, status=None), method = &#39;GET&#39;, url = &#39;/chrome-for-testing/known-good-versions-with-downloads.json&#39;\nresponse = None\nerror = NewConnectionError(&#39;&amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;: Failed to establish a new connection: [Errno 11001] getaddrinfo failed&#39;)\n_pool = &amp;lt;urllib3.connectionpool.HTTPSConnectionPool object at 0x000002487F354910&amp;gt;, _stacktrace = &amp;lt;traceback object at 0x000002487F354FC0&amp;gt;\n\n    def increment(\n        self,\n        method=None,\n        url=None,\n        response=None,\n        error=None,\n        _pool=None,\n        _stacktrace=None,\n    ):\n        \&#34;\&#34;\&#34;Return a new Retry object with incremented retry counters.\n    \n        :param response: A response object, or None, if the server did not\n            return a response.\n        :type response: :class:`~urllib3.response.HTTPResponse`\n        :param Exception error: An error encountered during the request, or\n            None if the response was received successfully.\n    \n        :return: A new ``Retry`` object.\n        \&#34;\&#34;\&#34;\n        if self.total is False and error:\n            # Disabled, indicate to re-raise the error.\n            raise six.reraise(type(error), error, _stacktrace)\n    \n        total = self.total\n        if total is not None:\n            total -= 1\n    \n        connect = self.connect\n        read = self.read\n        redirect = self.redirect\n        status_count = self.status\n        other = self.other\n        cause = \&#34;unknown\&#34;\n        status = None\n        redirect_location = None\n    \n        if error and self._is_connection_error(error):\n            # Connect retry?\n            if connect is False:\n                raise six.reraise(type(error), error, _stacktrace)\n            elif connect is not None:\n                connect -= 1\n    \n        elif error and self._is_read_error(error):\n            # Read retry?\n            if read is False or not self._is_method_retryable(method):\n                raise six.reraise(type(error), error, _stacktrace)\n            elif read is not None:\n                read -= 1\n    \n        elif error:\n            # Other retry?\n            if other is not None:\n                other -= 1\n    \n        elif response and response.get_redirect_location():\n            # Redirect retry?\n            if redirect is not None:\n                redirect -= 1\n            cause = \&#34;too many redirects\&#34;\n            redirect_location = response.get_redirect_location()\n            status = response.status\n    \n        else:\n            # Incrementing because of a server error like a 500 in\n            # status_forcelist and the given method is in the allowed_methods\n            cause = ResponseError.GENERIC_ERROR\n            if response and response.status:\n                if status_count is not None:\n                    status_count -= 1\n                cause = ResponseError.SPECIFIC_ERROR.format(status_code=response.status)\n                status = response.status\n    \n        history = self.history + (\n            RequestHistory(method, url, error, status, redirect_location),\n        )\n    \n        new_retry = self.new(\n            total=total,\n            connect=connect,\n            read=read,\n            redirect=redirect,\n            status=status_count,\n            other=other,\n            history=history,\n        )\n    \n        if new_retry.is_exhausted():\n&amp;gt;           raise MaxRetryError(_pool, url, error or ResponseError(cause))\nE           urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host=&#39;googlechromelabs.github.io&#39;, port=443): Max retries exceeded with url: /chrome-for-testing/known-good-versions-with-downloads.json (Caused by NewConnectionError(&#39;&amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;: Failed to establish a new connection: [Errno 11001] getaddrinfo failed&#39;))\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\util\\retry.py:592: MaxRetryError\n\nDuring handling of the above exception, another exception occurred:\n\nself = &amp;lt;webdriver_manager.core.http.WDMHttpClient object at 0x000002487F2E6990&amp;gt;\nurl = &#39;https://googlechromelabs.github.io/chrome-for-testing/known-good-versions-with-downloads.json&#39;, kwargs = {}\n\n    def get(self, url, **kwargs) -&amp;gt; Response:\n        try:\n&amp;gt;           resp = requests.get(\n                url=url, verify=self._ssl_verify, stream=True, **kwargs)\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\core\\http.py:32: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\api.py:75: in get\n    return request(&#39;get&#39;, url, params=params, **kwargs)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\api.py:61: in request\n    return session.request(method=method, url=url, **kwargs)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\sessions.py:529: in request\n    resp = self.send(prep, **send_kwargs)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\sessions.py:645: in send\n    r = adapter.send(request, **kwargs)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;requests.adapters.HTTPAdapter object at 0x000002487F34AA10&amp;gt;, request = &amp;lt;PreparedRequest [GET]&amp;gt;, stream = True, timeout = Timeout(connect=None, read=None, total=None)\nverify = True, cert = None, proxies = OrderedDict()\n\n    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):\n        \&#34;\&#34;\&#34;Sends PreparedRequest object. Returns Response object.\n    \n        :param request: The :class:`PreparedRequest &amp;lt;PreparedRequest&amp;gt;` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) &amp;lt;timeouts&amp;gt;` tuple.\n        :type timeout: float or tuple or urllib3 Timeout object\n        :param verify: (optional) Either a boolean, in which case it controls whether\n            we verify the server&#39;s TLS certificate, or a string, in which case it\n            must be a path to a CA bundle to use\n        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        :rtype: requests.Response\n        \&#34;\&#34;\&#34;\n    \n        try:\n            conn = self.get_connection(request.url, proxies)\n        except LocationValueError as e:\n            raise InvalidURL(e, request=request)\n    \n        self.cert_verify(conn, request.url, verify, cert)\n        url = self.request_url(request, proxies)\n        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)\n    \n        chunked = not (request.body is None or &#39;Content-Length&#39; in request.headers)\n    \n        if isinstance(timeout, tuple):\n            try:\n                connect, read = timeout\n                timeout = TimeoutSauce(connect=connect, read=read)\n            except ValueError as e:\n                # this may raise a string formatting error.\n                err = (\&#34;Invalid timeout {}. Pass a (connect, read) \&#34;\n                       \&#34;timeout tuple, or a single float to set \&#34;\n                       \&#34;both timeouts to the same value\&#34;.format(timeout))\n                raise ValueError(err)\n        elif isinstance(timeout, TimeoutSauce):\n            pass\n        else:\n            timeout = TimeoutSauce(connect=timeout, read=timeout)\n    \n        try:\n            if not chunked:\n                resp = conn.urlopen(\n                    method=request.method,\n                    url=url,\n                    body=request.body,\n                    headers=request.headers,\n                    redirect=False,\n                    assert_same_host=False,\n                    preload_content=False,\n                    decode_content=False,\n                    retries=self.max_retries,\n                    timeout=timeout\n                )\n    \n            # Send the request.\n            else:\n                if hasattr(conn, &#39;proxy_pool&#39;):\n                    conn = conn.proxy_pool\n    \n                low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)\n    \n                try:\n                    skip_host = &#39;Host&#39; in request.headers\n                    low_conn.putrequest(request.method,\n                                        url,\n                                        skip_accept_encoding=True,\n                                        skip_host=skip_host)\n    \n                    for header, value in request.headers.items():\n                        low_conn.putheader(header, value)\n    \n                    low_conn.endheaders()\n    \n                    for i in request.body:\n                        low_conn.send(hex(len(i))[2:].encode(&#39;utf-8&#39;))\n                        low_conn.send(b&#39;\\r\\n&#39;)\n                        low_conn.send(i)\n                        low_conn.send(b&#39;\\r\\n&#39;)\n                    low_conn.send(b&#39;0\\r\\n\\r\\n&#39;)\n    \n                    # Receive the response from the server\n                    try:\n                        # For Python 2.7, use buffering of HTTP responses\n                        r = low_conn.getresponse(buffering=True)\n                    except TypeError:\n                        # For compatibility with Python 3.3+\n                        r = low_conn.getresponse()\n    \n                    resp = HTTPResponse.from_httplib(\n                        r,\n                        pool=conn,\n                        connection=low_conn,\n                        preload_content=False,\n                        decode_content=False\n                    )\n                except:\n                    # If we hit any problems here, clean up the connection.\n                    # Then, reraise so that we can handle the actual exception.\n                    low_conn.close()\n                    raise\n    \n        except (ProtocolError, socket.error) as err:\n            raise ConnectionError(err, request=request)\n    \n        except MaxRetryError as e:\n            if isinstance(e.reason, ConnectTimeoutError):\n                # TODO: Remove this in 3.0.0: see #2811\n                if not isinstance(e.reason, NewConnectionError):\n                    raise ConnectTimeout(e, request=request)\n    \n            if isinstance(e.reason, ResponseError):\n                raise RetryError(e, request=request)\n    \n            if isinstance(e.reason, _ProxyError):\n                raise ProxyError(e, request=request)\n    \n            if isinstance(e.reason, _SSLError):\n                # This branch is for urllib3 v1.22 and later.\n                raise SSLError(e, request=request)\n    \n&amp;gt;           raise ConnectionError(e, request=request)\nE           requests.exceptions.ConnectionError: HTTPSConnectionPool(host=&#39;googlechromelabs.github.io&#39;, port=443): Max retries exceeded with url: /chrome-for-testing/known-good-versions-with-downloads.json (Caused by NewConnectionError(&#39;&amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;: Failed to establish a new connection: [Errno 11001] getaddrinfo failed&#39;))\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\adapters.py:519: ConnectionError\n\nDuring handling of the above exception, another exception occurred:\n\n    @pytest.fixture(scope=\&#34;module\&#34;)\n    def driver():\n        options = Options()\n        options.add_experimental_option(\&#34;detach\&#34;, True)\n        #driver = webdriver.Chrome(options=options)\n&amp;gt;       driver = webdriver.Chrome(options=options, service=Service(ChromeDriverManager().install()))\n\nSingle_bucket_sim.py:27: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\chrome.py:40: in install\n    driver_path = self._get_driver_binary_path(self.driver)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\core\\manager.py:40: in _get_driver_binary_path\n    file = self._download_manager.download_file(driver.get_driver_download_url(os_type))\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\drivers\\chrome.py:44: in get_driver_download_url\n    modern_version_url = self.get_url_for_version_and_platform(driver_version_to_download, os_type)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\drivers\\chrome.py:69: in get_url_for_version_and_platform\n    response = self._http_client.get(url)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;webdriver_manager.core.http.WDMHttpClient object at 0x000002487F2E6990&amp;gt;\nurl = &#39;https://googlechromelabs.github.io/chrome-for-testing/known-good-versions-with-downloads.json&#39;, kwargs = {}\n\n    def get(self, url, **kwargs) -&amp;gt; Response:\n        try:\n            resp = requests.get(\n                url=url, verify=self._ssl_verify, stream=True, **kwargs)\n        except exceptions.ConnectionError:\n&amp;gt;           raise exceptions.ConnectionError(f\&#34;Could not reach host. Are you offline?\&#34;)\nE           requests.exceptions.ConnectionError: Could not reach host. Are you offline?\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\core\\http.py:35: ConnectionError\n&#34;}], &#34;Single_bucket_sim.py::test_click_next_button_1&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Error&#34;, &#34;testId&#34;: &#34;Single_bucket_sim.py::test_click_next_button_1::setup&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Error&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;Single_bucket_sim.py::test_click_next_button_1::setup&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;\n\n    def _new_conn(self):\n        \&#34;\&#34;\&#34;Establish a socket connection and set nodelay settings on it.\n    \n        :return: New socket connection.\n        \&#34;\&#34;\&#34;\n        extra_kw = {}\n        if self.source_address:\n            extra_kw[\&#34;source_address\&#34;] = self.source_address\n    \n        if self.socket_options:\n            extra_kw[\&#34;socket_options\&#34;] = self.socket_options\n    \n        try:\n&amp;gt;           conn = connection.create_connection(\n                (self._dns_host, self.port), self.timeout, **extra_kw\n            )\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connection.py:174: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\util\\connection.py:72: in create_connection\n    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nhost = &#39;googlechromelabs.github.io&#39;, port = 443, family = &amp;lt;AddressFamily.AF_UNSPEC: 0&amp;gt;, type = &amp;lt;SocketKind.SOCK_STREAM: 1&amp;gt;, proto = 0, flags = 0\n\n    def getaddrinfo(host, port, family=0, type=0, proto=0, flags=0):\n        \&#34;\&#34;\&#34;Resolve host and port into list of address info entries.\n    \n        Translate the host/port argument into a sequence of 5-tuples that contain\n        all the necessary arguments for creating a socket connected to that service.\n        host is a domain name, a string representation of an IPv4/v6 address or\n        None. port is a string service name such as &#39;http&#39;, a numeric port number or\n        None. By passing None as the value of host and port, you can pass NULL to\n        the underlying C API.\n    \n        The family, type and proto arguments can be optionally specified in order to\n        narrow the list of addresses returned. Passing zero as a value for each of\n        these arguments selects the full range of results.\n        \&#34;\&#34;\&#34;\n        # We override this function since we want to translate the numeric family\n        # and socket type values to enum constants.\n        addrlist = []\n&amp;gt;       for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\nE       socket.gaierror: [Errno 11001] getaddrinfo failed\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\socket.py:962: gaierror\n\nDuring handling of the above exception, another exception occurred:\n\nself = &amp;lt;urllib3.connectionpool.HTTPSConnectionPool object at 0x000002487F354910&amp;gt;, method = &#39;GET&#39;, url = &#39;/chrome-for-testing/known-good-versions-with-downloads.json&#39;\nbody = None, headers = {&#39;User-Agent&#39;: &#39;python-requests/2.27.1&#39;, &#39;Accept-Encoding&#39;: &#39;gzip, deflate&#39;, &#39;Accept&#39;: &#39;*/*&#39;, &#39;Connection&#39;: &#39;keep-alive&#39;}\nretries = Retry(total=0, connect=None, read=False, redirect=None, status=None), redirect = False, assert_same_host = False\ntimeout = Timeout(connect=None, read=None, total=None), pool_timeout = None, release_conn = False, chunked = False, body_pos = None\nresponse_kw = {&#39;decode_content&#39;: False, &#39;preload_content&#39;: False}\nparsed_url = Url(scheme=None, auth=None, host=None, port=None, path=&#39;/chrome-for-testing/known-good-versions-with-downloads.json&#39;, query=None, fragment=None)\ndestination_scheme = None, conn = None, release_this_conn = True, http_tunnel_required = False, err = None, clean_exit = False\n\n    def urlopen(\n        self,\n        method,\n        url,\n        body=None,\n        headers=None,\n        retries=None,\n        redirect=True,\n        assert_same_host=True,\n        timeout=_Default,\n        pool_timeout=None,\n        release_conn=None,\n        chunked=False,\n        body_pos=None,\n        **response_kw\n    ):\n        \&#34;\&#34;\&#34;\n        Get a connection from the pool and perform an HTTP request. This is the\n        lowest level call for making a request, so you&#39;ll need to specify all\n        the raw details.\n    \n        .. note::\n    \n           More commonly, it&#39;s appropriate to use a convenience method provided\n           by :class:`.RequestMethods`, such as :meth:`request`.\n    \n        .. note::\n    \n           `release_conn` will only behave as expected if\n           `preload_content=False` because we want to make\n           `preload_content=False` the default behaviour someday soon without\n           breaking backwards compatibility.\n    \n        :param method:\n            HTTP request method (such as GET, POST, PUT, etc.)\n    \n        :param url:\n            The URL to perform the request on.\n    \n        :param body:\n            Data to send in the request body, either :class:`str`, :class:`bytes`,\n            an iterable of :class:`str`/:class:`bytes`, or a file-like object.\n    \n        :param headers:\n            Dictionary of custom headers to send, such as User-Agent,\n            If-None-Match, etc. If None, pool headers are used. If provided,\n            these headers completely replace any pool-specific headers.\n    \n        :param retries:\n            Configure the number of retries to allow before raising a\n            :class:`~urllib3.exceptions.MaxRetryError` exception.\n    \n            Pass ``None`` to retry until you receive a response. Pass a\n            :class:`~urllib3.util.retry.Retry` object for fine-grained control\n            over different types of retries.\n            Pass an integer number to retry connection errors that many times,\n            but no other types of errors. Pass zero to never retry.\n    \n            If ``False``, then retries are disabled and any exception is raised\n            immediately. Also, instead of raising a MaxRetryError on redirects,\n            the redirect response will be returned.\n    \n        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.\n    \n        :param redirect:\n            If True, automatically handle redirects (status codes 301, 302,\n            303, 307, 308). Each redirect counts as a retry. Disabling retries\n            will disable redirect, too.\n    \n        :param assert_same_host:\n            If ``True``, will make sure that the host of the pool requests is\n            consistent else will raise HostChangedError. When ``False``, you can\n            use the pool on an HTTP proxy and request foreign hosts.\n    \n        :param timeout:\n            If specified, overrides the default timeout for this one\n            request. It may be a float (in seconds) or an instance of\n            :class:`urllib3.util.Timeout`.\n    \n        :param pool_timeout:\n            If set and the pool is set to block=True, then this method will\n            block for ``pool_timeout`` seconds and raise EmptyPoolError if no\n            connection is available within the time period.\n    \n        :param release_conn:\n            If False, then the urlopen call will not release the connection\n            back into the pool once a response is received (but will release if\n            you read the entire contents of the response such as when\n            `preload_content=True`). This is useful if you&#39;re not preloading\n            the response&#39;s content immediately. You will need to call\n            ``r.release_conn()`` on the response ``r`` to return the connection\n            back into the pool. If None, it takes the value of\n            ``response_kw.get(&#39;preload_content&#39;, True)``.\n    \n        :param chunked:\n            If True, urllib3 will send the body using chunked transfer\n            encoding. Otherwise, urllib3 will send the body using the standard\n            content-length form. Defaults to False.\n    \n        :param int body_pos:\n            Position to seek to in file-like body in the event of a retry or\n            redirect. Typically this won&#39;t need to be set because urllib3 will\n            auto-populate the value when needed.\n    \n        :param \\\\**response_kw:\n            Additional parameters are passed to\n            :meth:`urllib3.response.HTTPResponse.from_httplib`\n        \&#34;\&#34;\&#34;\n    \n        parsed_url = parse_url(url)\n        destination_scheme = parsed_url.scheme\n    \n        if headers is None:\n            headers = self.headers\n    \n        if not isinstance(retries, Retry):\n            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)\n    \n        if release_conn is None:\n            release_conn = response_kw.get(\&#34;preload_content\&#34;, True)\n    \n        # Check host\n        if assert_same_host and not self.is_same_host(url):\n            raise HostChangedError(self, url, retries)\n    \n        # Ensure that the URL we&#39;re connecting to is properly encoded\n        if url.startswith(\&#34;/\&#34;):\n            url = six.ensure_str(_encode_target(url))\n        else:\n            url = six.ensure_str(parsed_url.url)\n    \n        conn = None\n    \n        # Track whether `conn` needs to be released before\n        # returning/raising/recursing. Update this variable if necessary, and\n        # leave `release_conn` constant throughout the function. That way, if\n        # the function recurses, the original value of `release_conn` will be\n        # passed down into the recursive call, and its value will be respected.\n        #\n        # See issue #651 [1] for details.\n        #\n        # [1] &amp;lt;https://github.com/urllib3/urllib3/issues/651&amp;gt;\n        release_this_conn = release_conn\n    \n        http_tunnel_required = connection_requires_http_tunnel(\n            self.proxy, self.proxy_config, destination_scheme\n        )\n    \n        # Merge the proxy headers. Only done when not using HTTP CONNECT. We\n        # have to copy the headers dict so we can safely change it without those\n        # changes being reflected in anyone else&#39;s copy.\n        if not http_tunnel_required:\n            headers = headers.copy()\n            headers.update(self.proxy_headers)\n    \n        # Must keep the exception bound to a separate variable or else Python 3\n        # complains about UnboundLocalError.\n        err = None\n    \n        # Keep track of whether we cleanly exited the except block. This\n        # ensures we do proper cleanup in finally.\n        clean_exit = False\n    \n        # Rewind body position, if needed. Record current position\n        # for future rewinds in the event of a redirect/retry.\n        body_pos = set_file_position(body, body_pos)\n    \n        try:\n            # Request a connection from the queue.\n            timeout_obj = self._get_timeout(timeout)\n            conn = self._get_conn(timeout=pool_timeout)\n    \n            conn.timeout = timeout_obj.connect_timeout\n    \n            is_new_proxy_conn = self.proxy is not None and not getattr(\n                conn, \&#34;sock\&#34;, None\n            )\n            if is_new_proxy_conn and http_tunnel_required:\n                self._prepare_proxy(conn)\n    \n            # Make the request on the httplib connection object.\n&amp;gt;           httplib_response = self._make_request(\n                conn,\n                method,\n                url,\n                timeout=timeout_obj,\n                body=body,\n                headers=headers,\n                chunked=chunked,\n            )\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:715: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:404: in _make_request\n    self._validate_conn(conn)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1058: in _validate_conn\n    conn.connect()\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connection.py:363: in connect\n    self.sock = conn = self._new_conn()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;\n\n    def _new_conn(self):\n        \&#34;\&#34;\&#34;Establish a socket connection and set nodelay settings on it.\n    \n        :return: New socket connection.\n        \&#34;\&#34;\&#34;\n        extra_kw = {}\n        if self.source_address:\n            extra_kw[\&#34;source_address\&#34;] = self.source_address\n    \n        if self.socket_options:\n            extra_kw[\&#34;socket_options\&#34;] = self.socket_options\n    \n        try:\n            conn = connection.create_connection(\n                (self._dns_host, self.port), self.timeout, **extra_kw\n            )\n    \n        except SocketTimeout:\n            raise ConnectTimeoutError(\n                self,\n                \&#34;Connection to %s timed out. (connect timeout=%s)\&#34;\n                % (self.host, self.timeout),\n            )\n    \n        except SocketError as e:\n&amp;gt;           raise NewConnectionError(\n                self, \&#34;Failed to establish a new connection: %s\&#34; % e\n            )\nE           urllib3.exceptions.NewConnectionError: &amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;: Failed to establish a new connection: [Errno 11001] getaddrinfo failed\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connection.py:186: NewConnectionError\n\nDuring handling of the above exception, another exception occurred:\n\nself = &amp;lt;requests.adapters.HTTPAdapter object at 0x000002487F34AA10&amp;gt;, request = &amp;lt;PreparedRequest [GET]&amp;gt;, stream = True, timeout = Timeout(connect=None, read=None, total=None)\nverify = True, cert = None, proxies = OrderedDict()\n\n    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):\n        \&#34;\&#34;\&#34;Sends PreparedRequest object. Returns Response object.\n    \n        :param request: The :class:`PreparedRequest &amp;lt;PreparedRequest&amp;gt;` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) &amp;lt;timeouts&amp;gt;` tuple.\n        :type timeout: float or tuple or urllib3 Timeout object\n        :param verify: (optional) Either a boolean, in which case it controls whether\n            we verify the server&#39;s TLS certificate, or a string, in which case it\n            must be a path to a CA bundle to use\n        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        :rtype: requests.Response\n        \&#34;\&#34;\&#34;\n    \n        try:\n            conn = self.get_connection(request.url, proxies)\n        except LocationValueError as e:\n            raise InvalidURL(e, request=request)\n    \n        self.cert_verify(conn, request.url, verify, cert)\n        url = self.request_url(request, proxies)\n        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)\n    \n        chunked = not (request.body is None or &#39;Content-Length&#39; in request.headers)\n    \n        if isinstance(timeout, tuple):\n            try:\n                connect, read = timeout\n                timeout = TimeoutSauce(connect=connect, read=read)\n            except ValueError as e:\n                # this may raise a string formatting error.\n                err = (\&#34;Invalid timeout {}. Pass a (connect, read) \&#34;\n                       \&#34;timeout tuple, or a single float to set \&#34;\n                       \&#34;both timeouts to the same value\&#34;.format(timeout))\n                raise ValueError(err)\n        elif isinstance(timeout, TimeoutSauce):\n            pass\n        else:\n            timeout = TimeoutSauce(connect=timeout, read=timeout)\n    \n        try:\n            if not chunked:\n&amp;gt;               resp = conn.urlopen(\n                    method=request.method,\n                    url=url,\n                    body=request.body,\n                    headers=request.headers,\n                    redirect=False,\n                    assert_same_host=False,\n                    preload_content=False,\n                    decode_content=False,\n                    retries=self.max_retries,\n                    timeout=timeout\n                )\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\adapters.py:440: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:799: in urlopen\n    retries = retries.increment(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = Retry(total=0, connect=None, read=False, redirect=None, status=None), method = &#39;GET&#39;, url = &#39;/chrome-for-testing/known-good-versions-with-downloads.json&#39;\nresponse = None\nerror = NewConnectionError(&#39;&amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;: Failed to establish a new connection: [Errno 11001] getaddrinfo failed&#39;)\n_pool = &amp;lt;urllib3.connectionpool.HTTPSConnectionPool object at 0x000002487F354910&amp;gt;, _stacktrace = &amp;lt;traceback object at 0x000002487F354FC0&amp;gt;\n\n    def increment(\n        self,\n        method=None,\n        url=None,\n        response=None,\n        error=None,\n        _pool=None,\n        _stacktrace=None,\n    ):\n        \&#34;\&#34;\&#34;Return a new Retry object with incremented retry counters.\n    \n        :param response: A response object, or None, if the server did not\n            return a response.\n        :type response: :class:`~urllib3.response.HTTPResponse`\n        :param Exception error: An error encountered during the request, or\n            None if the response was received successfully.\n    \n        :return: A new ``Retry`` object.\n        \&#34;\&#34;\&#34;\n        if self.total is False and error:\n            # Disabled, indicate to re-raise the error.\n            raise six.reraise(type(error), error, _stacktrace)\n    \n        total = self.total\n        if total is not None:\n            total -= 1\n    \n        connect = self.connect\n        read = self.read\n        redirect = self.redirect\n        status_count = self.status\n        other = self.other\n        cause = \&#34;unknown\&#34;\n        status = None\n        redirect_location = None\n    \n        if error and self._is_connection_error(error):\n            # Connect retry?\n            if connect is False:\n                raise six.reraise(type(error), error, _stacktrace)\n            elif connect is not None:\n                connect -= 1\n    \n        elif error and self._is_read_error(error):\n            # Read retry?\n            if read is False or not self._is_method_retryable(method):\n                raise six.reraise(type(error), error, _stacktrace)\n            elif read is not None:\n                read -= 1\n    \n        elif error:\n            # Other retry?\n            if other is not None:\n                other -= 1\n    \n        elif response and response.get_redirect_location():\n            # Redirect retry?\n            if redirect is not None:\n                redirect -= 1\n            cause = \&#34;too many redirects\&#34;\n            redirect_location = response.get_redirect_location()\n            status = response.status\n    \n        else:\n            # Incrementing because of a server error like a 500 in\n            # status_forcelist and the given method is in the allowed_methods\n            cause = ResponseError.GENERIC_ERROR\n            if response and response.status:\n                if status_count is not None:\n                    status_count -= 1\n                cause = ResponseError.SPECIFIC_ERROR.format(status_code=response.status)\n                status = response.status\n    \n        history = self.history + (\n            RequestHistory(method, url, error, status, redirect_location),\n        )\n    \n        new_retry = self.new(\n            total=total,\n            connect=connect,\n            read=read,\n            redirect=redirect,\n            status=status_count,\n            other=other,\n            history=history,\n        )\n    \n        if new_retry.is_exhausted():\n&amp;gt;           raise MaxRetryError(_pool, url, error or ResponseError(cause))\nE           urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host=&#39;googlechromelabs.github.io&#39;, port=443): Max retries exceeded with url: /chrome-for-testing/known-good-versions-with-downloads.json (Caused by NewConnectionError(&#39;&amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;: Failed to establish a new connection: [Errno 11001] getaddrinfo failed&#39;))\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\util\\retry.py:592: MaxRetryError\n\nDuring handling of the above exception, another exception occurred:\n\nself = &amp;lt;webdriver_manager.core.http.WDMHttpClient object at 0x000002487F2E6990&amp;gt;\nurl = &#39;https://googlechromelabs.github.io/chrome-for-testing/known-good-versions-with-downloads.json&#39;, kwargs = {}\n\n    def get(self, url, **kwargs) -&amp;gt; Response:\n        try:\n&amp;gt;           resp = requests.get(\n                url=url, verify=self._ssl_verify, stream=True, **kwargs)\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\core\\http.py:32: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\api.py:75: in get\n    return request(&#39;get&#39;, url, params=params, **kwargs)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\api.py:61: in request\n    return session.request(method=method, url=url, **kwargs)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\sessions.py:529: in request\n    resp = self.send(prep, **send_kwargs)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\sessions.py:645: in send\n    r = adapter.send(request, **kwargs)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;requests.adapters.HTTPAdapter object at 0x000002487F34AA10&amp;gt;, request = &amp;lt;PreparedRequest [GET]&amp;gt;, stream = True, timeout = Timeout(connect=None, read=None, total=None)\nverify = True, cert = None, proxies = OrderedDict()\n\n    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):\n        \&#34;\&#34;\&#34;Sends PreparedRequest object. Returns Response object.\n    \n        :param request: The :class:`PreparedRequest &amp;lt;PreparedRequest&amp;gt;` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) &amp;lt;timeouts&amp;gt;` tuple.\n        :type timeout: float or tuple or urllib3 Timeout object\n        :param verify: (optional) Either a boolean, in which case it controls whether\n            we verify the server&#39;s TLS certificate, or a string, in which case it\n            must be a path to a CA bundle to use\n        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        :rtype: requests.Response\n        \&#34;\&#34;\&#34;\n    \n        try:\n            conn = self.get_connection(request.url, proxies)\n        except LocationValueError as e:\n            raise InvalidURL(e, request=request)\n    \n        self.cert_verify(conn, request.url, verify, cert)\n        url = self.request_url(request, proxies)\n        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)\n    \n        chunked = not (request.body is None or &#39;Content-Length&#39; in request.headers)\n    \n        if isinstance(timeout, tuple):\n            try:\n                connect, read = timeout\n                timeout = TimeoutSauce(connect=connect, read=read)\n            except ValueError as e:\n                # this may raise a string formatting error.\n                err = (\&#34;Invalid timeout {}. Pass a (connect, read) \&#34;\n                       \&#34;timeout tuple, or a single float to set \&#34;\n                       \&#34;both timeouts to the same value\&#34;.format(timeout))\n                raise ValueError(err)\n        elif isinstance(timeout, TimeoutSauce):\n            pass\n        else:\n            timeout = TimeoutSauce(connect=timeout, read=timeout)\n    \n        try:\n            if not chunked:\n                resp = conn.urlopen(\n                    method=request.method,\n                    url=url,\n                    body=request.body,\n                    headers=request.headers,\n                    redirect=False,\n                    assert_same_host=False,\n                    preload_content=False,\n                    decode_content=False,\n                    retries=self.max_retries,\n                    timeout=timeout\n                )\n    \n            # Send the request.\n            else:\n                if hasattr(conn, &#39;proxy_pool&#39;):\n                    conn = conn.proxy_pool\n    \n                low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)\n    \n                try:\n                    skip_host = &#39;Host&#39; in request.headers\n                    low_conn.putrequest(request.method,\n                                        url,\n                                        skip_accept_encoding=True,\n                                        skip_host=skip_host)\n    \n                    for header, value in request.headers.items():\n                        low_conn.putheader(header, value)\n    \n                    low_conn.endheaders()\n    \n                    for i in request.body:\n                        low_conn.send(hex(len(i))[2:].encode(&#39;utf-8&#39;))\n                        low_conn.send(b&#39;\\r\\n&#39;)\n                        low_conn.send(i)\n                        low_conn.send(b&#39;\\r\\n&#39;)\n                    low_conn.send(b&#39;0\\r\\n\\r\\n&#39;)\n    \n                    # Receive the response from the server\n                    try:\n                        # For Python 2.7, use buffering of HTTP responses\n                        r = low_conn.getresponse(buffering=True)\n                    except TypeError:\n                        # For compatibility with Python 3.3+\n                        r = low_conn.getresponse()\n    \n                    resp = HTTPResponse.from_httplib(\n                        r,\n                        pool=conn,\n                        connection=low_conn,\n                        preload_content=False,\n                        decode_content=False\n                    )\n                except:\n                    # If we hit any problems here, clean up the connection.\n                    # Then, reraise so that we can handle the actual exception.\n                    low_conn.close()\n                    raise\n    \n        except (ProtocolError, socket.error) as err:\n            raise ConnectionError(err, request=request)\n    \n        except MaxRetryError as e:\n            if isinstance(e.reason, ConnectTimeoutError):\n                # TODO: Remove this in 3.0.0: see #2811\n                if not isinstance(e.reason, NewConnectionError):\n                    raise ConnectTimeout(e, request=request)\n    \n            if isinstance(e.reason, ResponseError):\n                raise RetryError(e, request=request)\n    \n            if isinstance(e.reason, _ProxyError):\n                raise ProxyError(e, request=request)\n    \n            if isinstance(e.reason, _SSLError):\n                # This branch is for urllib3 v1.22 and later.\n                raise SSLError(e, request=request)\n    \n&amp;gt;           raise ConnectionError(e, request=request)\nE           requests.exceptions.ConnectionError: HTTPSConnectionPool(host=&#39;googlechromelabs.github.io&#39;, port=443): Max retries exceeded with url: /chrome-for-testing/known-good-versions-with-downloads.json (Caused by NewConnectionError(&#39;&amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;: Failed to establish a new connection: [Errno 11001] getaddrinfo failed&#39;))\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\adapters.py:519: ConnectionError\n\nDuring handling of the above exception, another exception occurred:\n\n    @pytest.fixture(scope=\&#34;module\&#34;)\n    def driver():\n        options = Options()\n        options.add_experimental_option(\&#34;detach\&#34;, True)\n        #driver = webdriver.Chrome(options=options)\n&amp;gt;       driver = webdriver.Chrome(options=options, service=Service(ChromeDriverManager().install()))\n\nSingle_bucket_sim.py:27: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\chrome.py:40: in install\n    driver_path = self._get_driver_binary_path(self.driver)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\core\\manager.py:40: in _get_driver_binary_path\n    file = self._download_manager.download_file(driver.get_driver_download_url(os_type))\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\drivers\\chrome.py:44: in get_driver_download_url\n    modern_version_url = self.get_url_for_version_and_platform(driver_version_to_download, os_type)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\drivers\\chrome.py:69: in get_url_for_version_and_platform\n    response = self._http_client.get(url)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;webdriver_manager.core.http.WDMHttpClient object at 0x000002487F2E6990&amp;gt;\nurl = &#39;https://googlechromelabs.github.io/chrome-for-testing/known-good-versions-with-downloads.json&#39;, kwargs = {}\n\n    def get(self, url, **kwargs) -&amp;gt; Response:\n        try:\n            resp = requests.get(\n                url=url, verify=self._ssl_verify, stream=True, **kwargs)\n        except exceptions.ConnectionError:\n&amp;gt;           raise exceptions.ConnectionError(f\&#34;Could not reach host. Are you offline?\&#34;)\nE           requests.exceptions.ConnectionError: Could not reach host. Are you offline?\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\core\\http.py:35: ConnectionError\n&#34;}], &#34;Single_bucket_sim.py::test_click_next_button_2&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Error&#34;, &#34;testId&#34;: &#34;Single_bucket_sim.py::test_click_next_button_2::setup&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Error&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;Single_bucket_sim.py::test_click_next_button_2::setup&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;\n\n    def _new_conn(self):\n        \&#34;\&#34;\&#34;Establish a socket connection and set nodelay settings on it.\n    \n        :return: New socket connection.\n        \&#34;\&#34;\&#34;\n        extra_kw = {}\n        if self.source_address:\n            extra_kw[\&#34;source_address\&#34;] = self.source_address\n    \n        if self.socket_options:\n            extra_kw[\&#34;socket_options\&#34;] = self.socket_options\n    \n        try:\n&amp;gt;           conn = connection.create_connection(\n                (self._dns_host, self.port), self.timeout, **extra_kw\n            )\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connection.py:174: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\util\\connection.py:72: in create_connection\n    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nhost = &#39;googlechromelabs.github.io&#39;, port = 443, family = &amp;lt;AddressFamily.AF_UNSPEC: 0&amp;gt;, type = &amp;lt;SocketKind.SOCK_STREAM: 1&amp;gt;, proto = 0, flags = 0\n\n    def getaddrinfo(host, port, family=0, type=0, proto=0, flags=0):\n        \&#34;\&#34;\&#34;Resolve host and port into list of address info entries.\n    \n        Translate the host/port argument into a sequence of 5-tuples that contain\n        all the necessary arguments for creating a socket connected to that service.\n        host is a domain name, a string representation of an IPv4/v6 address or\n        None. port is a string service name such as &#39;http&#39;, a numeric port number or\n        None. By passing None as the value of host and port, you can pass NULL to\n        the underlying C API.\n    \n        The family, type and proto arguments can be optionally specified in order to\n        narrow the list of addresses returned. Passing zero as a value for each of\n        these arguments selects the full range of results.\n        \&#34;\&#34;\&#34;\n        # We override this function since we want to translate the numeric family\n        # and socket type values to enum constants.\n        addrlist = []\n&amp;gt;       for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\nE       socket.gaierror: [Errno 11001] getaddrinfo failed\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\socket.py:962: gaierror\n\nDuring handling of the above exception, another exception occurred:\n\nself = &amp;lt;urllib3.connectionpool.HTTPSConnectionPool object at 0x000002487F354910&amp;gt;, method = &#39;GET&#39;, url = &#39;/chrome-for-testing/known-good-versions-with-downloads.json&#39;\nbody = None, headers = {&#39;User-Agent&#39;: &#39;python-requests/2.27.1&#39;, &#39;Accept-Encoding&#39;: &#39;gzip, deflate&#39;, &#39;Accept&#39;: &#39;*/*&#39;, &#39;Connection&#39;: &#39;keep-alive&#39;}\nretries = Retry(total=0, connect=None, read=False, redirect=None, status=None), redirect = False, assert_same_host = False\ntimeout = Timeout(connect=None, read=None, total=None), pool_timeout = None, release_conn = False, chunked = False, body_pos = None\nresponse_kw = {&#39;decode_content&#39;: False, &#39;preload_content&#39;: False}\nparsed_url = Url(scheme=None, auth=None, host=None, port=None, path=&#39;/chrome-for-testing/known-good-versions-with-downloads.json&#39;, query=None, fragment=None)\ndestination_scheme = None, conn = None, release_this_conn = True, http_tunnel_required = False, err = None, clean_exit = False\n\n    def urlopen(\n        self,\n        method,\n        url,\n        body=None,\n        headers=None,\n        retries=None,\n        redirect=True,\n        assert_same_host=True,\n        timeout=_Default,\n        pool_timeout=None,\n        release_conn=None,\n        chunked=False,\n        body_pos=None,\n        **response_kw\n    ):\n        \&#34;\&#34;\&#34;\n        Get a connection from the pool and perform an HTTP request. This is the\n        lowest level call for making a request, so you&#39;ll need to specify all\n        the raw details.\n    \n        .. note::\n    \n           More commonly, it&#39;s appropriate to use a convenience method provided\n           by :class:`.RequestMethods`, such as :meth:`request`.\n    \n        .. note::\n    \n           `release_conn` will only behave as expected if\n           `preload_content=False` because we want to make\n           `preload_content=False` the default behaviour someday soon without\n           breaking backwards compatibility.\n    \n        :param method:\n            HTTP request method (such as GET, POST, PUT, etc.)\n    \n        :param url:\n            The URL to perform the request on.\n    \n        :param body:\n            Data to send in the request body, either :class:`str`, :class:`bytes`,\n            an iterable of :class:`str`/:class:`bytes`, or a file-like object.\n    \n        :param headers:\n            Dictionary of custom headers to send, such as User-Agent,\n            If-None-Match, etc. If None, pool headers are used. If provided,\n            these headers completely replace any pool-specific headers.\n    \n        :param retries:\n            Configure the number of retries to allow before raising a\n            :class:`~urllib3.exceptions.MaxRetryError` exception.\n    \n            Pass ``None`` to retry until you receive a response. Pass a\n            :class:`~urllib3.util.retry.Retry` object for fine-grained control\n            over different types of retries.\n            Pass an integer number to retry connection errors that many times,\n            but no other types of errors. Pass zero to never retry.\n    \n            If ``False``, then retries are disabled and any exception is raised\n            immediately. Also, instead of raising a MaxRetryError on redirects,\n            the redirect response will be returned.\n    \n        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.\n    \n        :param redirect:\n            If True, automatically handle redirects (status codes 301, 302,\n            303, 307, 308). Each redirect counts as a retry. Disabling retries\n            will disable redirect, too.\n    \n        :param assert_same_host:\n            If ``True``, will make sure that the host of the pool requests is\n            consistent else will raise HostChangedError. When ``False``, you can\n            use the pool on an HTTP proxy and request foreign hosts.\n    \n        :param timeout:\n            If specified, overrides the default timeout for this one\n            request. It may be a float (in seconds) or an instance of\n            :class:`urllib3.util.Timeout`.\n    \n        :param pool_timeout:\n            If set and the pool is set to block=True, then this method will\n            block for ``pool_timeout`` seconds and raise EmptyPoolError if no\n            connection is available within the time period.\n    \n        :param release_conn:\n            If False, then the urlopen call will not release the connection\n            back into the pool once a response is received (but will release if\n            you read the entire contents of the response such as when\n            `preload_content=True`). This is useful if you&#39;re not preloading\n            the response&#39;s content immediately. You will need to call\n            ``r.release_conn()`` on the response ``r`` to return the connection\n            back into the pool. If None, it takes the value of\n            ``response_kw.get(&#39;preload_content&#39;, True)``.\n    \n        :param chunked:\n            If True, urllib3 will send the body using chunked transfer\n            encoding. Otherwise, urllib3 will send the body using the standard\n            content-length form. Defaults to False.\n    \n        :param int body_pos:\n            Position to seek to in file-like body in the event of a retry or\n            redirect. Typically this won&#39;t need to be set because urllib3 will\n            auto-populate the value when needed.\n    \n        :param \\\\**response_kw:\n            Additional parameters are passed to\n            :meth:`urllib3.response.HTTPResponse.from_httplib`\n        \&#34;\&#34;\&#34;\n    \n        parsed_url = parse_url(url)\n        destination_scheme = parsed_url.scheme\n    \n        if headers is None:\n            headers = self.headers\n    \n        if not isinstance(retries, Retry):\n            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)\n    \n        if release_conn is None:\n            release_conn = response_kw.get(\&#34;preload_content\&#34;, True)\n    \n        # Check host\n        if assert_same_host and not self.is_same_host(url):\n            raise HostChangedError(self, url, retries)\n    \n        # Ensure that the URL we&#39;re connecting to is properly encoded\n        if url.startswith(\&#34;/\&#34;):\n            url = six.ensure_str(_encode_target(url))\n        else:\n            url = six.ensure_str(parsed_url.url)\n    \n        conn = None\n    \n        # Track whether `conn` needs to be released before\n        # returning/raising/recursing. Update this variable if necessary, and\n        # leave `release_conn` constant throughout the function. That way, if\n        # the function recurses, the original value of `release_conn` will be\n        # passed down into the recursive call, and its value will be respected.\n        #\n        # See issue #651 [1] for details.\n        #\n        # [1] &amp;lt;https://github.com/urllib3/urllib3/issues/651&amp;gt;\n        release_this_conn = release_conn\n    \n        http_tunnel_required = connection_requires_http_tunnel(\n            self.proxy, self.proxy_config, destination_scheme\n        )\n    \n        # Merge the proxy headers. Only done when not using HTTP CONNECT. We\n        # have to copy the headers dict so we can safely change it without those\n        # changes being reflected in anyone else&#39;s copy.\n        if not http_tunnel_required:\n            headers = headers.copy()\n            headers.update(self.proxy_headers)\n    \n        # Must keep the exception bound to a separate variable or else Python 3\n        # complains about UnboundLocalError.\n        err = None\n    \n        # Keep track of whether we cleanly exited the except block. This\n        # ensures we do proper cleanup in finally.\n        clean_exit = False\n    \n        # Rewind body position, if needed. Record current position\n        # for future rewinds in the event of a redirect/retry.\n        body_pos = set_file_position(body, body_pos)\n    \n        try:\n            # Request a connection from the queue.\n            timeout_obj = self._get_timeout(timeout)\n            conn = self._get_conn(timeout=pool_timeout)\n    \n            conn.timeout = timeout_obj.connect_timeout\n    \n            is_new_proxy_conn = self.proxy is not None and not getattr(\n                conn, \&#34;sock\&#34;, None\n            )\n            if is_new_proxy_conn and http_tunnel_required:\n                self._prepare_proxy(conn)\n    \n            # Make the request on the httplib connection object.\n&amp;gt;           httplib_response = self._make_request(\n                conn,\n                method,\n                url,\n                timeout=timeout_obj,\n                body=body,\n                headers=headers,\n                chunked=chunked,\n            )\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:715: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:404: in _make_request\n    self._validate_conn(conn)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1058: in _validate_conn\n    conn.connect()\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connection.py:363: in connect\n    self.sock = conn = self._new_conn()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;\n\n    def _new_conn(self):\n        \&#34;\&#34;\&#34;Establish a socket connection and set nodelay settings on it.\n    \n        :return: New socket connection.\n        \&#34;\&#34;\&#34;\n        extra_kw = {}\n        if self.source_address:\n            extra_kw[\&#34;source_address\&#34;] = self.source_address\n    \n        if self.socket_options:\n            extra_kw[\&#34;socket_options\&#34;] = self.socket_options\n    \n        try:\n            conn = connection.create_connection(\n                (self._dns_host, self.port), self.timeout, **extra_kw\n            )\n    \n        except SocketTimeout:\n            raise ConnectTimeoutError(\n                self,\n                \&#34;Connection to %s timed out. (connect timeout=%s)\&#34;\n                % (self.host, self.timeout),\n            )\n    \n        except SocketError as e:\n&amp;gt;           raise NewConnectionError(\n                self, \&#34;Failed to establish a new connection: %s\&#34; % e\n            )\nE           urllib3.exceptions.NewConnectionError: &amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;: Failed to establish a new connection: [Errno 11001] getaddrinfo failed\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connection.py:186: NewConnectionError\n\nDuring handling of the above exception, another exception occurred:\n\nself = &amp;lt;requests.adapters.HTTPAdapter object at 0x000002487F34AA10&amp;gt;, request = &amp;lt;PreparedRequest [GET]&amp;gt;, stream = True, timeout = Timeout(connect=None, read=None, total=None)\nverify = True, cert = None, proxies = OrderedDict()\n\n    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):\n        \&#34;\&#34;\&#34;Sends PreparedRequest object. Returns Response object.\n    \n        :param request: The :class:`PreparedRequest &amp;lt;PreparedRequest&amp;gt;` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) &amp;lt;timeouts&amp;gt;` tuple.\n        :type timeout: float or tuple or urllib3 Timeout object\n        :param verify: (optional) Either a boolean, in which case it controls whether\n            we verify the server&#39;s TLS certificate, or a string, in which case it\n            must be a path to a CA bundle to use\n        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        :rtype: requests.Response\n        \&#34;\&#34;\&#34;\n    \n        try:\n            conn = self.get_connection(request.url, proxies)\n        except LocationValueError as e:\n            raise InvalidURL(e, request=request)\n    \n        self.cert_verify(conn, request.url, verify, cert)\n        url = self.request_url(request, proxies)\n        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)\n    \n        chunked = not (request.body is None or &#39;Content-Length&#39; in request.headers)\n    \n        if isinstance(timeout, tuple):\n            try:\n                connect, read = timeout\n                timeout = TimeoutSauce(connect=connect, read=read)\n            except ValueError as e:\n                # this may raise a string formatting error.\n                err = (\&#34;Invalid timeout {}. Pass a (connect, read) \&#34;\n                       \&#34;timeout tuple, or a single float to set \&#34;\n                       \&#34;both timeouts to the same value\&#34;.format(timeout))\n                raise ValueError(err)\n        elif isinstance(timeout, TimeoutSauce):\n            pass\n        else:\n            timeout = TimeoutSauce(connect=timeout, read=timeout)\n    \n        try:\n            if not chunked:\n&amp;gt;               resp = conn.urlopen(\n                    method=request.method,\n                    url=url,\n                    body=request.body,\n                    headers=request.headers,\n                    redirect=False,\n                    assert_same_host=False,\n                    preload_content=False,\n                    decode_content=False,\n                    retries=self.max_retries,\n                    timeout=timeout\n                )\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\adapters.py:440: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:799: in urlopen\n    retries = retries.increment(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = Retry(total=0, connect=None, read=False, redirect=None, status=None), method = &#39;GET&#39;, url = &#39;/chrome-for-testing/known-good-versions-with-downloads.json&#39;\nresponse = None\nerror = NewConnectionError(&#39;&amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;: Failed to establish a new connection: [Errno 11001] getaddrinfo failed&#39;)\n_pool = &amp;lt;urllib3.connectionpool.HTTPSConnectionPool object at 0x000002487F354910&amp;gt;, _stacktrace = &amp;lt;traceback object at 0x000002487F354FC0&amp;gt;\n\n    def increment(\n        self,\n        method=None,\n        url=None,\n        response=None,\n        error=None,\n        _pool=None,\n        _stacktrace=None,\n    ):\n        \&#34;\&#34;\&#34;Return a new Retry object with incremented retry counters.\n    \n        :param response: A response object, or None, if the server did not\n            return a response.\n        :type response: :class:`~urllib3.response.HTTPResponse`\n        :param Exception error: An error encountered during the request, or\n            None if the response was received successfully.\n    \n        :return: A new ``Retry`` object.\n        \&#34;\&#34;\&#34;\n        if self.total is False and error:\n            # Disabled, indicate to re-raise the error.\n            raise six.reraise(type(error), error, _stacktrace)\n    \n        total = self.total\n        if total is not None:\n            total -= 1\n    \n        connect = self.connect\n        read = self.read\n        redirect = self.redirect\n        status_count = self.status\n        other = self.other\n        cause = \&#34;unknown\&#34;\n        status = None\n        redirect_location = None\n    \n        if error and self._is_connection_error(error):\n            # Connect retry?\n            if connect is False:\n                raise six.reraise(type(error), error, _stacktrace)\n            elif connect is not None:\n                connect -= 1\n    \n        elif error and self._is_read_error(error):\n            # Read retry?\n            if read is False or not self._is_method_retryable(method):\n                raise six.reraise(type(error), error, _stacktrace)\n            elif read is not None:\n                read -= 1\n    \n        elif error:\n            # Other retry?\n            if other is not None:\n                other -= 1\n    \n        elif response and response.get_redirect_location():\n            # Redirect retry?\n            if redirect is not None:\n                redirect -= 1\n            cause = \&#34;too many redirects\&#34;\n            redirect_location = response.get_redirect_location()\n            status = response.status\n    \n        else:\n            # Incrementing because of a server error like a 500 in\n            # status_forcelist and the given method is in the allowed_methods\n            cause = ResponseError.GENERIC_ERROR\n            if response and response.status:\n                if status_count is not None:\n                    status_count -= 1\n                cause = ResponseError.SPECIFIC_ERROR.format(status_code=response.status)\n                status = response.status\n    \n        history = self.history + (\n            RequestHistory(method, url, error, status, redirect_location),\n        )\n    \n        new_retry = self.new(\n            total=total,\n            connect=connect,\n            read=read,\n            redirect=redirect,\n            status=status_count,\n            other=other,\n            history=history,\n        )\n    \n        if new_retry.is_exhausted():\n&amp;gt;           raise MaxRetryError(_pool, url, error or ResponseError(cause))\nE           urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host=&#39;googlechromelabs.github.io&#39;, port=443): Max retries exceeded with url: /chrome-for-testing/known-good-versions-with-downloads.json (Caused by NewConnectionError(&#39;&amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;: Failed to establish a new connection: [Errno 11001] getaddrinfo failed&#39;))\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\util\\retry.py:592: MaxRetryError\n\nDuring handling of the above exception, another exception occurred:\n\nself = &amp;lt;webdriver_manager.core.http.WDMHttpClient object at 0x000002487F2E6990&amp;gt;\nurl = &#39;https://googlechromelabs.github.io/chrome-for-testing/known-good-versions-with-downloads.json&#39;, kwargs = {}\n\n    def get(self, url, **kwargs) -&amp;gt; Response:\n        try:\n&amp;gt;           resp = requests.get(\n                url=url, verify=self._ssl_verify, stream=True, **kwargs)\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\core\\http.py:32: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\api.py:75: in get\n    return request(&#39;get&#39;, url, params=params, **kwargs)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\api.py:61: in request\n    return session.request(method=method, url=url, **kwargs)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\sessions.py:529: in request\n    resp = self.send(prep, **send_kwargs)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\sessions.py:645: in send\n    r = adapter.send(request, **kwargs)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;requests.adapters.HTTPAdapter object at 0x000002487F34AA10&amp;gt;, request = &amp;lt;PreparedRequest [GET]&amp;gt;, stream = True, timeout = Timeout(connect=None, read=None, total=None)\nverify = True, cert = None, proxies = OrderedDict()\n\n    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):\n        \&#34;\&#34;\&#34;Sends PreparedRequest object. Returns Response object.\n    \n        :param request: The :class:`PreparedRequest &amp;lt;PreparedRequest&amp;gt;` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) &amp;lt;timeouts&amp;gt;` tuple.\n        :type timeout: float or tuple or urllib3 Timeout object\n        :param verify: (optional) Either a boolean, in which case it controls whether\n            we verify the server&#39;s TLS certificate, or a string, in which case it\n            must be a path to a CA bundle to use\n        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        :rtype: requests.Response\n        \&#34;\&#34;\&#34;\n    \n        try:\n            conn = self.get_connection(request.url, proxies)\n        except LocationValueError as e:\n            raise InvalidURL(e, request=request)\n    \n        self.cert_verify(conn, request.url, verify, cert)\n        url = self.request_url(request, proxies)\n        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)\n    \n        chunked = not (request.body is None or &#39;Content-Length&#39; in request.headers)\n    \n        if isinstance(timeout, tuple):\n            try:\n                connect, read = timeout\n                timeout = TimeoutSauce(connect=connect, read=read)\n            except ValueError as e:\n                # this may raise a string formatting error.\n                err = (\&#34;Invalid timeout {}. Pass a (connect, read) \&#34;\n                       \&#34;timeout tuple, or a single float to set \&#34;\n                       \&#34;both timeouts to the same value\&#34;.format(timeout))\n                raise ValueError(err)\n        elif isinstance(timeout, TimeoutSauce):\n            pass\n        else:\n            timeout = TimeoutSauce(connect=timeout, read=timeout)\n    \n        try:\n            if not chunked:\n                resp = conn.urlopen(\n                    method=request.method,\n                    url=url,\n                    body=request.body,\n                    headers=request.headers,\n                    redirect=False,\n                    assert_same_host=False,\n                    preload_content=False,\n                    decode_content=False,\n                    retries=self.max_retries,\n                    timeout=timeout\n                )\n    \n            # Send the request.\n            else:\n                if hasattr(conn, &#39;proxy_pool&#39;):\n                    conn = conn.proxy_pool\n    \n                low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)\n    \n                try:\n                    skip_host = &#39;Host&#39; in request.headers\n                    low_conn.putrequest(request.method,\n                                        url,\n                                        skip_accept_encoding=True,\n                                        skip_host=skip_host)\n    \n                    for header, value in request.headers.items():\n                        low_conn.putheader(header, value)\n    \n                    low_conn.endheaders()\n    \n                    for i in request.body:\n                        low_conn.send(hex(len(i))[2:].encode(&#39;utf-8&#39;))\n                        low_conn.send(b&#39;\\r\\n&#39;)\n                        low_conn.send(i)\n                        low_conn.send(b&#39;\\r\\n&#39;)\n                    low_conn.send(b&#39;0\\r\\n\\r\\n&#39;)\n    \n                    # Receive the response from the server\n                    try:\n                        # For Python 2.7, use buffering of HTTP responses\n                        r = low_conn.getresponse(buffering=True)\n                    except TypeError:\n                        # For compatibility with Python 3.3+\n                        r = low_conn.getresponse()\n    \n                    resp = HTTPResponse.from_httplib(\n                        r,\n                        pool=conn,\n                        connection=low_conn,\n                        preload_content=False,\n                        decode_content=False\n                    )\n                except:\n                    # If we hit any problems here, clean up the connection.\n                    # Then, reraise so that we can handle the actual exception.\n                    low_conn.close()\n                    raise\n    \n        except (ProtocolError, socket.error) as err:\n            raise ConnectionError(err, request=request)\n    \n        except MaxRetryError as e:\n            if isinstance(e.reason, ConnectTimeoutError):\n                # TODO: Remove this in 3.0.0: see #2811\n                if not isinstance(e.reason, NewConnectionError):\n                    raise ConnectTimeout(e, request=request)\n    \n            if isinstance(e.reason, ResponseError):\n                raise RetryError(e, request=request)\n    \n            if isinstance(e.reason, _ProxyError):\n                raise ProxyError(e, request=request)\n    \n            if isinstance(e.reason, _SSLError):\n                # This branch is for urllib3 v1.22 and later.\n                raise SSLError(e, request=request)\n    \n&amp;gt;           raise ConnectionError(e, request=request)\nE           requests.exceptions.ConnectionError: HTTPSConnectionPool(host=&#39;googlechromelabs.github.io&#39;, port=443): Max retries exceeded with url: /chrome-for-testing/known-good-versions-with-downloads.json (Caused by NewConnectionError(&#39;&amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;: Failed to establish a new connection: [Errno 11001] getaddrinfo failed&#39;))\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\adapters.py:519: ConnectionError\n\nDuring handling of the above exception, another exception occurred:\n\n    @pytest.fixture(scope=\&#34;module\&#34;)\n    def driver():\n        options = Options()\n        options.add_experimental_option(\&#34;detach\&#34;, True)\n        #driver = webdriver.Chrome(options=options)\n&amp;gt;       driver = webdriver.Chrome(options=options, service=Service(ChromeDriverManager().install()))\n\nSingle_bucket_sim.py:27: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\chrome.py:40: in install\n    driver_path = self._get_driver_binary_path(self.driver)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\core\\manager.py:40: in _get_driver_binary_path\n    file = self._download_manager.download_file(driver.get_driver_download_url(os_type))\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\drivers\\chrome.py:44: in get_driver_download_url\n    modern_version_url = self.get_url_for_version_and_platform(driver_version_to_download, os_type)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\drivers\\chrome.py:69: in get_url_for_version_and_platform\n    response = self._http_client.get(url)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;webdriver_manager.core.http.WDMHttpClient object at 0x000002487F2E6990&amp;gt;\nurl = &#39;https://googlechromelabs.github.io/chrome-for-testing/known-good-versions-with-downloads.json&#39;, kwargs = {}\n\n    def get(self, url, **kwargs) -&amp;gt; Response:\n        try:\n            resp = requests.get(\n                url=url, verify=self._ssl_verify, stream=True, **kwargs)\n        except exceptions.ConnectionError:\n&amp;gt;           raise exceptions.ConnectionError(f\&#34;Could not reach host. Are you offline?\&#34;)\nE           requests.exceptions.ConnectionError: Could not reach host. Are you offline?\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\core\\http.py:35: ConnectionError\n&#34;}], &#34;Single_bucket_sim.py::test_click_next_button_3&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Error&#34;, &#34;testId&#34;: &#34;Single_bucket_sim.py::test_click_next_button_3::setup&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Error&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;Single_bucket_sim.py::test_click_next_button_3::setup&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;\n\n    def _new_conn(self):\n        \&#34;\&#34;\&#34;Establish a socket connection and set nodelay settings on it.\n    \n        :return: New socket connection.\n        \&#34;\&#34;\&#34;\n        extra_kw = {}\n        if self.source_address:\n            extra_kw[\&#34;source_address\&#34;] = self.source_address\n    \n        if self.socket_options:\n            extra_kw[\&#34;socket_options\&#34;] = self.socket_options\n    \n        try:\n&amp;gt;           conn = connection.create_connection(\n                (self._dns_host, self.port), self.timeout, **extra_kw\n            )\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connection.py:174: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\util\\connection.py:72: in create_connection\n    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nhost = &#39;googlechromelabs.github.io&#39;, port = 443, family = &amp;lt;AddressFamily.AF_UNSPEC: 0&amp;gt;, type = &amp;lt;SocketKind.SOCK_STREAM: 1&amp;gt;, proto = 0, flags = 0\n\n    def getaddrinfo(host, port, family=0, type=0, proto=0, flags=0):\n        \&#34;\&#34;\&#34;Resolve host and port into list of address info entries.\n    \n        Translate the host/port argument into a sequence of 5-tuples that contain\n        all the necessary arguments for creating a socket connected to that service.\n        host is a domain name, a string representation of an IPv4/v6 address or\n        None. port is a string service name such as &#39;http&#39;, a numeric port number or\n        None. By passing None as the value of host and port, you can pass NULL to\n        the underlying C API.\n    \n        The family, type and proto arguments can be optionally specified in order to\n        narrow the list of addresses returned. Passing zero as a value for each of\n        these arguments selects the full range of results.\n        \&#34;\&#34;\&#34;\n        # We override this function since we want to translate the numeric family\n        # and socket type values to enum constants.\n        addrlist = []\n&amp;gt;       for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\nE       socket.gaierror: [Errno 11001] getaddrinfo failed\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\socket.py:962: gaierror\n\nDuring handling of the above exception, another exception occurred:\n\nself = &amp;lt;urllib3.connectionpool.HTTPSConnectionPool object at 0x000002487F354910&amp;gt;, method = &#39;GET&#39;, url = &#39;/chrome-for-testing/known-good-versions-with-downloads.json&#39;\nbody = None, headers = {&#39;User-Agent&#39;: &#39;python-requests/2.27.1&#39;, &#39;Accept-Encoding&#39;: &#39;gzip, deflate&#39;, &#39;Accept&#39;: &#39;*/*&#39;, &#39;Connection&#39;: &#39;keep-alive&#39;}\nretries = Retry(total=0, connect=None, read=False, redirect=None, status=None), redirect = False, assert_same_host = False\ntimeout = Timeout(connect=None, read=None, total=None), pool_timeout = None, release_conn = False, chunked = False, body_pos = None\nresponse_kw = {&#39;decode_content&#39;: False, &#39;preload_content&#39;: False}\nparsed_url = Url(scheme=None, auth=None, host=None, port=None, path=&#39;/chrome-for-testing/known-good-versions-with-downloads.json&#39;, query=None, fragment=None)\ndestination_scheme = None, conn = None, release_this_conn = True, http_tunnel_required = False, err = None, clean_exit = False\n\n    def urlopen(\n        self,\n        method,\n        url,\n        body=None,\n        headers=None,\n        retries=None,\n        redirect=True,\n        assert_same_host=True,\n        timeout=_Default,\n        pool_timeout=None,\n        release_conn=None,\n        chunked=False,\n        body_pos=None,\n        **response_kw\n    ):\n        \&#34;\&#34;\&#34;\n        Get a connection from the pool and perform an HTTP request. This is the\n        lowest level call for making a request, so you&#39;ll need to specify all\n        the raw details.\n    \n        .. note::\n    \n           More commonly, it&#39;s appropriate to use a convenience method provided\n           by :class:`.RequestMethods`, such as :meth:`request`.\n    \n        .. note::\n    \n           `release_conn` will only behave as expected if\n           `preload_content=False` because we want to make\n           `preload_content=False` the default behaviour someday soon without\n           breaking backwards compatibility.\n    \n        :param method:\n            HTTP request method (such as GET, POST, PUT, etc.)\n    \n        :param url:\n            The URL to perform the request on.\n    \n        :param body:\n            Data to send in the request body, either :class:`str`, :class:`bytes`,\n            an iterable of :class:`str`/:class:`bytes`, or a file-like object.\n    \n        :param headers:\n            Dictionary of custom headers to send, such as User-Agent,\n            If-None-Match, etc. If None, pool headers are used. If provided,\n            these headers completely replace any pool-specific headers.\n    \n        :param retries:\n            Configure the number of retries to allow before raising a\n            :class:`~urllib3.exceptions.MaxRetryError` exception.\n    \n            Pass ``None`` to retry until you receive a response. Pass a\n            :class:`~urllib3.util.retry.Retry` object for fine-grained control\n            over different types of retries.\n            Pass an integer number to retry connection errors that many times,\n            but no other types of errors. Pass zero to never retry.\n    \n            If ``False``, then retries are disabled and any exception is raised\n            immediately. Also, instead of raising a MaxRetryError on redirects,\n            the redirect response will be returned.\n    \n        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.\n    \n        :param redirect:\n            If True, automatically handle redirects (status codes 301, 302,\n            303, 307, 308). Each redirect counts as a retry. Disabling retries\n            will disable redirect, too.\n    \n        :param assert_same_host:\n            If ``True``, will make sure that the host of the pool requests is\n            consistent else will raise HostChangedError. When ``False``, you can\n            use the pool on an HTTP proxy and request foreign hosts.\n    \n        :param timeout:\n            If specified, overrides the default timeout for this one\n            request. It may be a float (in seconds) or an instance of\n            :class:`urllib3.util.Timeout`.\n    \n        :param pool_timeout:\n            If set and the pool is set to block=True, then this method will\n            block for ``pool_timeout`` seconds and raise EmptyPoolError if no\n            connection is available within the time period.\n    \n        :param release_conn:\n            If False, then the urlopen call will not release the connection\n            back into the pool once a response is received (but will release if\n            you read the entire contents of the response such as when\n            `preload_content=True`). This is useful if you&#39;re not preloading\n            the response&#39;s content immediately. You will need to call\n            ``r.release_conn()`` on the response ``r`` to return the connection\n            back into the pool. If None, it takes the value of\n            ``response_kw.get(&#39;preload_content&#39;, True)``.\n    \n        :param chunked:\n            If True, urllib3 will send the body using chunked transfer\n            encoding. Otherwise, urllib3 will send the body using the standard\n            content-length form. Defaults to False.\n    \n        :param int body_pos:\n            Position to seek to in file-like body in the event of a retry or\n            redirect. Typically this won&#39;t need to be set because urllib3 will\n            auto-populate the value when needed.\n    \n        :param \\\\**response_kw:\n            Additional parameters are passed to\n            :meth:`urllib3.response.HTTPResponse.from_httplib`\n        \&#34;\&#34;\&#34;\n    \n        parsed_url = parse_url(url)\n        destination_scheme = parsed_url.scheme\n    \n        if headers is None:\n            headers = self.headers\n    \n        if not isinstance(retries, Retry):\n            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)\n    \n        if release_conn is None:\n            release_conn = response_kw.get(\&#34;preload_content\&#34;, True)\n    \n        # Check host\n        if assert_same_host and not self.is_same_host(url):\n            raise HostChangedError(self, url, retries)\n    \n        # Ensure that the URL we&#39;re connecting to is properly encoded\n        if url.startswith(\&#34;/\&#34;):\n            url = six.ensure_str(_encode_target(url))\n        else:\n            url = six.ensure_str(parsed_url.url)\n    \n        conn = None\n    \n        # Track whether `conn` needs to be released before\n        # returning/raising/recursing. Update this variable if necessary, and\n        # leave `release_conn` constant throughout the function. That way, if\n        # the function recurses, the original value of `release_conn` will be\n        # passed down into the recursive call, and its value will be respected.\n        #\n        # See issue #651 [1] for details.\n        #\n        # [1] &amp;lt;https://github.com/urllib3/urllib3/issues/651&amp;gt;\n        release_this_conn = release_conn\n    \n        http_tunnel_required = connection_requires_http_tunnel(\n            self.proxy, self.proxy_config, destination_scheme\n        )\n    \n        # Merge the proxy headers. Only done when not using HTTP CONNECT. We\n        # have to copy the headers dict so we can safely change it without those\n        # changes being reflected in anyone else&#39;s copy.\n        if not http_tunnel_required:\n            headers = headers.copy()\n            headers.update(self.proxy_headers)\n    \n        # Must keep the exception bound to a separate variable or else Python 3\n        # complains about UnboundLocalError.\n        err = None\n    \n        # Keep track of whether we cleanly exited the except block. This\n        # ensures we do proper cleanup in finally.\n        clean_exit = False\n    \n        # Rewind body position, if needed. Record current position\n        # for future rewinds in the event of a redirect/retry.\n        body_pos = set_file_position(body, body_pos)\n    \n        try:\n            # Request a connection from the queue.\n            timeout_obj = self._get_timeout(timeout)\n            conn = self._get_conn(timeout=pool_timeout)\n    \n            conn.timeout = timeout_obj.connect_timeout\n    \n            is_new_proxy_conn = self.proxy is not None and not getattr(\n                conn, \&#34;sock\&#34;, None\n            )\n            if is_new_proxy_conn and http_tunnel_required:\n                self._prepare_proxy(conn)\n    \n            # Make the request on the httplib connection object.\n&amp;gt;           httplib_response = self._make_request(\n                conn,\n                method,\n                url,\n                timeout=timeout_obj,\n                body=body,\n                headers=headers,\n                chunked=chunked,\n            )\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:715: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:404: in _make_request\n    self._validate_conn(conn)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1058: in _validate_conn\n    conn.connect()\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connection.py:363: in connect\n    self.sock = conn = self._new_conn()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;\n\n    def _new_conn(self):\n        \&#34;\&#34;\&#34;Establish a socket connection and set nodelay settings on it.\n    \n        :return: New socket connection.\n        \&#34;\&#34;\&#34;\n        extra_kw = {}\n        if self.source_address:\n            extra_kw[\&#34;source_address\&#34;] = self.source_address\n    \n        if self.socket_options:\n            extra_kw[\&#34;socket_options\&#34;] = self.socket_options\n    \n        try:\n            conn = connection.create_connection(\n                (self._dns_host, self.port), self.timeout, **extra_kw\n            )\n    \n        except SocketTimeout:\n            raise ConnectTimeoutError(\n                self,\n                \&#34;Connection to %s timed out. (connect timeout=%s)\&#34;\n                % (self.host, self.timeout),\n            )\n    \n        except SocketError as e:\n&amp;gt;           raise NewConnectionError(\n                self, \&#34;Failed to establish a new connection: %s\&#34; % e\n            )\nE           urllib3.exceptions.NewConnectionError: &amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;: Failed to establish a new connection: [Errno 11001] getaddrinfo failed\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connection.py:186: NewConnectionError\n\nDuring handling of the above exception, another exception occurred:\n\nself = &amp;lt;requests.adapters.HTTPAdapter object at 0x000002487F34AA10&amp;gt;, request = &amp;lt;PreparedRequest [GET]&amp;gt;, stream = True, timeout = Timeout(connect=None, read=None, total=None)\nverify = True, cert = None, proxies = OrderedDict()\n\n    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):\n        \&#34;\&#34;\&#34;Sends PreparedRequest object. Returns Response object.\n    \n        :param request: The :class:`PreparedRequest &amp;lt;PreparedRequest&amp;gt;` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) &amp;lt;timeouts&amp;gt;` tuple.\n        :type timeout: float or tuple or urllib3 Timeout object\n        :param verify: (optional) Either a boolean, in which case it controls whether\n            we verify the server&#39;s TLS certificate, or a string, in which case it\n            must be a path to a CA bundle to use\n        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        :rtype: requests.Response\n        \&#34;\&#34;\&#34;\n    \n        try:\n            conn = self.get_connection(request.url, proxies)\n        except LocationValueError as e:\n            raise InvalidURL(e, request=request)\n    \n        self.cert_verify(conn, request.url, verify, cert)\n        url = self.request_url(request, proxies)\n        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)\n    \n        chunked = not (request.body is None or &#39;Content-Length&#39; in request.headers)\n    \n        if isinstance(timeout, tuple):\n            try:\n                connect, read = timeout\n                timeout = TimeoutSauce(connect=connect, read=read)\n            except ValueError as e:\n                # this may raise a string formatting error.\n                err = (\&#34;Invalid timeout {}. Pass a (connect, read) \&#34;\n                       \&#34;timeout tuple, or a single float to set \&#34;\n                       \&#34;both timeouts to the same value\&#34;.format(timeout))\n                raise ValueError(err)\n        elif isinstance(timeout, TimeoutSauce):\n            pass\n        else:\n            timeout = TimeoutSauce(connect=timeout, read=timeout)\n    \n        try:\n            if not chunked:\n&amp;gt;               resp = conn.urlopen(\n                    method=request.method,\n                    url=url,\n                    body=request.body,\n                    headers=request.headers,\n                    redirect=False,\n                    assert_same_host=False,\n                    preload_content=False,\n                    decode_content=False,\n                    retries=self.max_retries,\n                    timeout=timeout\n                )\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\adapters.py:440: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:799: in urlopen\n    retries = retries.increment(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = Retry(total=0, connect=None, read=False, redirect=None, status=None), method = &#39;GET&#39;, url = &#39;/chrome-for-testing/known-good-versions-with-downloads.json&#39;\nresponse = None\nerror = NewConnectionError(&#39;&amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;: Failed to establish a new connection: [Errno 11001] getaddrinfo failed&#39;)\n_pool = &amp;lt;urllib3.connectionpool.HTTPSConnectionPool object at 0x000002487F354910&amp;gt;, _stacktrace = &amp;lt;traceback object at 0x000002487F354FC0&amp;gt;\n\n    def increment(\n        self,\n        method=None,\n        url=None,\n        response=None,\n        error=None,\n        _pool=None,\n        _stacktrace=None,\n    ):\n        \&#34;\&#34;\&#34;Return a new Retry object with incremented retry counters.\n    \n        :param response: A response object, or None, if the server did not\n            return a response.\n        :type response: :class:`~urllib3.response.HTTPResponse`\n        :param Exception error: An error encountered during the request, or\n            None if the response was received successfully.\n    \n        :return: A new ``Retry`` object.\n        \&#34;\&#34;\&#34;\n        if self.total is False and error:\n            # Disabled, indicate to re-raise the error.\n            raise six.reraise(type(error), error, _stacktrace)\n    \n        total = self.total\n        if total is not None:\n            total -= 1\n    \n        connect = self.connect\n        read = self.read\n        redirect = self.redirect\n        status_count = self.status\n        other = self.other\n        cause = \&#34;unknown\&#34;\n        status = None\n        redirect_location = None\n    \n        if error and self._is_connection_error(error):\n            # Connect retry?\n            if connect is False:\n                raise six.reraise(type(error), error, _stacktrace)\n            elif connect is not None:\n                connect -= 1\n    \n        elif error and self._is_read_error(error):\n            # Read retry?\n            if read is False or not self._is_method_retryable(method):\n                raise six.reraise(type(error), error, _stacktrace)\n            elif read is not None:\n                read -= 1\n    \n        elif error:\n            # Other retry?\n            if other is not None:\n                other -= 1\n    \n        elif response and response.get_redirect_location():\n            # Redirect retry?\n            if redirect is not None:\n                redirect -= 1\n            cause = \&#34;too many redirects\&#34;\n            redirect_location = response.get_redirect_location()\n            status = response.status\n    \n        else:\n            # Incrementing because of a server error like a 500 in\n            # status_forcelist and the given method is in the allowed_methods\n            cause = ResponseError.GENERIC_ERROR\n            if response and response.status:\n                if status_count is not None:\n                    status_count -= 1\n                cause = ResponseError.SPECIFIC_ERROR.format(status_code=response.status)\n                status = response.status\n    \n        history = self.history + (\n            RequestHistory(method, url, error, status, redirect_location),\n        )\n    \n        new_retry = self.new(\n            total=total,\n            connect=connect,\n            read=read,\n            redirect=redirect,\n            status=status_count,\n            other=other,\n            history=history,\n        )\n    \n        if new_retry.is_exhausted():\n&amp;gt;           raise MaxRetryError(_pool, url, error or ResponseError(cause))\nE           urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host=&#39;googlechromelabs.github.io&#39;, port=443): Max retries exceeded with url: /chrome-for-testing/known-good-versions-with-downloads.json (Caused by NewConnectionError(&#39;&amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;: Failed to establish a new connection: [Errno 11001] getaddrinfo failed&#39;))\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\util\\retry.py:592: MaxRetryError\n\nDuring handling of the above exception, another exception occurred:\n\nself = &amp;lt;webdriver_manager.core.http.WDMHttpClient object at 0x000002487F2E6990&amp;gt;\nurl = &#39;https://googlechromelabs.github.io/chrome-for-testing/known-good-versions-with-downloads.json&#39;, kwargs = {}\n\n    def get(self, url, **kwargs) -&amp;gt; Response:\n        try:\n&amp;gt;           resp = requests.get(\n                url=url, verify=self._ssl_verify, stream=True, **kwargs)\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\core\\http.py:32: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\api.py:75: in get\n    return request(&#39;get&#39;, url, params=params, **kwargs)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\api.py:61: in request\n    return session.request(method=method, url=url, **kwargs)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\sessions.py:529: in request\n    resp = self.send(prep, **send_kwargs)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\sessions.py:645: in send\n    r = adapter.send(request, **kwargs)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;requests.adapters.HTTPAdapter object at 0x000002487F34AA10&amp;gt;, request = &amp;lt;PreparedRequest [GET]&amp;gt;, stream = True, timeout = Timeout(connect=None, read=None, total=None)\nverify = True, cert = None, proxies = OrderedDict()\n\n    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):\n        \&#34;\&#34;\&#34;Sends PreparedRequest object. Returns Response object.\n    \n        :param request: The :class:`PreparedRequest &amp;lt;PreparedRequest&amp;gt;` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) &amp;lt;timeouts&amp;gt;` tuple.\n        :type timeout: float or tuple or urllib3 Timeout object\n        :param verify: (optional) Either a boolean, in which case it controls whether\n            we verify the server&#39;s TLS certificate, or a string, in which case it\n            must be a path to a CA bundle to use\n        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        :rtype: requests.Response\n        \&#34;\&#34;\&#34;\n    \n        try:\n            conn = self.get_connection(request.url, proxies)\n        except LocationValueError as e:\n            raise InvalidURL(e, request=request)\n    \n        self.cert_verify(conn, request.url, verify, cert)\n        url = self.request_url(request, proxies)\n        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)\n    \n        chunked = not (request.body is None or &#39;Content-Length&#39; in request.headers)\n    \n        if isinstance(timeout, tuple):\n            try:\n                connect, read = timeout\n                timeout = TimeoutSauce(connect=connect, read=read)\n            except ValueError as e:\n                # this may raise a string formatting error.\n                err = (\&#34;Invalid timeout {}. Pass a (connect, read) \&#34;\n                       \&#34;timeout tuple, or a single float to set \&#34;\n                       \&#34;both timeouts to the same value\&#34;.format(timeout))\n                raise ValueError(err)\n        elif isinstance(timeout, TimeoutSauce):\n            pass\n        else:\n            timeout = TimeoutSauce(connect=timeout, read=timeout)\n    \n        try:\n            if not chunked:\n                resp = conn.urlopen(\n                    method=request.method,\n                    url=url,\n                    body=request.body,\n                    headers=request.headers,\n                    redirect=False,\n                    assert_same_host=False,\n                    preload_content=False,\n                    decode_content=False,\n                    retries=self.max_retries,\n                    timeout=timeout\n                )\n    \n            # Send the request.\n            else:\n                if hasattr(conn, &#39;proxy_pool&#39;):\n                    conn = conn.proxy_pool\n    \n                low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)\n    \n                try:\n                    skip_host = &#39;Host&#39; in request.headers\n                    low_conn.putrequest(request.method,\n                                        url,\n                                        skip_accept_encoding=True,\n                                        skip_host=skip_host)\n    \n                    for header, value in request.headers.items():\n                        low_conn.putheader(header, value)\n    \n                    low_conn.endheaders()\n    \n                    for i in request.body:\n                        low_conn.send(hex(len(i))[2:].encode(&#39;utf-8&#39;))\n                        low_conn.send(b&#39;\\r\\n&#39;)\n                        low_conn.send(i)\n                        low_conn.send(b&#39;\\r\\n&#39;)\n                    low_conn.send(b&#39;0\\r\\n\\r\\n&#39;)\n    \n                    # Receive the response from the server\n                    try:\n                        # For Python 2.7, use buffering of HTTP responses\n                        r = low_conn.getresponse(buffering=True)\n                    except TypeError:\n                        # For compatibility with Python 3.3+\n                        r = low_conn.getresponse()\n    \n                    resp = HTTPResponse.from_httplib(\n                        r,\n                        pool=conn,\n                        connection=low_conn,\n                        preload_content=False,\n                        decode_content=False\n                    )\n                except:\n                    # If we hit any problems here, clean up the connection.\n                    # Then, reraise so that we can handle the actual exception.\n                    low_conn.close()\n                    raise\n    \n        except (ProtocolError, socket.error) as err:\n            raise ConnectionError(err, request=request)\n    \n        except MaxRetryError as e:\n            if isinstance(e.reason, ConnectTimeoutError):\n                # TODO: Remove this in 3.0.0: see #2811\n                if not isinstance(e.reason, NewConnectionError):\n                    raise ConnectTimeout(e, request=request)\n    \n            if isinstance(e.reason, ResponseError):\n                raise RetryError(e, request=request)\n    \n            if isinstance(e.reason, _ProxyError):\n                raise ProxyError(e, request=request)\n    \n            if isinstance(e.reason, _SSLError):\n                # This branch is for urllib3 v1.22 and later.\n                raise SSLError(e, request=request)\n    \n&amp;gt;           raise ConnectionError(e, request=request)\nE           requests.exceptions.ConnectionError: HTTPSConnectionPool(host=&#39;googlechromelabs.github.io&#39;, port=443): Max retries exceeded with url: /chrome-for-testing/known-good-versions-with-downloads.json (Caused by NewConnectionError(&#39;&amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;: Failed to establish a new connection: [Errno 11001] getaddrinfo failed&#39;))\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\adapters.py:519: ConnectionError\n\nDuring handling of the above exception, another exception occurred:\n\n    @pytest.fixture(scope=\&#34;module\&#34;)\n    def driver():\n        options = Options()\n        options.add_experimental_option(\&#34;detach\&#34;, True)\n        #driver = webdriver.Chrome(options=options)\n&amp;gt;       driver = webdriver.Chrome(options=options, service=Service(ChromeDriverManager().install()))\n\nSingle_bucket_sim.py:27: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\chrome.py:40: in install\n    driver_path = self._get_driver_binary_path(self.driver)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\core\\manager.py:40: in _get_driver_binary_path\n    file = self._download_manager.download_file(driver.get_driver_download_url(os_type))\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\drivers\\chrome.py:44: in get_driver_download_url\n    modern_version_url = self.get_url_for_version_and_platform(driver_version_to_download, os_type)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\drivers\\chrome.py:69: in get_url_for_version_and_platform\n    response = self._http_client.get(url)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;webdriver_manager.core.http.WDMHttpClient object at 0x000002487F2E6990&amp;gt;\nurl = &#39;https://googlechromelabs.github.io/chrome-for-testing/known-good-versions-with-downloads.json&#39;, kwargs = {}\n\n    def get(self, url, **kwargs) -&amp;gt; Response:\n        try:\n            resp = requests.get(\n                url=url, verify=self._ssl_verify, stream=True, **kwargs)\n        except exceptions.ConnectionError:\n&amp;gt;           raise exceptions.ConnectionError(f\&#34;Could not reach host. Are you offline?\&#34;)\nE           requests.exceptions.ConnectionError: Could not reach host. Are you offline?\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\core\\http.py:35: ConnectionError\n&#34;}], &#34;Single_bucket_sim.py::test_case_summary&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Error&#34;, &#34;testId&#34;: &#34;Single_bucket_sim.py::test_case_summary::setup&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Error&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;Single_bucket_sim.py::test_case_summary::setup&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;\n\n    def _new_conn(self):\n        \&#34;\&#34;\&#34;Establish a socket connection and set nodelay settings on it.\n    \n        :return: New socket connection.\n        \&#34;\&#34;\&#34;\n        extra_kw = {}\n        if self.source_address:\n            extra_kw[\&#34;source_address\&#34;] = self.source_address\n    \n        if self.socket_options:\n            extra_kw[\&#34;socket_options\&#34;] = self.socket_options\n    \n        try:\n&amp;gt;           conn = connection.create_connection(\n                (self._dns_host, self.port), self.timeout, **extra_kw\n            )\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connection.py:174: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\util\\connection.py:72: in create_connection\n    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nhost = &#39;googlechromelabs.github.io&#39;, port = 443, family = &amp;lt;AddressFamily.AF_UNSPEC: 0&amp;gt;, type = &amp;lt;SocketKind.SOCK_STREAM: 1&amp;gt;, proto = 0, flags = 0\n\n    def getaddrinfo(host, port, family=0, type=0, proto=0, flags=0):\n        \&#34;\&#34;\&#34;Resolve host and port into list of address info entries.\n    \n        Translate the host/port argument into a sequence of 5-tuples that contain\n        all the necessary arguments for creating a socket connected to that service.\n        host is a domain name, a string representation of an IPv4/v6 address or\n        None. port is a string service name such as &#39;http&#39;, a numeric port number or\n        None. By passing None as the value of host and port, you can pass NULL to\n        the underlying C API.\n    \n        The family, type and proto arguments can be optionally specified in order to\n        narrow the list of addresses returned. Passing zero as a value for each of\n        these arguments selects the full range of results.\n        \&#34;\&#34;\&#34;\n        # We override this function since we want to translate the numeric family\n        # and socket type values to enum constants.\n        addrlist = []\n&amp;gt;       for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\nE       socket.gaierror: [Errno 11001] getaddrinfo failed\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\socket.py:962: gaierror\n\nDuring handling of the above exception, another exception occurred:\n\nself = &amp;lt;urllib3.connectionpool.HTTPSConnectionPool object at 0x000002487F354910&amp;gt;, method = &#39;GET&#39;, url = &#39;/chrome-for-testing/known-good-versions-with-downloads.json&#39;\nbody = None, headers = {&#39;User-Agent&#39;: &#39;python-requests/2.27.1&#39;, &#39;Accept-Encoding&#39;: &#39;gzip, deflate&#39;, &#39;Accept&#39;: &#39;*/*&#39;, &#39;Connection&#39;: &#39;keep-alive&#39;}\nretries = Retry(total=0, connect=None, read=False, redirect=None, status=None), redirect = False, assert_same_host = False\ntimeout = Timeout(connect=None, read=None, total=None), pool_timeout = None, release_conn = False, chunked = False, body_pos = None\nresponse_kw = {&#39;decode_content&#39;: False, &#39;preload_content&#39;: False}\nparsed_url = Url(scheme=None, auth=None, host=None, port=None, path=&#39;/chrome-for-testing/known-good-versions-with-downloads.json&#39;, query=None, fragment=None)\ndestination_scheme = None, conn = None, release_this_conn = True, http_tunnel_required = False, err = None, clean_exit = False\n\n    def urlopen(\n        self,\n        method,\n        url,\n        body=None,\n        headers=None,\n        retries=None,\n        redirect=True,\n        assert_same_host=True,\n        timeout=_Default,\n        pool_timeout=None,\n        release_conn=None,\n        chunked=False,\n        body_pos=None,\n        **response_kw\n    ):\n        \&#34;\&#34;\&#34;\n        Get a connection from the pool and perform an HTTP request. This is the\n        lowest level call for making a request, so you&#39;ll need to specify all\n        the raw details.\n    \n        .. note::\n    \n           More commonly, it&#39;s appropriate to use a convenience method provided\n           by :class:`.RequestMethods`, such as :meth:`request`.\n    \n        .. note::\n    \n           `release_conn` will only behave as expected if\n           `preload_content=False` because we want to make\n           `preload_content=False` the default behaviour someday soon without\n           breaking backwards compatibility.\n    \n        :param method:\n            HTTP request method (such as GET, POST, PUT, etc.)\n    \n        :param url:\n            The URL to perform the request on.\n    \n        :param body:\n            Data to send in the request body, either :class:`str`, :class:`bytes`,\n            an iterable of :class:`str`/:class:`bytes`, or a file-like object.\n    \n        :param headers:\n            Dictionary of custom headers to send, such as User-Agent,\n            If-None-Match, etc. If None, pool headers are used. If provided,\n            these headers completely replace any pool-specific headers.\n    \n        :param retries:\n            Configure the number of retries to allow before raising a\n            :class:`~urllib3.exceptions.MaxRetryError` exception.\n    \n            Pass ``None`` to retry until you receive a response. Pass a\n            :class:`~urllib3.util.retry.Retry` object for fine-grained control\n            over different types of retries.\n            Pass an integer number to retry connection errors that many times,\n            but no other types of errors. Pass zero to never retry.\n    \n            If ``False``, then retries are disabled and any exception is raised\n            immediately. Also, instead of raising a MaxRetryError on redirects,\n            the redirect response will be returned.\n    \n        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.\n    \n        :param redirect:\n            If True, automatically handle redirects (status codes 301, 302,\n            303, 307, 308). Each redirect counts as a retry. Disabling retries\n            will disable redirect, too.\n    \n        :param assert_same_host:\n            If ``True``, will make sure that the host of the pool requests is\n            consistent else will raise HostChangedError. When ``False``, you can\n            use the pool on an HTTP proxy and request foreign hosts.\n    \n        :param timeout:\n            If specified, overrides the default timeout for this one\n            request. It may be a float (in seconds) or an instance of\n            :class:`urllib3.util.Timeout`.\n    \n        :param pool_timeout:\n            If set and the pool is set to block=True, then this method will\n            block for ``pool_timeout`` seconds and raise EmptyPoolError if no\n            connection is available within the time period.\n    \n        :param release_conn:\n            If False, then the urlopen call will not release the connection\n            back into the pool once a response is received (but will release if\n            you read the entire contents of the response such as when\n            `preload_content=True`). This is useful if you&#39;re not preloading\n            the response&#39;s content immediately. You will need to call\n            ``r.release_conn()`` on the response ``r`` to return the connection\n            back into the pool. If None, it takes the value of\n            ``response_kw.get(&#39;preload_content&#39;, True)``.\n    \n        :param chunked:\n            If True, urllib3 will send the body using chunked transfer\n            encoding. Otherwise, urllib3 will send the body using the standard\n            content-length form. Defaults to False.\n    \n        :param int body_pos:\n            Position to seek to in file-like body in the event of a retry or\n            redirect. Typically this won&#39;t need to be set because urllib3 will\n            auto-populate the value when needed.\n    \n        :param \\\\**response_kw:\n            Additional parameters are passed to\n            :meth:`urllib3.response.HTTPResponse.from_httplib`\n        \&#34;\&#34;\&#34;\n    \n        parsed_url = parse_url(url)\n        destination_scheme = parsed_url.scheme\n    \n        if headers is None:\n            headers = self.headers\n    \n        if not isinstance(retries, Retry):\n            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)\n    \n        if release_conn is None:\n            release_conn = response_kw.get(\&#34;preload_content\&#34;, True)\n    \n        # Check host\n        if assert_same_host and not self.is_same_host(url):\n            raise HostChangedError(self, url, retries)\n    \n        # Ensure that the URL we&#39;re connecting to is properly encoded\n        if url.startswith(\&#34;/\&#34;):\n            url = six.ensure_str(_encode_target(url))\n        else:\n            url = six.ensure_str(parsed_url.url)\n    \n        conn = None\n    \n        # Track whether `conn` needs to be released before\n        # returning/raising/recursing. Update this variable if necessary, and\n        # leave `release_conn` constant throughout the function. That way, if\n        # the function recurses, the original value of `release_conn` will be\n        # passed down into the recursive call, and its value will be respected.\n        #\n        # See issue #651 [1] for details.\n        #\n        # [1] &amp;lt;https://github.com/urllib3/urllib3/issues/651&amp;gt;\n        release_this_conn = release_conn\n    \n        http_tunnel_required = connection_requires_http_tunnel(\n            self.proxy, self.proxy_config, destination_scheme\n        )\n    \n        # Merge the proxy headers. Only done when not using HTTP CONNECT. We\n        # have to copy the headers dict so we can safely change it without those\n        # changes being reflected in anyone else&#39;s copy.\n        if not http_tunnel_required:\n            headers = headers.copy()\n            headers.update(self.proxy_headers)\n    \n        # Must keep the exception bound to a separate variable or else Python 3\n        # complains about UnboundLocalError.\n        err = None\n    \n        # Keep track of whether we cleanly exited the except block. This\n        # ensures we do proper cleanup in finally.\n        clean_exit = False\n    \n        # Rewind body position, if needed. Record current position\n        # for future rewinds in the event of a redirect/retry.\n        body_pos = set_file_position(body, body_pos)\n    \n        try:\n            # Request a connection from the queue.\n            timeout_obj = self._get_timeout(timeout)\n            conn = self._get_conn(timeout=pool_timeout)\n    \n            conn.timeout = timeout_obj.connect_timeout\n    \n            is_new_proxy_conn = self.proxy is not None and not getattr(\n                conn, \&#34;sock\&#34;, None\n            )\n            if is_new_proxy_conn and http_tunnel_required:\n                self._prepare_proxy(conn)\n    \n            # Make the request on the httplib connection object.\n&amp;gt;           httplib_response = self._make_request(\n                conn,\n                method,\n                url,\n                timeout=timeout_obj,\n                body=body,\n                headers=headers,\n                chunked=chunked,\n            )\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:715: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:404: in _make_request\n    self._validate_conn(conn)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1058: in _validate_conn\n    conn.connect()\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connection.py:363: in connect\n    self.sock = conn = self._new_conn()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;\n\n    def _new_conn(self):\n        \&#34;\&#34;\&#34;Establish a socket connection and set nodelay settings on it.\n    \n        :return: New socket connection.\n        \&#34;\&#34;\&#34;\n        extra_kw = {}\n        if self.source_address:\n            extra_kw[\&#34;source_address\&#34;] = self.source_address\n    \n        if self.socket_options:\n            extra_kw[\&#34;socket_options\&#34;] = self.socket_options\n    \n        try:\n            conn = connection.create_connection(\n                (self._dns_host, self.port), self.timeout, **extra_kw\n            )\n    \n        except SocketTimeout:\n            raise ConnectTimeoutError(\n                self,\n                \&#34;Connection to %s timed out. (connect timeout=%s)\&#34;\n                % (self.host, self.timeout),\n            )\n    \n        except SocketError as e:\n&amp;gt;           raise NewConnectionError(\n                self, \&#34;Failed to establish a new connection: %s\&#34; % e\n            )\nE           urllib3.exceptions.NewConnectionError: &amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;: Failed to establish a new connection: [Errno 11001] getaddrinfo failed\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connection.py:186: NewConnectionError\n\nDuring handling of the above exception, another exception occurred:\n\nself = &amp;lt;requests.adapters.HTTPAdapter object at 0x000002487F34AA10&amp;gt;, request = &amp;lt;PreparedRequest [GET]&amp;gt;, stream = True, timeout = Timeout(connect=None, read=None, total=None)\nverify = True, cert = None, proxies = OrderedDict()\n\n    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):\n        \&#34;\&#34;\&#34;Sends PreparedRequest object. Returns Response object.\n    \n        :param request: The :class:`PreparedRequest &amp;lt;PreparedRequest&amp;gt;` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) &amp;lt;timeouts&amp;gt;` tuple.\n        :type timeout: float or tuple or urllib3 Timeout object\n        :param verify: (optional) Either a boolean, in which case it controls whether\n            we verify the server&#39;s TLS certificate, or a string, in which case it\n            must be a path to a CA bundle to use\n        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        :rtype: requests.Response\n        \&#34;\&#34;\&#34;\n    \n        try:\n            conn = self.get_connection(request.url, proxies)\n        except LocationValueError as e:\n            raise InvalidURL(e, request=request)\n    \n        self.cert_verify(conn, request.url, verify, cert)\n        url = self.request_url(request, proxies)\n        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)\n    \n        chunked = not (request.body is None or &#39;Content-Length&#39; in request.headers)\n    \n        if isinstance(timeout, tuple):\n            try:\n                connect, read = timeout\n                timeout = TimeoutSauce(connect=connect, read=read)\n            except ValueError as e:\n                # this may raise a string formatting error.\n                err = (\&#34;Invalid timeout {}. Pass a (connect, read) \&#34;\n                       \&#34;timeout tuple, or a single float to set \&#34;\n                       \&#34;both timeouts to the same value\&#34;.format(timeout))\n                raise ValueError(err)\n        elif isinstance(timeout, TimeoutSauce):\n            pass\n        else:\n            timeout = TimeoutSauce(connect=timeout, read=timeout)\n    \n        try:\n            if not chunked:\n&amp;gt;               resp = conn.urlopen(\n                    method=request.method,\n                    url=url,\n                    body=request.body,\n                    headers=request.headers,\n                    redirect=False,\n                    assert_same_host=False,\n                    preload_content=False,\n                    decode_content=False,\n                    retries=self.max_retries,\n                    timeout=timeout\n                )\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\adapters.py:440: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:799: in urlopen\n    retries = retries.increment(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = Retry(total=0, connect=None, read=False, redirect=None, status=None), method = &#39;GET&#39;, url = &#39;/chrome-for-testing/known-good-versions-with-downloads.json&#39;\nresponse = None\nerror = NewConnectionError(&#39;&amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;: Failed to establish a new connection: [Errno 11001] getaddrinfo failed&#39;)\n_pool = &amp;lt;urllib3.connectionpool.HTTPSConnectionPool object at 0x000002487F354910&amp;gt;, _stacktrace = &amp;lt;traceback object at 0x000002487F354FC0&amp;gt;\n\n    def increment(\n        self,\n        method=None,\n        url=None,\n        response=None,\n        error=None,\n        _pool=None,\n        _stacktrace=None,\n    ):\n        \&#34;\&#34;\&#34;Return a new Retry object with incremented retry counters.\n    \n        :param response: A response object, or None, if the server did not\n            return a response.\n        :type response: :class:`~urllib3.response.HTTPResponse`\n        :param Exception error: An error encountered during the request, or\n            None if the response was received successfully.\n    \n        :return: A new ``Retry`` object.\n        \&#34;\&#34;\&#34;\n        if self.total is False and error:\n            # Disabled, indicate to re-raise the error.\n            raise six.reraise(type(error), error, _stacktrace)\n    \n        total = self.total\n        if total is not None:\n            total -= 1\n    \n        connect = self.connect\n        read = self.read\n        redirect = self.redirect\n        status_count = self.status\n        other = self.other\n        cause = \&#34;unknown\&#34;\n        status = None\n        redirect_location = None\n    \n        if error and self._is_connection_error(error):\n            # Connect retry?\n            if connect is False:\n                raise six.reraise(type(error), error, _stacktrace)\n            elif connect is not None:\n                connect -= 1\n    \n        elif error and self._is_read_error(error):\n            # Read retry?\n            if read is False or not self._is_method_retryable(method):\n                raise six.reraise(type(error), error, _stacktrace)\n            elif read is not None:\n                read -= 1\n    \n        elif error:\n            # Other retry?\n            if other is not None:\n                other -= 1\n    \n        elif response and response.get_redirect_location():\n            # Redirect retry?\n            if redirect is not None:\n                redirect -= 1\n            cause = \&#34;too many redirects\&#34;\n            redirect_location = response.get_redirect_location()\n            status = response.status\n    \n        else:\n            # Incrementing because of a server error like a 500 in\n            # status_forcelist and the given method is in the allowed_methods\n            cause = ResponseError.GENERIC_ERROR\n            if response and response.status:\n                if status_count is not None:\n                    status_count -= 1\n                cause = ResponseError.SPECIFIC_ERROR.format(status_code=response.status)\n                status = response.status\n    \n        history = self.history + (\n            RequestHistory(method, url, error, status, redirect_location),\n        )\n    \n        new_retry = self.new(\n            total=total,\n            connect=connect,\n            read=read,\n            redirect=redirect,\n            status=status_count,\n            other=other,\n            history=history,\n        )\n    \n        if new_retry.is_exhausted():\n&amp;gt;           raise MaxRetryError(_pool, url, error or ResponseError(cause))\nE           urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host=&#39;googlechromelabs.github.io&#39;, port=443): Max retries exceeded with url: /chrome-for-testing/known-good-versions-with-downloads.json (Caused by NewConnectionError(&#39;&amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;: Failed to establish a new connection: [Errno 11001] getaddrinfo failed&#39;))\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\util\\retry.py:592: MaxRetryError\n\nDuring handling of the above exception, another exception occurred:\n\nself = &amp;lt;webdriver_manager.core.http.WDMHttpClient object at 0x000002487F2E6990&amp;gt;\nurl = &#39;https://googlechromelabs.github.io/chrome-for-testing/known-good-versions-with-downloads.json&#39;, kwargs = {}\n\n    def get(self, url, **kwargs) -&amp;gt; Response:\n        try:\n&amp;gt;           resp = requests.get(\n                url=url, verify=self._ssl_verify, stream=True, **kwargs)\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\core\\http.py:32: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\api.py:75: in get\n    return request(&#39;get&#39;, url, params=params, **kwargs)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\api.py:61: in request\n    return session.request(method=method, url=url, **kwargs)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\sessions.py:529: in request\n    resp = self.send(prep, **send_kwargs)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\sessions.py:645: in send\n    r = adapter.send(request, **kwargs)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;requests.adapters.HTTPAdapter object at 0x000002487F34AA10&amp;gt;, request = &amp;lt;PreparedRequest [GET]&amp;gt;, stream = True, timeout = Timeout(connect=None, read=None, total=None)\nverify = True, cert = None, proxies = OrderedDict()\n\n    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):\n        \&#34;\&#34;\&#34;Sends PreparedRequest object. Returns Response object.\n    \n        :param request: The :class:`PreparedRequest &amp;lt;PreparedRequest&amp;gt;` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) &amp;lt;timeouts&amp;gt;` tuple.\n        :type timeout: float or tuple or urllib3 Timeout object\n        :param verify: (optional) Either a boolean, in which case it controls whether\n            we verify the server&#39;s TLS certificate, or a string, in which case it\n            must be a path to a CA bundle to use\n        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        :rtype: requests.Response\n        \&#34;\&#34;\&#34;\n    \n        try:\n            conn = self.get_connection(request.url, proxies)\n        except LocationValueError as e:\n            raise InvalidURL(e, request=request)\n    \n        self.cert_verify(conn, request.url, verify, cert)\n        url = self.request_url(request, proxies)\n        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)\n    \n        chunked = not (request.body is None or &#39;Content-Length&#39; in request.headers)\n    \n        if isinstance(timeout, tuple):\n            try:\n                connect, read = timeout\n                timeout = TimeoutSauce(connect=connect, read=read)\n            except ValueError as e:\n                # this may raise a string formatting error.\n                err = (\&#34;Invalid timeout {}. Pass a (connect, read) \&#34;\n                       \&#34;timeout tuple, or a single float to set \&#34;\n                       \&#34;both timeouts to the same value\&#34;.format(timeout))\n                raise ValueError(err)\n        elif isinstance(timeout, TimeoutSauce):\n            pass\n        else:\n            timeout = TimeoutSauce(connect=timeout, read=timeout)\n    \n        try:\n            if not chunked:\n                resp = conn.urlopen(\n                    method=request.method,\n                    url=url,\n                    body=request.body,\n                    headers=request.headers,\n                    redirect=False,\n                    assert_same_host=False,\n                    preload_content=False,\n                    decode_content=False,\n                    retries=self.max_retries,\n                    timeout=timeout\n                )\n    \n            # Send the request.\n            else:\n                if hasattr(conn, &#39;proxy_pool&#39;):\n                    conn = conn.proxy_pool\n    \n                low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)\n    \n                try:\n                    skip_host = &#39;Host&#39; in request.headers\n                    low_conn.putrequest(request.method,\n                                        url,\n                                        skip_accept_encoding=True,\n                                        skip_host=skip_host)\n    \n                    for header, value in request.headers.items():\n                        low_conn.putheader(header, value)\n    \n                    low_conn.endheaders()\n    \n                    for i in request.body:\n                        low_conn.send(hex(len(i))[2:].encode(&#39;utf-8&#39;))\n                        low_conn.send(b&#39;\\r\\n&#39;)\n                        low_conn.send(i)\n                        low_conn.send(b&#39;\\r\\n&#39;)\n                    low_conn.send(b&#39;0\\r\\n\\r\\n&#39;)\n    \n                    # Receive the response from the server\n                    try:\n                        # For Python 2.7, use buffering of HTTP responses\n                        r = low_conn.getresponse(buffering=True)\n                    except TypeError:\n                        # For compatibility with Python 3.3+\n                        r = low_conn.getresponse()\n    \n                    resp = HTTPResponse.from_httplib(\n                        r,\n                        pool=conn,\n                        connection=low_conn,\n                        preload_content=False,\n                        decode_content=False\n                    )\n                except:\n                    # If we hit any problems here, clean up the connection.\n                    # Then, reraise so that we can handle the actual exception.\n                    low_conn.close()\n                    raise\n    \n        except (ProtocolError, socket.error) as err:\n            raise ConnectionError(err, request=request)\n    \n        except MaxRetryError as e:\n            if isinstance(e.reason, ConnectTimeoutError):\n                # TODO: Remove this in 3.0.0: see #2811\n                if not isinstance(e.reason, NewConnectionError):\n                    raise ConnectTimeout(e, request=request)\n    \n            if isinstance(e.reason, ResponseError):\n                raise RetryError(e, request=request)\n    \n            if isinstance(e.reason, _ProxyError):\n                raise ProxyError(e, request=request)\n    \n            if isinstance(e.reason, _SSLError):\n                # This branch is for urllib3 v1.22 and later.\n                raise SSLError(e, request=request)\n    \n&amp;gt;           raise ConnectionError(e, request=request)\nE           requests.exceptions.ConnectionError: HTTPSConnectionPool(host=&#39;googlechromelabs.github.io&#39;, port=443): Max retries exceeded with url: /chrome-for-testing/known-good-versions-with-downloads.json (Caused by NewConnectionError(&#39;&amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;: Failed to establish a new connection: [Errno 11001] getaddrinfo failed&#39;))\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\adapters.py:519: ConnectionError\n\nDuring handling of the above exception, another exception occurred:\n\n    @pytest.fixture(scope=\&#34;module\&#34;)\n    def driver():\n        options = Options()\n        options.add_experimental_option(\&#34;detach\&#34;, True)\n        #driver = webdriver.Chrome(options=options)\n&amp;gt;       driver = webdriver.Chrome(options=options, service=Service(ChromeDriverManager().install()))\n\nSingle_bucket_sim.py:27: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\chrome.py:40: in install\n    driver_path = self._get_driver_binary_path(self.driver)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\core\\manager.py:40: in _get_driver_binary_path\n    file = self._download_manager.download_file(driver.get_driver_download_url(os_type))\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\drivers\\chrome.py:44: in get_driver_download_url\n    modern_version_url = self.get_url_for_version_and_platform(driver_version_to_download, os_type)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\drivers\\chrome.py:69: in get_url_for_version_and_platform\n    response = self._http_client.get(url)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;webdriver_manager.core.http.WDMHttpClient object at 0x000002487F2E6990&amp;gt;\nurl = &#39;https://googlechromelabs.github.io/chrome-for-testing/known-good-versions-with-downloads.json&#39;, kwargs = {}\n\n    def get(self, url, **kwargs) -&amp;gt; Response:\n        try:\n            resp = requests.get(\n                url=url, verify=self._ssl_verify, stream=True, **kwargs)\n        except exceptions.ConnectionError:\n&amp;gt;           raise exceptions.ConnectionError(f\&#34;Could not reach host. Are you offline?\&#34;)\nE           requests.exceptions.ConnectionError: Could not reach host. Are you offline?\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\core\\http.py:35: ConnectionError\n&#34;}], &#34;Single_bucket_sim.py::test_table1_in_case_summary&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Error&#34;, &#34;testId&#34;: &#34;Single_bucket_sim.py::test_table1_in_case_summary::setup&#34;, &#34;duration&#34;: &#34;0 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Error&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;Single_bucket_sim.py::test_table1_in_case_summary::setup&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;0 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;\n\n    def _new_conn(self):\n        \&#34;\&#34;\&#34;Establish a socket connection and set nodelay settings on it.\n    \n        :return: New socket connection.\n        \&#34;\&#34;\&#34;\n        extra_kw = {}\n        if self.source_address:\n            extra_kw[\&#34;source_address\&#34;] = self.source_address\n    \n        if self.socket_options:\n            extra_kw[\&#34;socket_options\&#34;] = self.socket_options\n    \n        try:\n&amp;gt;           conn = connection.create_connection(\n                (self._dns_host, self.port), self.timeout, **extra_kw\n            )\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connection.py:174: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\util\\connection.py:72: in create_connection\n    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nhost = &#39;googlechromelabs.github.io&#39;, port = 443, family = &amp;lt;AddressFamily.AF_UNSPEC: 0&amp;gt;, type = &amp;lt;SocketKind.SOCK_STREAM: 1&amp;gt;, proto = 0, flags = 0\n\n    def getaddrinfo(host, port, family=0, type=0, proto=0, flags=0):\n        \&#34;\&#34;\&#34;Resolve host and port into list of address info entries.\n    \n        Translate the host/port argument into a sequence of 5-tuples that contain\n        all the necessary arguments for creating a socket connected to that service.\n        host is a domain name, a string representation of an IPv4/v6 address or\n        None. port is a string service name such as &#39;http&#39;, a numeric port number or\n        None. By passing None as the value of host and port, you can pass NULL to\n        the underlying C API.\n    \n        The family, type and proto arguments can be optionally specified in order to\n        narrow the list of addresses returned. Passing zero as a value for each of\n        these arguments selects the full range of results.\n        \&#34;\&#34;\&#34;\n        # We override this function since we want to translate the numeric family\n        # and socket type values to enum constants.\n        addrlist = []\n&amp;gt;       for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\nE       socket.gaierror: [Errno 11001] getaddrinfo failed\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\socket.py:962: gaierror\n\nDuring handling of the above exception, another exception occurred:\n\nself = &amp;lt;urllib3.connectionpool.HTTPSConnectionPool object at 0x000002487F354910&amp;gt;, method = &#39;GET&#39;, url = &#39;/chrome-for-testing/known-good-versions-with-downloads.json&#39;\nbody = None, headers = {&#39;User-Agent&#39;: &#39;python-requests/2.27.1&#39;, &#39;Accept-Encoding&#39;: &#39;gzip, deflate&#39;, &#39;Accept&#39;: &#39;*/*&#39;, &#39;Connection&#39;: &#39;keep-alive&#39;}\nretries = Retry(total=0, connect=None, read=False, redirect=None, status=None), redirect = False, assert_same_host = False\ntimeout = Timeout(connect=None, read=None, total=None), pool_timeout = None, release_conn = False, chunked = False, body_pos = None\nresponse_kw = {&#39;decode_content&#39;: False, &#39;preload_content&#39;: False}\nparsed_url = Url(scheme=None, auth=None, host=None, port=None, path=&#39;/chrome-for-testing/known-good-versions-with-downloads.json&#39;, query=None, fragment=None)\ndestination_scheme = None, conn = None, release_this_conn = True, http_tunnel_required = False, err = None, clean_exit = False\n\n    def urlopen(\n        self,\n        method,\n        url,\n        body=None,\n        headers=None,\n        retries=None,\n        redirect=True,\n        assert_same_host=True,\n        timeout=_Default,\n        pool_timeout=None,\n        release_conn=None,\n        chunked=False,\n        body_pos=None,\n        **response_kw\n    ):\n        \&#34;\&#34;\&#34;\n        Get a connection from the pool and perform an HTTP request. This is the\n        lowest level call for making a request, so you&#39;ll need to specify all\n        the raw details.\n    \n        .. note::\n    \n           More commonly, it&#39;s appropriate to use a convenience method provided\n           by :class:`.RequestMethods`, such as :meth:`request`.\n    \n        .. note::\n    \n           `release_conn` will only behave as expected if\n           `preload_content=False` because we want to make\n           `preload_content=False` the default behaviour someday soon without\n           breaking backwards compatibility.\n    \n        :param method:\n            HTTP request method (such as GET, POST, PUT, etc.)\n    \n        :param url:\n            The URL to perform the request on.\n    \n        :param body:\n            Data to send in the request body, either :class:`str`, :class:`bytes`,\n            an iterable of :class:`str`/:class:`bytes`, or a file-like object.\n    \n        :param headers:\n            Dictionary of custom headers to send, such as User-Agent,\n            If-None-Match, etc. If None, pool headers are used. If provided,\n            these headers completely replace any pool-specific headers.\n    \n        :param retries:\n            Configure the number of retries to allow before raising a\n            :class:`~urllib3.exceptions.MaxRetryError` exception.\n    \n            Pass ``None`` to retry until you receive a response. Pass a\n            :class:`~urllib3.util.retry.Retry` object for fine-grained control\n            over different types of retries.\n            Pass an integer number to retry connection errors that many times,\n            but no other types of errors. Pass zero to never retry.\n    \n            If ``False``, then retries are disabled and any exception is raised\n            immediately. Also, instead of raising a MaxRetryError on redirects,\n            the redirect response will be returned.\n    \n        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.\n    \n        :param redirect:\n            If True, automatically handle redirects (status codes 301, 302,\n            303, 307, 308). Each redirect counts as a retry. Disabling retries\n            will disable redirect, too.\n    \n        :param assert_same_host:\n            If ``True``, will make sure that the host of the pool requests is\n            consistent else will raise HostChangedError. When ``False``, you can\n            use the pool on an HTTP proxy and request foreign hosts.\n    \n        :param timeout:\n            If specified, overrides the default timeout for this one\n            request. It may be a float (in seconds) or an instance of\n            :class:`urllib3.util.Timeout`.\n    \n        :param pool_timeout:\n            If set and the pool is set to block=True, then this method will\n            block for ``pool_timeout`` seconds and raise EmptyPoolError if no\n            connection is available within the time period.\n    \n        :param release_conn:\n            If False, then the urlopen call will not release the connection\n            back into the pool once a response is received (but will release if\n            you read the entire contents of the response such as when\n            `preload_content=True`). This is useful if you&#39;re not preloading\n            the response&#39;s content immediately. You will need to call\n            ``r.release_conn()`` on the response ``r`` to return the connection\n            back into the pool. If None, it takes the value of\n            ``response_kw.get(&#39;preload_content&#39;, True)``.\n    \n        :param chunked:\n            If True, urllib3 will send the body using chunked transfer\n            encoding. Otherwise, urllib3 will send the body using the standard\n            content-length form. Defaults to False.\n    \n        :param int body_pos:\n            Position to seek to in file-like body in the event of a retry or\n            redirect. Typically this won&#39;t need to be set because urllib3 will\n            auto-populate the value when needed.\n    \n        :param \\\\**response_kw:\n            Additional parameters are passed to\n            :meth:`urllib3.response.HTTPResponse.from_httplib`\n        \&#34;\&#34;\&#34;\n    \n        parsed_url = parse_url(url)\n        destination_scheme = parsed_url.scheme\n    \n        if headers is None:\n            headers = self.headers\n    \n        if not isinstance(retries, Retry):\n            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)\n    \n        if release_conn is None:\n            release_conn = response_kw.get(\&#34;preload_content\&#34;, True)\n    \n        # Check host\n        if assert_same_host and not self.is_same_host(url):\n            raise HostChangedError(self, url, retries)\n    \n        # Ensure that the URL we&#39;re connecting to is properly encoded\n        if url.startswith(\&#34;/\&#34;):\n            url = six.ensure_str(_encode_target(url))\n        else:\n            url = six.ensure_str(parsed_url.url)\n    \n        conn = None\n    \n        # Track whether `conn` needs to be released before\n        # returning/raising/recursing. Update this variable if necessary, and\n        # leave `release_conn` constant throughout the function. That way, if\n        # the function recurses, the original value of `release_conn` will be\n        # passed down into the recursive call, and its value will be respected.\n        #\n        # See issue #651 [1] for details.\n        #\n        # [1] &amp;lt;https://github.com/urllib3/urllib3/issues/651&amp;gt;\n        release_this_conn = release_conn\n    \n        http_tunnel_required = connection_requires_http_tunnel(\n            self.proxy, self.proxy_config, destination_scheme\n        )\n    \n        # Merge the proxy headers. Only done when not using HTTP CONNECT. We\n        # have to copy the headers dict so we can safely change it without those\n        # changes being reflected in anyone else&#39;s copy.\n        if not http_tunnel_required:\n            headers = headers.copy()\n            headers.update(self.proxy_headers)\n    \n        # Must keep the exception bound to a separate variable or else Python 3\n        # complains about UnboundLocalError.\n        err = None\n    \n        # Keep track of whether we cleanly exited the except block. This\n        # ensures we do proper cleanup in finally.\n        clean_exit = False\n    \n        # Rewind body position, if needed. Record current position\n        # for future rewinds in the event of a redirect/retry.\n        body_pos = set_file_position(body, body_pos)\n    \n        try:\n            # Request a connection from the queue.\n            timeout_obj = self._get_timeout(timeout)\n            conn = self._get_conn(timeout=pool_timeout)\n    \n            conn.timeout = timeout_obj.connect_timeout\n    \n            is_new_proxy_conn = self.proxy is not None and not getattr(\n                conn, \&#34;sock\&#34;, None\n            )\n            if is_new_proxy_conn and http_tunnel_required:\n                self._prepare_proxy(conn)\n    \n            # Make the request on the httplib connection object.\n&amp;gt;           httplib_response = self._make_request(\n                conn,\n                method,\n                url,\n                timeout=timeout_obj,\n                body=body,\n                headers=headers,\n                chunked=chunked,\n            )\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:715: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:404: in _make_request\n    self._validate_conn(conn)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1058: in _validate_conn\n    conn.connect()\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connection.py:363: in connect\n    self.sock = conn = self._new_conn()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;\n\n    def _new_conn(self):\n        \&#34;\&#34;\&#34;Establish a socket connection and set nodelay settings on it.\n    \n        :return: New socket connection.\n        \&#34;\&#34;\&#34;\n        extra_kw = {}\n        if self.source_address:\n            extra_kw[\&#34;source_address\&#34;] = self.source_address\n    \n        if self.socket_options:\n            extra_kw[\&#34;socket_options\&#34;] = self.socket_options\n    \n        try:\n            conn = connection.create_connection(\n                (self._dns_host, self.port), self.timeout, **extra_kw\n            )\n    \n        except SocketTimeout:\n            raise ConnectTimeoutError(\n                self,\n                \&#34;Connection to %s timed out. (connect timeout=%s)\&#34;\n                % (self.host, self.timeout),\n            )\n    \n        except SocketError as e:\n&amp;gt;           raise NewConnectionError(\n                self, \&#34;Failed to establish a new connection: %s\&#34; % e\n            )\nE           urllib3.exceptions.NewConnectionError: &amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;: Failed to establish a new connection: [Errno 11001] getaddrinfo failed\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connection.py:186: NewConnectionError\n\nDuring handling of the above exception, another exception occurred:\n\nself = &amp;lt;requests.adapters.HTTPAdapter object at 0x000002487F34AA10&amp;gt;, request = &amp;lt;PreparedRequest [GET]&amp;gt;, stream = True, timeout = Timeout(connect=None, read=None, total=None)\nverify = True, cert = None, proxies = OrderedDict()\n\n    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):\n        \&#34;\&#34;\&#34;Sends PreparedRequest object. Returns Response object.\n    \n        :param request: The :class:`PreparedRequest &amp;lt;PreparedRequest&amp;gt;` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) &amp;lt;timeouts&amp;gt;` tuple.\n        :type timeout: float or tuple or urllib3 Timeout object\n        :param verify: (optional) Either a boolean, in which case it controls whether\n            we verify the server&#39;s TLS certificate, or a string, in which case it\n            must be a path to a CA bundle to use\n        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        :rtype: requests.Response\n        \&#34;\&#34;\&#34;\n    \n        try:\n            conn = self.get_connection(request.url, proxies)\n        except LocationValueError as e:\n            raise InvalidURL(e, request=request)\n    \n        self.cert_verify(conn, request.url, verify, cert)\n        url = self.request_url(request, proxies)\n        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)\n    \n        chunked = not (request.body is None or &#39;Content-Length&#39; in request.headers)\n    \n        if isinstance(timeout, tuple):\n            try:\n                connect, read = timeout\n                timeout = TimeoutSauce(connect=connect, read=read)\n            except ValueError as e:\n                # this may raise a string formatting error.\n                err = (\&#34;Invalid timeout {}. Pass a (connect, read) \&#34;\n                       \&#34;timeout tuple, or a single float to set \&#34;\n                       \&#34;both timeouts to the same value\&#34;.format(timeout))\n                raise ValueError(err)\n        elif isinstance(timeout, TimeoutSauce):\n            pass\n        else:\n            timeout = TimeoutSauce(connect=timeout, read=timeout)\n    \n        try:\n            if not chunked:\n&amp;gt;               resp = conn.urlopen(\n                    method=request.method,\n                    url=url,\n                    body=request.body,\n                    headers=request.headers,\n                    redirect=False,\n                    assert_same_host=False,\n                    preload_content=False,\n                    decode_content=False,\n                    retries=self.max_retries,\n                    timeout=timeout\n                )\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\adapters.py:440: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:799: in urlopen\n    retries = retries.increment(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = Retry(total=0, connect=None, read=False, redirect=None, status=None), method = &#39;GET&#39;, url = &#39;/chrome-for-testing/known-good-versions-with-downloads.json&#39;\nresponse = None\nerror = NewConnectionError(&#39;&amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;: Failed to establish a new connection: [Errno 11001] getaddrinfo failed&#39;)\n_pool = &amp;lt;urllib3.connectionpool.HTTPSConnectionPool object at 0x000002487F354910&amp;gt;, _stacktrace = &amp;lt;traceback object at 0x000002487F354FC0&amp;gt;\n\n    def increment(\n        self,\n        method=None,\n        url=None,\n        response=None,\n        error=None,\n        _pool=None,\n        _stacktrace=None,\n    ):\n        \&#34;\&#34;\&#34;Return a new Retry object with incremented retry counters.\n    \n        :param response: A response object, or None, if the server did not\n            return a response.\n        :type response: :class:`~urllib3.response.HTTPResponse`\n        :param Exception error: An error encountered during the request, or\n            None if the response was received successfully.\n    \n        :return: A new ``Retry`` object.\n        \&#34;\&#34;\&#34;\n        if self.total is False and error:\n            # Disabled, indicate to re-raise the error.\n            raise six.reraise(type(error), error, _stacktrace)\n    \n        total = self.total\n        if total is not None:\n            total -= 1\n    \n        connect = self.connect\n        read = self.read\n        redirect = self.redirect\n        status_count = self.status\n        other = self.other\n        cause = \&#34;unknown\&#34;\n        status = None\n        redirect_location = None\n    \n        if error and self._is_connection_error(error):\n            # Connect retry?\n            if connect is False:\n                raise six.reraise(type(error), error, _stacktrace)\n            elif connect is not None:\n                connect -= 1\n    \n        elif error and self._is_read_error(error):\n            # Read retry?\n            if read is False or not self._is_method_retryable(method):\n                raise six.reraise(type(error), error, _stacktrace)\n            elif read is not None:\n                read -= 1\n    \n        elif error:\n            # Other retry?\n            if other is not None:\n                other -= 1\n    \n        elif response and response.get_redirect_location():\n            # Redirect retry?\n            if redirect is not None:\n                redirect -= 1\n            cause = \&#34;too many redirects\&#34;\n            redirect_location = response.get_redirect_location()\n            status = response.status\n    \n        else:\n            # Incrementing because of a server error like a 500 in\n            # status_forcelist and the given method is in the allowed_methods\n            cause = ResponseError.GENERIC_ERROR\n            if response and response.status:\n                if status_count is not None:\n                    status_count -= 1\n                cause = ResponseError.SPECIFIC_ERROR.format(status_code=response.status)\n                status = response.status\n    \n        history = self.history + (\n            RequestHistory(method, url, error, status, redirect_location),\n        )\n    \n        new_retry = self.new(\n            total=total,\n            connect=connect,\n            read=read,\n            redirect=redirect,\n            status=status_count,\n            other=other,\n            history=history,\n        )\n    \n        if new_retry.is_exhausted():\n&amp;gt;           raise MaxRetryError(_pool, url, error or ResponseError(cause))\nE           urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host=&#39;googlechromelabs.github.io&#39;, port=443): Max retries exceeded with url: /chrome-for-testing/known-good-versions-with-downloads.json (Caused by NewConnectionError(&#39;&amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;: Failed to establish a new connection: [Errno 11001] getaddrinfo failed&#39;))\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\util\\retry.py:592: MaxRetryError\n\nDuring handling of the above exception, another exception occurred:\n\nself = &amp;lt;webdriver_manager.core.http.WDMHttpClient object at 0x000002487F2E6990&amp;gt;\nurl = &#39;https://googlechromelabs.github.io/chrome-for-testing/known-good-versions-with-downloads.json&#39;, kwargs = {}\n\n    def get(self, url, **kwargs) -&amp;gt; Response:\n        try:\n&amp;gt;           resp = requests.get(\n                url=url, verify=self._ssl_verify, stream=True, **kwargs)\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\core\\http.py:32: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\api.py:75: in get\n    return request(&#39;get&#39;, url, params=params, **kwargs)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\api.py:61: in request\n    return session.request(method=method, url=url, **kwargs)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\sessions.py:529: in request\n    resp = self.send(prep, **send_kwargs)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\sessions.py:645: in send\n    r = adapter.send(request, **kwargs)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;requests.adapters.HTTPAdapter object at 0x000002487F34AA10&amp;gt;, request = &amp;lt;PreparedRequest [GET]&amp;gt;, stream = True, timeout = Timeout(connect=None, read=None, total=None)\nverify = True, cert = None, proxies = OrderedDict()\n\n    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):\n        \&#34;\&#34;\&#34;Sends PreparedRequest object. Returns Response object.\n    \n        :param request: The :class:`PreparedRequest &amp;lt;PreparedRequest&amp;gt;` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) &amp;lt;timeouts&amp;gt;` tuple.\n        :type timeout: float or tuple or urllib3 Timeout object\n        :param verify: (optional) Either a boolean, in which case it controls whether\n            we verify the server&#39;s TLS certificate, or a string, in which case it\n            must be a path to a CA bundle to use\n        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        :rtype: requests.Response\n        \&#34;\&#34;\&#34;\n    \n        try:\n            conn = self.get_connection(request.url, proxies)\n        except LocationValueError as e:\n            raise InvalidURL(e, request=request)\n    \n        self.cert_verify(conn, request.url, verify, cert)\n        url = self.request_url(request, proxies)\n        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)\n    \n        chunked = not (request.body is None or &#39;Content-Length&#39; in request.headers)\n    \n        if isinstance(timeout, tuple):\n            try:\n                connect, read = timeout\n                timeout = TimeoutSauce(connect=connect, read=read)\n            except ValueError as e:\n                # this may raise a string formatting error.\n                err = (\&#34;Invalid timeout {}. Pass a (connect, read) \&#34;\n                       \&#34;timeout tuple, or a single float to set \&#34;\n                       \&#34;both timeouts to the same value\&#34;.format(timeout))\n                raise ValueError(err)\n        elif isinstance(timeout, TimeoutSauce):\n            pass\n        else:\n            timeout = TimeoutSauce(connect=timeout, read=timeout)\n    \n        try:\n            if not chunked:\n                resp = conn.urlopen(\n                    method=request.method,\n                    url=url,\n                    body=request.body,\n                    headers=request.headers,\n                    redirect=False,\n                    assert_same_host=False,\n                    preload_content=False,\n                    decode_content=False,\n                    retries=self.max_retries,\n                    timeout=timeout\n                )\n    \n            # Send the request.\n            else:\n                if hasattr(conn, &#39;proxy_pool&#39;):\n                    conn = conn.proxy_pool\n    \n                low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)\n    \n                try:\n                    skip_host = &#39;Host&#39; in request.headers\n                    low_conn.putrequest(request.method,\n                                        url,\n                                        skip_accept_encoding=True,\n                                        skip_host=skip_host)\n    \n                    for header, value in request.headers.items():\n                        low_conn.putheader(header, value)\n    \n                    low_conn.endheaders()\n    \n                    for i in request.body:\n                        low_conn.send(hex(len(i))[2:].encode(&#39;utf-8&#39;))\n                        low_conn.send(b&#39;\\r\\n&#39;)\n                        low_conn.send(i)\n                        low_conn.send(b&#39;\\r\\n&#39;)\n                    low_conn.send(b&#39;0\\r\\n\\r\\n&#39;)\n    \n                    # Receive the response from the server\n                    try:\n                        # For Python 2.7, use buffering of HTTP responses\n                        r = low_conn.getresponse(buffering=True)\n                    except TypeError:\n                        # For compatibility with Python 3.3+\n                        r = low_conn.getresponse()\n    \n                    resp = HTTPResponse.from_httplib(\n                        r,\n                        pool=conn,\n                        connection=low_conn,\n                        preload_content=False,\n                        decode_content=False\n                    )\n                except:\n                    # If we hit any problems here, clean up the connection.\n                    # Then, reraise so that we can handle the actual exception.\n                    low_conn.close()\n                    raise\n    \n        except (ProtocolError, socket.error) as err:\n            raise ConnectionError(err, request=request)\n    \n        except MaxRetryError as e:\n            if isinstance(e.reason, ConnectTimeoutError):\n                # TODO: Remove this in 3.0.0: see #2811\n                if not isinstance(e.reason, NewConnectionError):\n                    raise ConnectTimeout(e, request=request)\n    \n            if isinstance(e.reason, ResponseError):\n                raise RetryError(e, request=request)\n    \n            if isinstance(e.reason, _ProxyError):\n                raise ProxyError(e, request=request)\n    \n            if isinstance(e.reason, _SSLError):\n                # This branch is for urllib3 v1.22 and later.\n                raise SSLError(e, request=request)\n    \n&amp;gt;           raise ConnectionError(e, request=request)\nE           requests.exceptions.ConnectionError: HTTPSConnectionPool(host=&#39;googlechromelabs.github.io&#39;, port=443): Max retries exceeded with url: /chrome-for-testing/known-good-versions-with-downloads.json (Caused by NewConnectionError(&#39;&amp;lt;urllib3.connection.HTTPSConnection object at 0x000002487F354E50&amp;gt;: Failed to establish a new connection: [Errno 11001] getaddrinfo failed&#39;))\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\adapters.py:519: ConnectionError\n\nDuring handling of the above exception, another exception occurred:\n\n    @pytest.fixture(scope=\&#34;module\&#34;)\n    def driver():\n        options = Options()\n        options.add_experimental_option(\&#34;detach\&#34;, True)\n        #driver = webdriver.Chrome(options=options)\n&amp;gt;       driver = webdriver.Chrome(options=options, service=Service(ChromeDriverManager().install()))\n\nSingle_bucket_sim.py:27: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\chrome.py:40: in install\n    driver_path = self._get_driver_binary_path(self.driver)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\core\\manager.py:40: in _get_driver_binary_path\n    file = self._download_manager.download_file(driver.get_driver_download_url(os_type))\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\drivers\\chrome.py:44: in get_driver_download_url\n    modern_version_url = self.get_url_for_version_and_platform(driver_version_to_download, os_type)\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\drivers\\chrome.py:69: in get_url_for_version_and_platform\n    response = self._http_client.get(url)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;webdriver_manager.core.http.WDMHttpClient object at 0x000002487F2E6990&amp;gt;\nurl = &#39;https://googlechromelabs.github.io/chrome-for-testing/known-good-versions-with-downloads.json&#39;, kwargs = {}\n\n    def get(self, url, **kwargs) -&amp;gt; Response:\n        try:\n            resp = requests.get(\n                url=url, verify=self._ssl_verify, stream=True, **kwargs)\n        except exceptions.ConnectionError:\n&amp;gt;           raise exceptions.ConnectionError(f\&#34;Could not reach host. Are you offline?\&#34;)\nE           requests.exceptions.ConnectionError: Could not reach host. Are you offline?\n\nC:\\Users\\Kottaisamy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\webdriver_manager\\core\\http.py:35: ConnectionError\n&#34;}]}, &#34;renderCollapsed&#34;: [&#34;passed&#34;], &#34;initialSort&#34;: &#34;result&#34;, &#34;title&#34;: &#34;report.html&#34;}"></div>
    <script>
      (function(){function r(e,n,t){function o(i,f){if(!n[i]){if(!e[i]){var c="function"==typeof require&&require;if(!f&&c)return c(i,!0);if(u)return u(i,!0);var a=new Error("Cannot find module '"+i+"'");throw a.code="MODULE_NOT_FOUND",a}var p=n[i]={exports:{}};e[i][0].call(p.exports,function(r){var n=e[i][1][r];return o(n||r)},p,p.exports,r,e,n,t)}return n[i].exports}for(var u="function"==typeof require&&require,i=0;i<t.length;i++)o(t[i]);return o}return r})()({1:[function(require,module,exports){
const { getCollapsedCategory, setCollapsedIds } = require('./storage.js')

class DataManager {
    setManager(data) {
        const collapsedCategories = [...getCollapsedCategory(data.renderCollapsed)]
        const collapsedIds = []
        const tests = Object.values(data.tests).flat().map((test, index) => {
            const collapsed = collapsedCategories.includes(test.result.toLowerCase())
            const id = `test_${index}`
            if (collapsed) {
                collapsedIds.push(id)
            }
            return {
                ...test,
                id,
                collapsed,
            }
        })
        const dataBlob = { ...data, tests }
        this.data = { ...dataBlob }
        this.renderData = { ...dataBlob }
        setCollapsedIds(collapsedIds)
    }

    get allData() {
        return { ...this.data }
    }

    resetRender() {
        this.renderData = { ...this.data }
    }

    setRender(data) {
        this.renderData.tests = [...data]
    }

    toggleCollapsedItem(id) {
        this.renderData.tests = this.renderData.tests.map((test) =>
            test.id === id ? { ...test, collapsed: !test.collapsed } : test,
        )
    }

    set allCollapsed(collapsed) {
        this.renderData = { ...this.renderData, tests: [...this.renderData.tests.map((test) => (
            { ...test, collapsed }
        ))] }
    }

    get testSubset() {
        return [...this.renderData.tests]
    }

    get environment() {
        return this.renderData.environment
    }

    get initialSort() {
        return this.data.initialSort
    }
}

module.exports = {
    manager: new DataManager(),
}

},{"./storage.js":8}],2:[function(require,module,exports){
const mediaViewer = require('./mediaviewer.js')
const templateEnvRow = document.getElementById('template_environment_row')
const templateResult = document.getElementById('template_results-table__tbody')

function htmlToElements(html) {
    const temp = document.createElement('template')
    temp.innerHTML = html
    return temp.content.childNodes
}

const find = (selector, elem) => {
    if (!elem) {
        elem = document
    }
    return elem.querySelector(selector)
}

const findAll = (selector, elem) => {
    if (!elem) {
        elem = document
    }
    return [...elem.querySelectorAll(selector)]
}

const dom = {
    getStaticRow: (key, value) => {
        const envRow = templateEnvRow.content.cloneNode(true)
        const isObj = typeof value === 'object' && value !== null
        const values = isObj ? Object.keys(value).map((k) => `${k}: ${value[k]}`) : null

        const valuesElement = htmlToElements(
            values ? `<ul>${values.map((val) => `<li>${val}</li>`).join('')}<ul>` : `<div>${value}</div>`)[0]
        const td = findAll('td', envRow)
        td[0].textContent = key
        td[1].appendChild(valuesElement)

        return envRow
    },
    getResultTBody: ({ testId, id, log, extras, resultsTableRow, tableHtml, result, collapsed }) => {
        const resultBody = templateResult.content.cloneNode(true)
        resultBody.querySelector('tbody').classList.add(result.toLowerCase())
        resultBody.querySelector('tbody').id = testId
        resultBody.querySelector('.collapsible').dataset.id = id

        resultsTableRow.forEach((html) => {
            const t = document.createElement('template')
            t.innerHTML = html
            resultBody.querySelector('.collapsible').appendChild(t.content)
        })

        if (log) {
            // Wrap lines starting with "E" with span.error to color those lines red
            const wrappedLog = log.replace(/^E.*$/gm, (match) => `<span class="error">${match}</span>`)
            resultBody.querySelector('.log').innerHTML = wrappedLog
        } else {
            resultBody.querySelector('.log').remove()
        }

        if (collapsed) {
            resultBody.querySelector('.collapsible > td')?.classList.add('collapsed')
            resultBody.querySelector('.extras-row').classList.add('hidden')
        } else {
            resultBody.querySelector('.collapsible > td')?.classList.remove('collapsed')
        }

        const media = []
        extras?.forEach(({ name, format_type, content }) => {
            if (['image', 'video'].includes(format_type)) {
                media.push({ path: content, name, format_type })
            }

            if (format_type === 'html') {
                resultBody.querySelector('.extraHTML').insertAdjacentHTML('beforeend', `<div>${content}</div>`)
            }
        })
        mediaViewer.setup(resultBody, media)

        // Add custom html from the pytest_html_results_table_html hook
        tableHtml?.forEach((item) => {
            resultBody.querySelector('td[class="extra"]').insertAdjacentHTML('beforeend', item)
        })

        return resultBody
    },
}

module.exports = {
    dom,
    htmlToElements,
    find,
    findAll,
}

},{"./mediaviewer.js":6}],3:[function(require,module,exports){
const { manager } = require('./datamanager.js')
const { doSort } = require('./sort.js')
const storageModule = require('./storage.js')

const getFilteredSubSet = (filter) =>
    manager.allData.tests.filter(({ result }) => filter.includes(result.toLowerCase()))

const doInitFilter = () => {
    const currentFilter = storageModule.getVisible()
    const filteredSubset = getFilteredSubSet(currentFilter)
    manager.setRender(filteredSubset)
}

const doFilter = (type, show) => {
    if (show) {
        storageModule.showCategory(type)
    } else {
        storageModule.hideCategory(type)
    }

    const currentFilter = storageModule.getVisible()
    const filteredSubset = getFilteredSubSet(currentFilter)
    manager.setRender(filteredSubset)

    const sortColumn = storageModule.getSort()
    doSort(sortColumn, true)
}

module.exports = {
    doFilter,
    doInitFilter,
}

},{"./datamanager.js":1,"./sort.js":7,"./storage.js":8}],4:[function(require,module,exports){
const { redraw, bindEvents, renderStatic } = require('./main.js')
const { doInitFilter } = require('./filter.js')
const { doInitSort } = require('./sort.js')
const { manager } = require('./datamanager.js')
const data = JSON.parse(document.getElementById('data-container').dataset.jsonblob)

function init() {
    manager.setManager(data)
    doInitFilter()
    doInitSort()
    renderStatic()
    redraw()
    bindEvents()
}

init()

},{"./datamanager.js":1,"./filter.js":3,"./main.js":5,"./sort.js":7}],5:[function(require,module,exports){
const { dom, find, findAll } = require('./dom.js')
const { manager } = require('./datamanager.js')
const { doSort } = require('./sort.js')
const { doFilter } = require('./filter.js')
const {
    getVisible,
    getCollapsedIds,
    setCollapsedIds,
    getSort,
    getSortDirection,
    possibleFilters,
} = require('./storage.js')

const removeChildren = (node) => {
    while (node.firstChild) {
        node.removeChild(node.firstChild)
    }
}

const renderStatic = () => {
    const renderEnvironmentTable = () => {
        const environment = manager.environment
        const rows = Object.keys(environment).map((key) => dom.getStaticRow(key, environment[key]))
        const table = document.getElementById('environment')
        removeChildren(table)
        rows.forEach((row) => table.appendChild(row))
    }
    renderEnvironmentTable()
}

const addItemToggleListener = (elem) => {
    elem.addEventListener('click', ({ target }) => {
        const id = target.parentElement.dataset.id
        manager.toggleCollapsedItem(id)

        const collapsedIds = getCollapsedIds()
        if (collapsedIds.includes(id)) {
            const updated = collapsedIds.filter((item) => item !== id)
            setCollapsedIds(updated)
        } else {
            collapsedIds.push(id)
            setCollapsedIds(collapsedIds)
        }
        redraw()
    })
}

const renderContent = (tests) => {
    const sortAttr = getSort(manager.initialSort)
    const sortAsc = JSON.parse(getSortDirection())
    const rows = tests.map(dom.getResultTBody)
    const table = document.getElementById('results-table')
    const tableHeader = document.getElementById('results-table-head')

    const newTable = document.createElement('table')
    newTable.id = 'results-table'

    // remove all sorting classes and set the relevant
    findAll('.sortable', tableHeader).forEach((elem) => elem.classList.remove('asc', 'desc'))
    tableHeader.querySelector(`.sortable[data-column-type="${sortAttr}"]`).classList.add(sortAsc ? 'desc' : 'asc')
    newTable.appendChild(tableHeader)

    if (!rows.length) {
        const emptyTable = document.getElementById('template_results-table__body--empty').content.cloneNode(true)
        newTable.appendChild(emptyTable)
    } else {
        rows.forEach((row) => {
            if (!!row) {
                findAll('.collapsible td:not(.col-links', row).forEach(addItemToggleListener)
                find('.logexpander', row).addEventListener('click',
                    (evt) => evt.target.parentNode.classList.toggle('expanded'),
                )
                newTable.appendChild(row)
            }
        })
    }

    table.replaceWith(newTable)
}

const renderDerived = () => {
    const currentFilter = getVisible()
    possibleFilters.forEach((result) => {
        const input = document.querySelector(`input[data-test-result="${result}"]`)
        input.checked = currentFilter.includes(result)
    })
}

const bindEvents = () => {
    const filterColumn = (evt) => {
        const { target: element } = evt
        const { testResult } = element.dataset

        doFilter(testResult, element.checked)
        const collapsedIds = getCollapsedIds()
        const updated = manager.renderData.tests.map((test) => {
            return {
                ...test,
                collapsed: collapsedIds.includes(test.id),
            }
        })
        manager.setRender(updated)
        redraw()
    }

    const header = document.getElementById('environment-header')
    header.addEventListener('click', () => {
        const table = document.getElementById('environment')
        table.classList.toggle('hidden')
        header.classList.toggle('collapsed')
    })

    findAll('input[name="filter_checkbox"]').forEach((elem) => {
        elem.addEventListener('click', filterColumn)
    })

    findAll('.sortable').forEach((elem) => {
        elem.addEventListener('click', (evt) => {
            const { target: element } = evt
            const { columnType } = element.dataset
            doSort(columnType)
            redraw()
        })
    })

    document.getElementById('show_all_details').addEventListener('click', () => {
        manager.allCollapsed = false
        setCollapsedIds([])
        redraw()
    })
    document.getElementById('hide_all_details').addEventListener('click', () => {
        manager.allCollapsed = true
        const allIds = manager.renderData.tests.map((test) => test.id)
        setCollapsedIds(allIds)
        redraw()
    })
}

const redraw = () => {
    const { testSubset } = manager

    renderContent(testSubset)
    renderDerived()
}

module.exports = {
    redraw,
    bindEvents,
    renderStatic,
}

},{"./datamanager.js":1,"./dom.js":2,"./filter.js":3,"./sort.js":7,"./storage.js":8}],6:[function(require,module,exports){
class MediaViewer {
    constructor(assets) {
        this.assets = assets
        this.index = 0
    }

    nextActive() {
        this.index = this.index === this.assets.length - 1 ? 0 : this.index + 1
        return [this.activeFile, this.index]
    }

    prevActive() {
        this.index = this.index === 0 ? this.assets.length - 1 : this.index -1
        return [this.activeFile, this.index]
    }

    get currentIndex() {
        return this.index
    }

    get activeFile() {
        return this.assets[this.index]
    }
}


const setup = (resultBody, assets) => {
    if (!assets.length) {
        resultBody.querySelector('.media').classList.add('hidden')
        return
    }

    const mediaViewer = new MediaViewer(assets)
    const container = resultBody.querySelector('.media-container')
    const leftArrow = resultBody.querySelector('.media-container__nav--left')
    const rightArrow = resultBody.querySelector('.media-container__nav--right')
    const mediaName = resultBody.querySelector('.media__name')
    const counter = resultBody.querySelector('.media__counter')
    const imageEl = resultBody.querySelector('img')
    const sourceEl = resultBody.querySelector('source')
    const videoEl = resultBody.querySelector('video')

    const setImg = (media, index) => {
        if (media?.format_type === 'image') {
            imageEl.src = media.path

            imageEl.classList.remove('hidden')
            videoEl.classList.add('hidden')
        } else if (media?.format_type === 'video') {
            sourceEl.src = media.path

            videoEl.classList.remove('hidden')
            imageEl.classList.add('hidden')
        }

        mediaName.innerText = media?.name
        counter.innerText = `${index + 1} / ${assets.length}`
    }
    setImg(mediaViewer.activeFile, mediaViewer.currentIndex)

    const moveLeft = () => {
        const [media, index] = mediaViewer.prevActive()
        setImg(media, index)
    }
    const doRight = () => {
        const [media, index] = mediaViewer.nextActive()
        setImg(media, index)
    }
    const openImg = () => {
        window.open(mediaViewer.activeFile.path, '_blank')
    }
    if (assets.length === 1) {
        container.classList.add('media-container--fullscreen')
    } else {
        leftArrow.addEventListener('click', moveLeft)
        rightArrow.addEventListener('click', doRight)
    }
    imageEl.addEventListener('click', openImg)
}

module.exports = {
    setup,
}

},{}],7:[function(require,module,exports){
const { manager } = require('./datamanager.js')
const storageModule = require('./storage.js')

const genericSort = (list, key, ascending, customOrder) => {
    let sorted
    if (customOrder) {
        sorted = list.sort((a, b) => {
            const aValue = a.result.toLowerCase()
            const bValue = b.result.toLowerCase()

            const aIndex = customOrder.findIndex((item) => item.toLowerCase() === aValue)
            const bIndex = customOrder.findIndex((item) => item.toLowerCase() === bValue)

            // Compare the indices to determine the sort order
            return aIndex - bIndex
        })
    } else {
        sorted = list.sort((a, b) => a[key] === b[key] ? 0 : a[key] > b[key] ? 1 : -1)
    }

    if (ascending) {
        sorted.reverse()
    }
    return sorted
}

const durationSort = (list, ascending) => {
    const parseDuration = (duration) => {
        if (duration.includes(':')) {
            // If it's in the format "HH:mm:ss"
            const [hours, minutes, seconds] = duration.split(':').map(Number)
            return (hours * 3600 + minutes * 60 + seconds) * 1000
        } else {
            // If it's in the format "nnn ms"
            return parseInt(duration)
        }
    }
    const sorted = list.sort((a, b) => parseDuration(a['duration']) - parseDuration(b['duration']))
    if (ascending) {
        sorted.reverse()
    }
    return sorted
}

const doInitSort = () => {
    const type = storageModule.getSort(manager.initialSort)
    const ascending = storageModule.getSortDirection()
    const list = manager.testSubset
    const initialOrder = ['Error', 'Failed', 'Rerun', 'XFailed', 'XPassed', 'Skipped', 'Passed']

    storageModule.setSort(type)
    storageModule.setSortDirection(ascending)

    if (type?.toLowerCase() === 'original') {
        manager.setRender(list)
    } else {
        let sortedList
        switch (type) {
        case 'duration':
            sortedList = durationSort(list, ascending)
            break
        case 'result':
            sortedList = genericSort(list, type, ascending, initialOrder)
            break
        default:
            sortedList = genericSort(list, type, ascending)
            break
        }
        manager.setRender(sortedList)
    }
}

const doSort = (type, skipDirection) => {
    const newSortType = storageModule.getSort(manager.initialSort) !== type
    const currentAsc = storageModule.getSortDirection()
    let ascending
    if (skipDirection) {
        ascending = currentAsc
    } else {
        ascending = newSortType ? false : !currentAsc
    }
    storageModule.setSort(type)
    storageModule.setSortDirection(ascending)

    const list = manager.testSubset
    const sortedList = type === 'duration' ? durationSort(list, ascending) : genericSort(list, type, ascending)
    manager.setRender(sortedList)
}

module.exports = {
    doInitSort,
    doSort,
}

},{"./datamanager.js":1,"./storage.js":8}],8:[function(require,module,exports){
const possibleFilters = [
    'passed',
    'skipped',
    'failed',
    'error',
    'xfailed',
    'xpassed',
    'rerun',
]

const getVisible = () => {
    const url = new URL(window.location.href)
    const settings = new URLSearchParams(url.search).get('visible')
    const lower = (item) => {
        const lowerItem = item.toLowerCase()
        if (possibleFilters.includes(lowerItem)) {
            return lowerItem
        }
        return null
    }
    return settings === null ?
        possibleFilters :
        [...new Set(settings?.split(',').map(lower).filter((item) => item))]
}

const hideCategory = (categoryToHide) => {
    const url = new URL(window.location.href)
    const visibleParams = new URLSearchParams(url.search).get('visible')
    const currentVisible = visibleParams ? visibleParams.split(',') : [...possibleFilters]
    const settings = [...new Set(currentVisible)].filter((f) => f !== categoryToHide).join(',')

    url.searchParams.set('visible', settings)
    window.history.pushState({}, null, unescape(url.href))
}

const showCategory = (categoryToShow) => {
    if (typeof window === 'undefined') {
        return
    }
    const url = new URL(window.location.href)
    const currentVisible = new URLSearchParams(url.search).get('visible')?.split(',').filter(Boolean) ||
        [...possibleFilters]
    const settings = [...new Set([categoryToShow, ...currentVisible])]
    const noFilter = possibleFilters.length === settings.length || !settings.length

    noFilter ? url.searchParams.delete('visible') : url.searchParams.set('visible', settings.join(','))
    window.history.pushState({}, null, unescape(url.href))
}

const getSort = (initialSort) => {
    const url = new URL(window.location.href)
    let sort = new URLSearchParams(url.search).get('sort')
    if (!sort) {
        sort = initialSort || 'result'
    }
    return sort
}

const setSort = (type) => {
    const url = new URL(window.location.href)
    url.searchParams.set('sort', type)
    window.history.pushState({}, null, unescape(url.href))
}

const getCollapsedCategory = (renderCollapsed) => {
    let categories
    if (typeof window !== 'undefined') {
        const url = new URL(window.location.href)
        const collapsedItems = new URLSearchParams(url.search).get('collapsed')
        switch (true) {
        case !renderCollapsed && collapsedItems === null:
            categories = ['passed']
            break
        case collapsedItems?.length === 0 || /^["']{2}$/.test(collapsedItems):
            categories = []
            break
        case /^all$/.test(collapsedItems) || collapsedItems === null && /^all$/.test(renderCollapsed):
            categories = [...possibleFilters]
            break
        default:
            categories = collapsedItems?.split(',').map((item) => item.toLowerCase()) || renderCollapsed
            break
        }
    } else {
        categories = []
    }
    return categories
}

const getSortDirection = () => JSON.parse(sessionStorage.getItem('sortAsc')) || false
const setSortDirection = (ascending) => sessionStorage.setItem('sortAsc', ascending)

const getCollapsedIds = () => JSON.parse(sessionStorage.getItem('collapsedIds')) || []
const setCollapsedIds = (list) => sessionStorage.setItem('collapsedIds', JSON.stringify(list))

module.exports = {
    getVisible,
    hideCategory,
    showCategory,
    getCollapsedIds,
    setCollapsedIds,
    getSort,
    setSort,
    getSortDirection,
    setSortDirection,
    getCollapsedCategory,
    possibleFilters,
}

},{}]},{},[4]);
    </script>
  </footer>
</html>